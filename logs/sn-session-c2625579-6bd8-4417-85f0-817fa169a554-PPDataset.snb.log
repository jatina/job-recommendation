2016-06-13 13:55:10,704  INFO [main] (notebook.kernel.pfork.BetterFork$) - Remote process starting
2016-06-13 13:55:11,513  INFO [Remote-akka.actor.default-dispatcher-2] (akka.event.slf4j.Slf4jLogger) - Slf4jLogger started
2016-06-13 13:55:11,591  INFO [Remote-akka.actor.default-dispatcher-5] (Remoting) - Starting remoting
2016-06-13 13:55:11,762  INFO [Remote-akka.actor.default-dispatcher-2] (Remoting) - Remoting started; listening on addresses :[akka.tcp://Remote@127.0.0.1:37485]
2016-06-13 13:55:11,765  INFO [Remote-akka.actor.default-dispatcher-2] (Remoting) - Remoting now listens on addresses: [akka.tcp://Remote@127.0.0.1:37485]
2016-06-13 13:55:12,381  INFO [Remote-akka.actor.default-dispatcher-5] (notebook.client.ReplCalculator) - ReplCalculator preStart
2016-06-13 13:55:12,403  INFO [Remote-akka.actor.default-dispatcher-5] (notebook.client.ReplCalculator) -  INIT SCRIPT: dummy
2016-06-13 13:55:13,295  WARN [Remote-akka.actor.default-dispatcher-2] (org.apache.hadoop.util.NativeCodeLoader) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2016-06-13 13:55:13,407  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.SecurityManager) - Changing view acls to: jatin
2016-06-13 13:55:13,409  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.SecurityManager) - Changing modify acls to: jatin
2016-06-13 13:55:13,410  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.SecurityManager) - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jatin); users with modify permissions: Set(jatin)
2016-06-13 13:55:13,938  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.HttpServer) - Starting HTTP Server
2016-06-13 13:55:14,042  INFO [Remote-akka.actor.default-dispatcher-2] (org.spark-project.jetty.server.Server) - jetty-8.y.z-SNAPSHOT
2016-06-13 13:55:14,072  INFO [Remote-akka.actor.default-dispatcher-2] (org.spark-project.jetty.server.AbstractConnector) - Started SocketConnector@0.0.0.0:36777
2016-06-13 13:55:14,075  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.util.Utils) - Successfully started service 'HTTP server' on port 36777.
2016-06-13 13:55:18,323  WARN [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.util.Utils) - Your hostname, PRINHYLTPDL0524 resolves to a loopback address: 127.0.1.1; using 172.16.51.158 instead (on interface wlp6s0)
2016-06-13 13:55:18,325  WARN [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.util.Utils) - Set SPARK_LOCAL_IP if you need to bind to another address
2016-06-13 13:55:21,196  INFO [Remote-akka.actor.default-dispatcher-5] (notebook.client.ReplCalculator) - Init script processed successfully
2016-06-13 13:55:21,197  INFO [Remote-akka.actor.default-dispatcher-5] (notebook.client.ReplCalculator) -  INIT SCRIPT: class server
2016-06-13 13:55:21,862  INFO [Remote-akka.actor.default-dispatcher-5] (notebook.client.ReplCalculator) - Init script processed successfully
2016-06-13 13:55:21,862  INFO [Remote-akka.actor.default-dispatcher-5] (notebook.client.ReplCalculator) -  INIT SCRIPT: deps
2016-06-13 13:55:22,480  INFO [Remote-akka.actor.default-dispatcher-5] (notebook.client.ReplCalculator) - Init script processed successfully
2016-06-13 13:55:22,480  INFO [Remote-akka.actor.default-dispatcher-5] (notebook.client.ReplCalculator) -  INIT SCRIPT: imports
2016-06-13 13:55:22,487  INFO [Remote-akka.actor.default-dispatcher-5] (notebook.client.ReplCalculator) -  INIT SCRIPT: custom conf
2016-06-13 13:55:23,770  INFO [Remote-akka.actor.default-dispatcher-5] (notebook.client.ReplCalculator) - Init script processed successfully
2016-06-13 13:55:23,770  INFO [Remote-akka.actor.default-dispatcher-5] (notebook.client.ReplCalculator) -  INIT SCRIPT: jar:file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/lib/nooostab.spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet.jar!/scripts/init.sc
2016-06-13 13:55:25,910  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.SparkContext) - Running Spark version 1.6.0
2016-06-13 13:55:26,444  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.SecurityManager) - Changing view acls to: jatin
2016-06-13 13:55:26,444  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.SecurityManager) - Changing modify acls to: jatin
2016-06-13 13:55:26,446  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.SecurityManager) - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jatin); users with modify permissions: Set(jatin)
2016-06-13 13:55:26,799  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.util.Utils) - Successfully started service 'sparkDriver' on port 33853.
2016-06-13 13:55:26,836  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-2] (akka.event.slf4j.Slf4jLogger) - Slf4jLogger started
2016-06-13 13:55:26,840  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-5] (Remoting) - Starting remoting
2016-06-13 13:55:26,862  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-5] (Remoting) - Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@172.16.51.158:45073]
2016-06-13 13:55:26,862  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.util.Utils) - Successfully started service 'sparkDriverActorSystem' on port 45073.
2016-06-13 13:55:26,873  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.SparkEnv) - Registering MapOutputTracker
2016-06-13 13:55:26,892  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.SparkEnv) - Registering BlockManagerMaster
2016-06-13 13:55:26,905  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.storage.DiskBlockManager) - Created local directory at /tmp/blockmgr-37016ca6-3a4f-45de-9454-80e2929997bc
2016-06-13 13:55:26,911  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.storage.MemoryStore) - MemoryStore started with capacity 9.8 GB
2016-06-13 13:55:26,997  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.SparkEnv) - Registering OutputCommitCoordinator
2016-06-13 13:55:27,139  INFO [Remote-akka.actor.default-dispatcher-2] (org.spark-project.jetty.server.Server) - jetty-8.y.z-SNAPSHOT
2016-06-13 13:55:27,164  INFO [Remote-akka.actor.default-dispatcher-2] (org.spark-project.jetty.server.AbstractConnector) - Started SelectChannelConnector@0.0.0.0:4040
2016-06-13 13:55:27,165  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.util.Utils) - Successfully started service 'SparkUI' on port 4040.
2016-06-13 13:55:27,168  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.ui.SparkUI) - Started SparkUI at http://172.16.51.158:4040
2016-06-13 13:55:27,214  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.HttpFileServer) - HTTP File server directory is /tmp/spark-7d3d95e2-3c3c-4cca-8ce7-ed84b038ccf3/httpd-4a9f221f-f431-424c-83e4-fd091c364362
2016-06-13 13:55:27,215  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.HttpServer) - Starting HTTP Server
2016-06-13 13:55:27,215  INFO [Remote-akka.actor.default-dispatcher-2] (org.spark-project.jetty.server.Server) - jetty-8.y.z-SNAPSHOT
2016-06-13 13:55:27,252  INFO [Remote-akka.actor.default-dispatcher-2] (org.spark-project.jetty.server.AbstractConnector) - Started SocketConnector@0.0.0.0:35307
2016-06-13 13:55:27,254  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.util.Utils) - Successfully started service 'HTTP file server' on port 35307.
2016-06-13 13:55:27,256 ERROR [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.SparkContext) - Error adding jar (java.lang.IllegalArgumentException: /home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet cannot be a directory.), was the --addJars option used?
2016-06-13 13:55:27,287  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.SparkContext) - Added JAR file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/lib/common.common-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet.jar at http://172.16.51.158:35307/jars/common.common-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet.jar with timestamp 1465806327286
2016-06-13 13:55:27,375  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.executor.Executor) - Starting executor ID driver on host localhost
2016-06-13 13:55:27,387  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.executor.Executor) - Using REPL class URI: http://172.16.51.158:36777
2016-06-13 13:55:27,413  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.util.Utils) - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45752.
2016-06-13 13:55:27,414  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.network.netty.NettyBlockTransferService) - Server created on 45752
2016-06-13 13:55:27,416  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.storage.BlockManagerMaster) - Trying to register BlockManager
2016-06-13 13:55:27,438  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerMasterEndpoint) - Registering block manager localhost:45752 with 9.8 GB RAM, BlockManagerId(driver, localhost, 45752)
2016-06-13 13:55:27,443  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.storage.BlockManagerMaster) - Registered BlockManager
2016-06-13 13:55:28,672  INFO [Remote-akka.actor.default-dispatcher-5] (notebook.client.ReplCalculator) - Init script processed successfully
2016-06-13 13:56:06,369  INFO [Remote-akka.actor.default-dispatcher-15] (org.hibernate.validator.internal.util.Version) - HV000001: Hibernate Validator 5.1.2.Final
2016-06-13 13:56:06,488  INFO [Remote-akka.actor.default-dispatcher-15] (com.jcabi.aspects.aj.MethodValidator) - JSR-303 validator org.hibernate.validator.internal.engine.ValidatorImpl instantiated by jcabi-aspects 0.18/55a5c13
2016-06-13 13:56:06,509  INFO [Remote-akka.actor.default-dispatcher-15] (com.jcabi.aspects.aj.NamedThreads) - jcabi-aspects 0.18/55a5c13 started new daemon thread jcabi-loggable for watching of @Loggable annotated methods
2016-06-13 13:56:06,695  WARN [Remote-akka.actor.default-dispatcher-15] (com.jcabi.aether.Aether) - mirrors: []
2016-06-13 13:56:06,759  WARN [FileRepositoryConnector-1] (com.jcabi.aether.LogTransferListener) - #transferFailed('GET FAILED file:/home/jatin/.m2/repository/org/js..132..repo/org/jsoup/jsoup/1.7.2/jsoup-1.7.2.pom'): in 29.57µs
2016-06-13 13:56:06,783  INFO [Remote-akka.actor.default-dispatcher-15] (com.ning.http.client.providers.netty.NettyAsyncHttpProvider) - Number of application's worked threads is 8
2016-06-13 13:56:07,528  INFO [New I/O worker #13] (com.jcabi.aether.LogTransferListener) - #transferSucceeded('GET SUCCEEDED http://repo1.maven.org/maven2/org/j..133..repo/org/jsoup/jsoup/1.7.2/jsoup-1.7.2.pom'): in 150.17µs
2016-06-13 13:56:07,939  WARN [FileRepositoryConnector-1] (com.jcabi.aether.LogTransferListener) - #transferFailed('GET FAILED file:/home/jatin/.m2/repository/org/js..132..repo/org/jsoup/jsoup/1.7.2/jsoup-1.7.2.jar'): in 33.06µs
2016-06-13 13:56:07,940  INFO [Remote-akka.actor.default-dispatcher-15] (com.ning.http.client.providers.netty.NettyAsyncHttpProvider) - Number of application's worked threads is 8
2016-06-13 13:56:11,207  INFO [New I/O worker #22] (com.jcabi.aether.LogTransferListener) - #transferSucceeded('GET SUCCEEDED http://repo1.maven.org/maven2/org/j..133..repo/org/jsoup/jsoup/1.7.2/jsoup-1.7.2.jar'): in 92.87µs
2016-06-13 13:56:11,498  INFO [Remote-akka.actor.default-dispatcher-15] (Aether downloads) - 
Resolved/Downloaded:
* org.jsoup:jsoup:jar:1.7.2
===================================================

2016-06-13 13:56:11,793  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2016-06-13 13:56:11,794  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-06-13 13:56:11,798  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/api,null}
2016-06-13 13:56:11,800  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/,null}
2016-06-13 13:56:11,801  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/static,null}
2016-06-13 13:56:11,802  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-06-13 13:56:11,802  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2016-06-13 13:56:11,803  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2016-06-13 13:56:11,804  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors,null}
2016-06-13 13:56:11,805  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2016-06-13 13:56:11,806  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/environment,null}
2016-06-13 13:56:11,806  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-06-13 13:56:11,807  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2016-06-13 13:56:11,808  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2016-06-13 13:56:11,808  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage,null}
2016-06-13 13:56:11,809  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2016-06-13 13:56:11,810  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2016-06-13 13:56:11,811  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2016-06-13 13:56:11,811  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2016-06-13 13:56:11,812  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2016-06-13 13:56:11,812  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages,null}
2016-06-13 13:56:11,812  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2016-06-13 13:56:11,812  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2016-06-13 13:56:11,813  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2016-06-13 13:56:11,813  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2016-06-13 13:56:11,867  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.ui.SparkUI) - Stopped Spark web UI at http://172.16.51.158:4040
2016-06-13 13:56:11,882  INFO [dispatcher-event-loop-0] (org.apache.spark.MapOutputTrackerMasterEndpoint) - MapOutputTrackerMasterEndpoint stopped!
2016-06-13 13:56:11,892  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.MemoryStore) - MemoryStore cleared
2016-06-13 13:56:11,893  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.BlockManager) - BlockManager stopped
2016-06-13 13:56:11,895  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.BlockManagerMaster) - BlockManagerMaster stopped
2016-06-13 13:56:11,901  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint) - OutputCommitCoordinator stopped!
2016-06-13 13:56:11,903  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkContext) - Successfully stopped SparkContext
2016-06-13 13:56:11,908  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-16] (akka.remote.RemoteActorRefProvider$RemotingTerminator) - Shutting down remote daemon.
2016-06-13 13:56:11,909  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-3] (akka.remote.RemoteActorRefProvider$RemotingTerminator) - Remote daemon shut down; proceeding with flushing remote transports.
2016-06-13 13:56:11,965  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-15] (akka.remote.RemoteActorRefProvider$RemotingTerminator) - Remoting shut down.
2016-06-13 13:56:12,151  INFO [Remote-akka.actor.default-dispatcher-3] (notebook.client.ReplCalculator) - 
2016-06-13 13:56:12,151  INFO [Remote-akka.actor.default-dispatcher-3] (notebook.client.ReplCalculator) - CP reload processed successfully
2016-06-13 13:56:12,164  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SecurityManager) - Changing view acls to: jatin
2016-06-13 13:56:12,164  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SecurityManager) - Changing modify acls to: jatin
2016-06-13 13:56:12,164  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SecurityManager) - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jatin); users with modify permissions: Set(jatin)
2016-06-13 13:56:12,170  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.HttpServer) - Starting HTTP Server
2016-06-13 13:56:12,171  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.Server) - jetty-8.y.z-SNAPSHOT
2016-06-13 13:56:12,180  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.AbstractConnector) - Started SocketConnector@0.0.0.0:35551
2016-06-13 13:56:12,180  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.util.Utils) - Successfully started service 'HTTP server' on port 35551.
2016-06-13 13:56:12,715  INFO [Remote-akka.actor.default-dispatcher-3] (notebook.client.ReplCalculator) - ReplCalculator preStart
2016-06-13 13:56:12,715  INFO [Remote-akka.actor.default-dispatcher-3] (notebook.client.ReplCalculator) -  INIT SCRIPT: dummy
2016-06-13 13:56:13,131  INFO [Remote-akka.actor.default-dispatcher-3] (notebook.client.ReplCalculator) - Init script processed successfully
2016-06-13 13:56:13,131  INFO [Remote-akka.actor.default-dispatcher-3] (notebook.client.ReplCalculator) -  INIT SCRIPT: class server
2016-06-13 13:56:13,299  INFO [Remote-akka.actor.default-dispatcher-3] (notebook.client.ReplCalculator) - Init script processed successfully
2016-06-13 13:56:13,299  INFO [Remote-akka.actor.default-dispatcher-3] (notebook.client.ReplCalculator) -  INIT SCRIPT: deps
2016-06-13 13:56:13,487  INFO [Remote-akka.actor.default-dispatcher-3] (notebook.client.ReplCalculator) - Init script processed successfully
2016-06-13 13:56:13,487  INFO [Remote-akka.actor.default-dispatcher-3] (notebook.client.ReplCalculator) -  INIT SCRIPT: imports
2016-06-13 13:56:13,487  INFO [Remote-akka.actor.default-dispatcher-3] (notebook.client.ReplCalculator) -  INIT SCRIPT: custom conf
2016-06-13 13:56:13,813  INFO [Remote-akka.actor.default-dispatcher-5] (notebook.client.ReplCalculator) - Init script processed successfully
2016-06-13 13:56:13,813  INFO [Remote-akka.actor.default-dispatcher-5] (notebook.client.ReplCalculator) -  INIT SCRIPT: jar:file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/lib/nooostab.spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet.jar!/scripts/init.sc
2016-06-13 13:56:14,710  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkContext) - Running Spark version 1.6.0
2016-06-13 13:56:14,711  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SecurityManager) - Changing view acls to: jatin
2016-06-13 13:56:14,711  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SecurityManager) - Changing modify acls to: jatin
2016-06-13 13:56:14,713  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SecurityManager) - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jatin); users with modify permissions: Set(jatin)
2016-06-13 13:56:14,739  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.util.Utils) - Successfully started service 'sparkDriver' on port 38705.
2016-06-13 13:56:14,771  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-5] (akka.event.slf4j.Slf4jLogger) - Slf4jLogger started
2016-06-13 13:56:14,779  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-4] (Remoting) - Starting remoting
2016-06-13 13:56:14,794  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-5] (Remoting) - Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:34561]
2016-06-13 13:56:14,795  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.util.Utils) - Successfully started service 'sparkDriverActorSystem' on port 34561.
2016-06-13 13:56:14,800  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkEnv) - Registering MapOutputTracker
2016-06-13 13:56:14,801  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkEnv) - Registering BlockManagerMaster
2016-06-13 13:56:14,802  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.DiskBlockManager) - Created local directory at /tmp/blockmgr-2167fe28-58e7-4ef6-aa40-3788c5f3e048
2016-06-13 13:56:14,804  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.MemoryStore) - MemoryStore started with capacity 9.8 GB
2016-06-13 13:56:14,810  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkEnv) - Registering OutputCommitCoordinator
2016-06-13 13:56:14,827  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.Server) - jetty-8.y.z-SNAPSHOT
2016-06-13 13:56:14,833  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.AbstractConnector) - Started SelectChannelConnector@0.0.0.0:4040
2016-06-13 13:56:14,833  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.util.Utils) - Successfully started service 'SparkUI' on port 4040.
2016-06-13 13:56:14,833  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.ui.SparkUI) - Started SparkUI at http://localhost:4040
2016-06-13 13:56:14,870  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.HttpFileServer) - HTTP File server directory is /tmp/spark-7d3d95e2-3c3c-4cca-8ce7-ed84b038ccf3/httpd-d0181b57-2383-4b16-a1ff-2521a682bdde
2016-06-13 13:56:14,872  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.HttpServer) - Starting HTTP Server
2016-06-13 13:56:14,874  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.Server) - jetty-8.y.z-SNAPSHOT
2016-06-13 13:56:14,885  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.AbstractConnector) - Started SocketConnector@0.0.0.0:39724
2016-06-13 13:56:14,885  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.util.Utils) - Successfully started service 'HTTP file server' on port 39724.
2016-06-13 13:56:14,885 ERROR [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkContext) - Error adding jar (java.lang.IllegalArgumentException: /home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet cannot be a directory.), was the --addJars option used?
2016-06-13 13:56:14,887  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkContext) - Added JAR file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/lib/common.common-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet.jar at http://localhost:39724/jars/common.common-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet.jar with timestamp 1465806374887
2016-06-13 13:56:14,903  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.executor.Executor) - Starting executor ID driver on host localhost
2016-06-13 13:56:14,903  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.executor.Executor) - Using REPL class URI: http://localhost:35551
2016-06-13 13:56:14,912  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.util.Utils) - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 34410.
2016-06-13 13:56:14,912  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.network.netty.NettyBlockTransferService) - Server created on 34410
2016-06-13 13:56:14,918  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.BlockManagerMaster) - Trying to register BlockManager
2016-06-13 13:56:14,918  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerMasterEndpoint) - Registering block manager localhost:34410 with 9.8 GB RAM, BlockManagerId(driver, localhost, 34410)
2016-06-13 13:56:14,920  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.BlockManagerMaster) - Registered BlockManager
2016-06-13 13:56:15,565  INFO [Remote-akka.actor.default-dispatcher-5] (notebook.client.ReplCalculator) - Init script processed successfully
2016-06-13 13:56:16,578  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2016-06-13 13:56:16,580  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-06-13 13:56:16,582  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/api,null}
2016-06-13 13:56:16,582  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/,null}
2016-06-13 13:56:16,588  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/static,null}
2016-06-13 13:56:16,589  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-06-13 13:56:16,589  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2016-06-13 13:56:16,589  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2016-06-13 13:56:16,589  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors,null}
2016-06-13 13:56:16,589  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2016-06-13 13:56:16,589  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/environment,null}
2016-06-13 13:56:16,589  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-06-13 13:56:16,589  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2016-06-13 13:56:16,589  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2016-06-13 13:56:16,589  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage,null}
2016-06-13 13:56:16,590  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2016-06-13 13:56:16,590  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2016-06-13 13:56:16,590  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2016-06-13 13:56:16,590  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2016-06-13 13:56:16,590  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2016-06-13 13:56:16,593  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages,null}
2016-06-13 13:56:16,598  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2016-06-13 13:56:16,598  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2016-06-13 13:56:16,598  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2016-06-13 13:56:16,598  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2016-06-13 13:56:16,649  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.ui.SparkUI) - Stopped Spark web UI at http://localhost:4040
2016-06-13 13:56:16,651  INFO [dispatcher-event-loop-2] (org.apache.spark.MapOutputTrackerMasterEndpoint) - MapOutputTrackerMasterEndpoint stopped!
2016-06-13 13:56:16,658  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.MemoryStore) - MemoryStore cleared
2016-06-13 13:56:16,658  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.BlockManager) - BlockManager stopped
2016-06-13 13:56:16,661  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.BlockManagerMaster) - BlockManagerMaster stopped
2016-06-13 13:56:16,661  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint) - OutputCommitCoordinator stopped!
2016-06-13 13:56:16,666  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkContext) - Successfully stopped SparkContext
2016-06-13 13:56:16,666  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-2] (akka.remote.RemoteActorRefProvider$RemotingTerminator) - Shutting down remote daemon.
2016-06-13 13:56:16,667  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-2] (akka.remote.RemoteActorRefProvider$RemotingTerminator) - Remote daemon shut down; proceeding with flushing remote transports.
2016-06-13 13:56:16,676  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-5] (akka.remote.RemoteActorRefProvider$RemotingTerminator) - Remoting shut down.
2016-06-13 13:56:17,279  INFO [Remote-akka.actor.default-dispatcher-5] (org.apache.spark.SparkContext) - SparkContext already stopped.
2016-06-13 13:56:17,280  INFO [Remote-akka.actor.default-dispatcher-5] (org.apache.spark.SparkContext) - Running Spark version 1.6.0
2016-06-13 13:56:17,281  INFO [Remote-akka.actor.default-dispatcher-5] (org.apache.spark.SecurityManager) - Changing view acls to: jatin
2016-06-13 13:56:17,281  INFO [Remote-akka.actor.default-dispatcher-5] (org.apache.spark.SecurityManager) - Changing modify acls to: jatin
2016-06-13 13:56:17,281  INFO [Remote-akka.actor.default-dispatcher-5] (org.apache.spark.SecurityManager) - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jatin); users with modify permissions: Set(jatin)
2016-06-13 13:56:17,303  INFO [Remote-akka.actor.default-dispatcher-5] (org.apache.spark.util.Utils) - Successfully started service 'sparkDriver' on port 38559.
2016-06-13 13:56:17,323  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-2] (akka.event.slf4j.Slf4jLogger) - Slf4jLogger started
2016-06-13 13:56:17,330  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-2] (Remoting) - Starting remoting
2016-06-13 13:56:17,349  INFO [Remote-akka.actor.default-dispatcher-5] (org.apache.spark.util.Utils) - Successfully started service 'sparkDriverActorSystem' on port 41503.
2016-06-13 13:56:17,359  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-4] (Remoting) - Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:41503]
2016-06-13 13:56:17,362  INFO [Remote-akka.actor.default-dispatcher-5] (org.apache.spark.SparkEnv) - Registering MapOutputTracker
2016-06-13 13:56:17,363  INFO [Remote-akka.actor.default-dispatcher-5] (org.apache.spark.SparkEnv) - Registering BlockManagerMaster
2016-06-13 13:56:17,364  INFO [Remote-akka.actor.default-dispatcher-5] (org.apache.spark.storage.DiskBlockManager) - Created local directory at /tmp/blockmgr-22d9c252-5e85-4629-8371-63d603da3395
2016-06-13 13:56:17,364  INFO [Remote-akka.actor.default-dispatcher-5] (org.apache.spark.storage.MemoryStore) - MemoryStore started with capacity 9.8 GB
2016-06-13 13:56:17,381  INFO [Remote-akka.actor.default-dispatcher-5] (org.apache.spark.SparkEnv) - Registering OutputCommitCoordinator
2016-06-13 13:56:17,407  INFO [Remote-akka.actor.default-dispatcher-5] (org.spark-project.jetty.server.Server) - jetty-8.y.z-SNAPSHOT
2016-06-13 13:56:17,418  INFO [Remote-akka.actor.default-dispatcher-5] (org.spark-project.jetty.server.AbstractConnector) - Started SelectChannelConnector@0.0.0.0:4040
2016-06-13 13:56:17,418  INFO [Remote-akka.actor.default-dispatcher-5] (org.apache.spark.util.Utils) - Successfully started service 'SparkUI' on port 4040.
2016-06-13 13:56:17,424  INFO [Remote-akka.actor.default-dispatcher-5] (org.apache.spark.ui.SparkUI) - Started SparkUI at http://localhost:4040
2016-06-13 13:56:17,458  INFO [Remote-akka.actor.default-dispatcher-5] (org.apache.spark.HttpFileServer) - HTTP File server directory is /tmp/spark-7d3d95e2-3c3c-4cca-8ce7-ed84b038ccf3/httpd-96eb931b-5a85-4a60-b605-93ecb1278857
2016-06-13 13:56:17,460  INFO [Remote-akka.actor.default-dispatcher-5] (org.apache.spark.HttpServer) - Starting HTTP Server
2016-06-13 13:56:17,463  INFO [Remote-akka.actor.default-dispatcher-5] (org.spark-project.jetty.server.Server) - jetty-8.y.z-SNAPSHOT
2016-06-13 13:56:17,466  INFO [Remote-akka.actor.default-dispatcher-5] (org.spark-project.jetty.server.AbstractConnector) - Started SocketConnector@0.0.0.0:37132
2016-06-13 13:56:17,466  INFO [Remote-akka.actor.default-dispatcher-5] (org.apache.spark.util.Utils) - Successfully started service 'HTTP file server' on port 37132.
2016-06-13 13:56:17,467  INFO [Remote-akka.actor.default-dispatcher-5] (org.apache.spark.SparkContext) - Added JAR /home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/repo/org/jsoup/jsoup/1.7.2/jsoup-1.7.2.jar at http://localhost:37132/jars/jsoup-1.7.2.jar with timestamp 1465806377467
2016-06-13 13:56:17,467 ERROR [Remote-akka.actor.default-dispatcher-5] (org.apache.spark.SparkContext) - Error adding jar (java.lang.IllegalArgumentException: /home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet cannot be a directory.), was the --addJars option used?
2016-06-13 13:56:17,469  INFO [Remote-akka.actor.default-dispatcher-5] (org.apache.spark.SparkContext) - Added JAR file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/lib/common.common-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet.jar at http://localhost:37132/jars/common.common-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet.jar with timestamp 1465806377469
2016-06-13 13:56:17,480  INFO [Remote-akka.actor.default-dispatcher-5] (org.apache.spark.executor.Executor) - Starting executor ID driver on host localhost
2016-06-13 13:56:17,481  INFO [Remote-akka.actor.default-dispatcher-5] (org.apache.spark.executor.Executor) - Using REPL class URI: http://localhost:35551
2016-06-13 13:56:17,494  INFO [Remote-akka.actor.default-dispatcher-5] (org.apache.spark.util.Utils) - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37774.
2016-06-13 13:56:17,494  INFO [Remote-akka.actor.default-dispatcher-5] (org.apache.spark.network.netty.NettyBlockTransferService) - Server created on 37774
2016-06-13 13:56:17,494  INFO [Remote-akka.actor.default-dispatcher-5] (org.apache.spark.storage.BlockManagerMaster) - Trying to register BlockManager
2016-06-13 13:56:17,495  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerMasterEndpoint) - Registering block manager localhost:37774 with 9.8 GB RAM, BlockManagerId(driver, localhost, 37774)
2016-06-13 13:56:17,495  INFO [Remote-akka.actor.default-dispatcher-5] (org.apache.spark.storage.BlockManagerMaster) - Registered BlockManager
2016-06-13 14:00:35,407  WARN [Remote-akka.actor.default-dispatcher-15] (com.jcabi.aether.Aether) - mirrors: []
2016-06-13 14:00:35,417  INFO [Remote-akka.actor.default-dispatcher-15] (Aether downloads) - 
Resolved/Downloaded:
* org.jsoup:jsoup:jar:1.7.2
===================================================

2016-06-13 14:00:35,672  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2016-06-13 14:00:35,674  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-06-13 14:00:35,676  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/api,null}
2016-06-13 14:00:35,677  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/,null}
2016-06-13 14:00:35,680  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/static,null}
2016-06-13 14:00:35,682  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-06-13 14:00:35,684  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2016-06-13 14:00:35,685  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2016-06-13 14:00:35,687  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors,null}
2016-06-13 14:00:35,690  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2016-06-13 14:00:35,692  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/environment,null}
2016-06-13 14:00:35,694  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-06-13 14:00:35,696  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2016-06-13 14:00:35,698  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2016-06-13 14:00:35,700  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage,null}
2016-06-13 14:00:35,710  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2016-06-13 14:00:35,712  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2016-06-13 14:00:35,717  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2016-06-13 14:00:35,717  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2016-06-13 14:00:35,723  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2016-06-13 14:00:35,725  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages,null}
2016-06-13 14:00:35,726  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2016-06-13 14:00:35,728  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2016-06-13 14:00:35,729  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2016-06-13 14:00:35,731  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2016-06-13 14:00:35,783  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.ui.SparkUI) - Stopped Spark web UI at http://localhost:4040
2016-06-13 14:00:35,789  INFO [dispatcher-event-loop-2] (org.apache.spark.MapOutputTrackerMasterEndpoint) - MapOutputTrackerMasterEndpoint stopped!
2016-06-13 14:00:35,805  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.MemoryStore) - MemoryStore cleared
2016-06-13 14:00:35,805  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.BlockManager) - BlockManager stopped
2016-06-13 14:00:35,806  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.BlockManagerMaster) - BlockManagerMaster stopped
2016-06-13 14:00:35,807  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint) - OutputCommitCoordinator stopped!
2016-06-13 14:00:35,817  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkContext) - Successfully stopped SparkContext
2016-06-13 14:00:35,823  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-16] (akka.remote.RemoteActorRefProvider$RemotingTerminator) - Shutting down remote daemon.
2016-06-13 14:00:35,823  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-16] (akka.remote.RemoteActorRefProvider$RemotingTerminator) - Remote daemon shut down; proceeding with flushing remote transports.
2016-06-13 14:00:35,847  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-17] (akka.remote.RemoteActorRefProvider$RemotingTerminator) - Remoting shut down.
2016-06-13 14:00:36,045  INFO [Remote-akka.actor.default-dispatcher-16] (notebook.client.ReplCalculator) - 
2016-06-13 14:00:36,045  INFO [Remote-akka.actor.default-dispatcher-16] (notebook.client.ReplCalculator) - CP reload processed successfully
2016-06-13 14:00:36,063  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SecurityManager) - Changing view acls to: jatin
2016-06-13 14:00:36,064  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SecurityManager) - Changing modify acls to: jatin
2016-06-13 14:00:36,064  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SecurityManager) - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jatin); users with modify permissions: Set(jatin)
2016-06-13 14:00:36,070  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.HttpServer) - Starting HTTP Server
2016-06-13 14:00:36,071  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.Server) - jetty-8.y.z-SNAPSHOT
2016-06-13 14:00:36,073  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.AbstractConnector) - Started SocketConnector@0.0.0.0:44411
2016-06-13 14:00:36,073  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.util.Utils) - Successfully started service 'HTTP server' on port 44411.
2016-06-13 14:00:36,586  INFO [Remote-akka.actor.default-dispatcher-16] (notebook.client.ReplCalculator) - ReplCalculator preStart
2016-06-13 14:00:36,586  INFO [Remote-akka.actor.default-dispatcher-16] (notebook.client.ReplCalculator) -  INIT SCRIPT: dummy
2016-06-13 14:00:37,433  INFO [Remote-akka.actor.default-dispatcher-16] (notebook.client.ReplCalculator) - Init script processed successfully
2016-06-13 14:00:37,433  INFO [Remote-akka.actor.default-dispatcher-16] (notebook.client.ReplCalculator) -  INIT SCRIPT: class server
2016-06-13 14:00:37,631  INFO [Remote-akka.actor.default-dispatcher-16] (notebook.client.ReplCalculator) - Init script processed successfully
2016-06-13 14:00:37,631  INFO [Remote-akka.actor.default-dispatcher-16] (notebook.client.ReplCalculator) -  INIT SCRIPT: deps
2016-06-13 14:00:37,857  INFO [Remote-akka.actor.default-dispatcher-16] (notebook.client.ReplCalculator) - Init script processed successfully
2016-06-13 14:00:37,857  INFO [Remote-akka.actor.default-dispatcher-16] (notebook.client.ReplCalculator) -  INIT SCRIPT: imports
2016-06-13 14:00:37,857  INFO [Remote-akka.actor.default-dispatcher-16] (notebook.client.ReplCalculator) -  INIT SCRIPT: custom conf
2016-06-13 14:00:38,296  INFO [Remote-akka.actor.default-dispatcher-3] (notebook.client.ReplCalculator) - Init script processed successfully
2016-06-13 14:00:38,296  INFO [Remote-akka.actor.default-dispatcher-3] (notebook.client.ReplCalculator) -  INIT SCRIPT: jar:file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/lib/nooostab.spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet.jar!/scripts/init.sc
2016-06-13 14:00:39,371  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkContext) - Running Spark version 1.6.0
2016-06-13 14:00:39,372  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SecurityManager) - Changing view acls to: jatin
2016-06-13 14:00:39,372  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SecurityManager) - Changing modify acls to: jatin
2016-06-13 14:00:39,372  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SecurityManager) - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jatin); users with modify permissions: Set(jatin)
2016-06-13 14:00:39,398  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.util.Utils) - Successfully started service 'sparkDriver' on port 46344.
2016-06-13 14:00:39,433  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-2] (akka.event.slf4j.Slf4jLogger) - Slf4jLogger started
2016-06-13 14:00:39,436  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-3] (Remoting) - Starting remoting
2016-06-13 14:00:39,454  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-2] (Remoting) - Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:32887]
2016-06-13 14:00:39,455  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.util.Utils) - Successfully started service 'sparkDriverActorSystem' on port 32887.
2016-06-13 14:00:39,455  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkEnv) - Registering MapOutputTracker
2016-06-13 14:00:39,458  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkEnv) - Registering BlockManagerMaster
2016-06-13 14:00:39,458  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.DiskBlockManager) - Created local directory at /tmp/blockmgr-4b1da70c-bc45-42ac-a02f-abfb33003ba5
2016-06-13 14:00:39,459  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.MemoryStore) - MemoryStore started with capacity 9.8 GB
2016-06-13 14:00:39,463  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkEnv) - Registering OutputCommitCoordinator
2016-06-13 14:00:39,479  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.Server) - jetty-8.y.z-SNAPSHOT
2016-06-13 14:00:39,491  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.AbstractConnector) - Started SelectChannelConnector@0.0.0.0:4040
2016-06-13 14:00:39,491  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.util.Utils) - Successfully started service 'SparkUI' on port 4040.
2016-06-13 14:00:39,492  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.ui.SparkUI) - Started SparkUI at http://localhost:4040
2016-06-13 14:00:39,527  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.HttpFileServer) - HTTP File server directory is /tmp/spark-7d3d95e2-3c3c-4cca-8ce7-ed84b038ccf3/httpd-1988bfcc-0376-4c05-a0c8-04cb2555ca8d
2016-06-13 14:00:39,527  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.HttpServer) - Starting HTTP Server
2016-06-13 14:00:39,528  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.Server) - jetty-8.y.z-SNAPSHOT
2016-06-13 14:00:39,539  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.AbstractConnector) - Started SocketConnector@0.0.0.0:44856
2016-06-13 14:00:39,539  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.util.Utils) - Successfully started service 'HTTP file server' on port 44856.
2016-06-13 14:00:39,539 ERROR [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkContext) - Error adding jar (java.lang.IllegalArgumentException: /home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet cannot be a directory.), was the --addJars option used?
2016-06-13 14:00:39,541  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkContext) - Added JAR file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/lib/common.common-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet.jar at http://localhost:44856/jars/common.common-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet.jar with timestamp 1465806639541
2016-06-13 14:00:39,553  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.executor.Executor) - Starting executor ID driver on host localhost
2016-06-13 14:00:39,553  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.executor.Executor) - Using REPL class URI: http://localhost:44411
2016-06-13 14:00:39,573  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.util.Utils) - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42556.
2016-06-13 14:00:39,573  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.network.netty.NettyBlockTransferService) - Server created on 42556
2016-06-13 14:00:39,573  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.BlockManagerMaster) - Trying to register BlockManager
2016-06-13 14:00:39,574  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerMasterEndpoint) - Registering block manager localhost:42556 with 9.8 GB RAM, BlockManagerId(driver, localhost, 42556)
2016-06-13 14:00:39,574  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.BlockManagerMaster) - Registered BlockManager
2016-06-13 14:00:40,250  INFO [Remote-akka.actor.default-dispatcher-3] (notebook.client.ReplCalculator) - Init script processed successfully
2016-06-13 14:00:41,332  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2016-06-13 14:00:41,333  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-06-13 14:00:41,334  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/api,null}
2016-06-13 14:00:41,334  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/,null}
2016-06-13 14:00:41,335  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/static,null}
2016-06-13 14:00:41,335  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-06-13 14:00:41,335  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2016-06-13 14:00:41,335  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2016-06-13 14:00:41,336  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors,null}
2016-06-13 14:00:41,336  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2016-06-13 14:00:41,336  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/environment,null}
2016-06-13 14:00:41,336  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-06-13 14:00:41,336  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2016-06-13 14:00:41,337  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2016-06-13 14:00:41,337  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage,null}
2016-06-13 14:00:41,337  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2016-06-13 14:00:41,337  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2016-06-13 14:00:41,338  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2016-06-13 14:00:41,338  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2016-06-13 14:00:41,338  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2016-06-13 14:00:41,338  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages,null}
2016-06-13 14:00:41,339  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2016-06-13 14:00:41,339  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2016-06-13 14:00:41,339  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2016-06-13 14:00:41,339  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2016-06-13 14:00:41,392  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.ui.SparkUI) - Stopped Spark web UI at http://localhost:4040
2016-06-13 14:00:41,395  INFO [dispatcher-event-loop-1] (org.apache.spark.MapOutputTrackerMasterEndpoint) - MapOutputTrackerMasterEndpoint stopped!
2016-06-13 14:00:41,415  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.MemoryStore) - MemoryStore cleared
2016-06-13 14:00:41,415  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.BlockManager) - BlockManager stopped
2016-06-13 14:00:41,416  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.BlockManagerMaster) - BlockManagerMaster stopped
2016-06-13 14:00:41,416  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint) - OutputCommitCoordinator stopped!
2016-06-13 14:00:41,418  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-3] (akka.remote.RemoteActorRefProvider$RemotingTerminator) - Shutting down remote daemon.
2016-06-13 14:00:41,418  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-3] (akka.remote.RemoteActorRefProvider$RemotingTerminator) - Remote daemon shut down; proceeding with flushing remote transports.
2016-06-13 14:00:41,423  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkContext) - Successfully stopped SparkContext
2016-06-13 14:00:41,454  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-2] (akka.remote.RemoteActorRefProvider$RemotingTerminator) - Remoting shut down.
2016-06-13 14:00:42,052  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkContext) - SparkContext already stopped.
2016-06-13 14:00:42,064  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkContext) - Running Spark version 1.6.0
2016-06-13 14:00:42,066  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SecurityManager) - Changing view acls to: jatin
2016-06-13 14:00:42,066  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SecurityManager) - Changing modify acls to: jatin
2016-06-13 14:00:42,066  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SecurityManager) - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jatin); users with modify permissions: Set(jatin)
2016-06-13 14:00:42,084  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.util.Utils) - Successfully started service 'sparkDriver' on port 41949.
2016-06-13 14:00:42,101  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-3] (akka.event.slf4j.Slf4jLogger) - Slf4jLogger started
2016-06-13 14:00:42,108  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-8] (Remoting) - Starting remoting
2016-06-13 14:00:42,138  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.util.Utils) - Successfully started service 'sparkDriverActorSystem' on port 35316.
2016-06-13 14:00:42,139  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-6] (Remoting) - Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:35316]
2016-06-13 14:00:42,142  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkEnv) - Registering MapOutputTracker
2016-06-13 14:00:42,143  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkEnv) - Registering BlockManagerMaster
2016-06-13 14:00:42,144  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.DiskBlockManager) - Created local directory at /tmp/blockmgr-f89931fd-0e58-4a99-a5d2-2a11433cb0c1
2016-06-13 14:00:42,144  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.MemoryStore) - MemoryStore started with capacity 9.8 GB
2016-06-13 14:00:42,148  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkEnv) - Registering OutputCommitCoordinator
2016-06-13 14:00:42,162  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.Server) - jetty-8.y.z-SNAPSHOT
2016-06-13 14:00:42,179  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.AbstractConnector) - Started SelectChannelConnector@0.0.0.0:4040
2016-06-13 14:00:42,179  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.util.Utils) - Successfully started service 'SparkUI' on port 4040.
2016-06-13 14:00:42,179  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.ui.SparkUI) - Started SparkUI at http://localhost:4040
2016-06-13 14:00:42,205  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.HttpFileServer) - HTTP File server directory is /tmp/spark-7d3d95e2-3c3c-4cca-8ce7-ed84b038ccf3/httpd-9f7dcf6b-1bd2-4a5a-a2ad-7d10ea552d84
2016-06-13 14:00:42,206  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.HttpServer) - Starting HTTP Server
2016-06-13 14:00:42,206  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.Server) - jetty-8.y.z-SNAPSHOT
2016-06-13 14:00:42,214  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.AbstractConnector) - Started SocketConnector@0.0.0.0:36997
2016-06-13 14:00:42,214  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.util.Utils) - Successfully started service 'HTTP file server' on port 36997.
2016-06-13 14:00:42,215  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkContext) - Added JAR /home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/repo/org/jsoup/jsoup/1.7.2/jsoup-1.7.2.jar at http://localhost:36997/jars/jsoup-1.7.2.jar with timestamp 1465806642215
2016-06-13 14:00:42,215 ERROR [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkContext) - Error adding jar (java.lang.IllegalArgumentException: /home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet cannot be a directory.), was the --addJars option used?
2016-06-13 14:00:42,217  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkContext) - Added JAR file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/lib/common.common-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet.jar at http://localhost:36997/jars/common.common-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet.jar with timestamp 1465806642217
2016-06-13 14:00:42,238  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.executor.Executor) - Starting executor ID driver on host localhost
2016-06-13 14:00:42,238  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.executor.Executor) - Using REPL class URI: http://localhost:44411
2016-06-13 14:00:42,259  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.util.Utils) - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43985.
2016-06-13 14:00:42,259  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.network.netty.NettyBlockTransferService) - Server created on 43985
2016-06-13 14:00:42,259  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.BlockManagerMaster) - Trying to register BlockManager
2016-06-13 14:00:42,259  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerMasterEndpoint) - Registering block manager localhost:43985 with 9.8 GB RAM, BlockManagerId(driver, localhost, 43985)
2016-06-13 14:00:42,263  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.BlockManagerMaster) - Registered BlockManager
2016-06-13 14:00:43,456  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/metrics/json,null}
2016-06-13 14:00:43,457  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/stage/kill,null}
2016-06-13 14:00:43,459  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/api,null}
2016-06-13 14:00:43,471  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/,null}
2016-06-13 14:00:43,474  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/static,null}
2016-06-13 14:00:43,474  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors/threadDump/json,null}
2016-06-13 14:00:43,475  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors/threadDump,null}
2016-06-13 14:00:43,475  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors/json,null}
2016-06-13 14:00:43,494  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/executors,null}
2016-06-13 14:00:43,497  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/environment/json,null}
2016-06-13 14:00:43,498  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/environment,null}
2016-06-13 14:00:43,500  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage/rdd/json,null}
2016-06-13 14:00:43,501  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage/rdd,null}
2016-06-13 14:00:43,503  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage/json,null}
2016-06-13 14:00:43,504  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/storage,null}
2016-06-13 14:00:43,507  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/pool/json,null}
2016-06-13 14:00:43,508  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/pool,null}
2016-06-13 14:00:43,510  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/stage/json,null}
2016-06-13 14:00:43,511  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/stage,null}
2016-06-13 14:00:43,512  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages/json,null}
2016-06-13 14:00:43,514  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/stages,null}
2016-06-13 14:00:43,515  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs/job/json,null}
2016-06-13 14:00:43,525  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs/job,null}
2016-06-13 14:00:43,529  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs/json,null}
2016-06-13 14:00:43,535  INFO [Remote-akka.actor.default-dispatcher-15] (org.spark-project.jetty.server.handler.ContextHandler) - stopped o.s.j.s.ServletContextHandler{/jobs,null}
2016-06-13 14:00:43,591  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.ui.SparkUI) - Stopped Spark web UI at http://localhost:4040
2016-06-13 14:00:43,597  INFO [dispatcher-event-loop-2] (org.apache.spark.MapOutputTrackerMasterEndpoint) - MapOutputTrackerMasterEndpoint stopped!
2016-06-13 14:00:43,619  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.MemoryStore) - MemoryStore cleared
2016-06-13 14:00:43,619  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.BlockManager) - BlockManager stopped
2016-06-13 14:00:43,620  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.BlockManagerMaster) - BlockManagerMaster stopped
2016-06-13 14:00:43,620  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint) - OutputCommitCoordinator stopped!
2016-06-13 14:00:43,624  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-2] (akka.remote.RemoteActorRefProvider$RemotingTerminator) - Shutting down remote daemon.
2016-06-13 14:00:43,624  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-2] (akka.remote.RemoteActorRefProvider$RemotingTerminator) - Remote daemon shut down; proceeding with flushing remote transports.
2016-06-13 14:00:43,666  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkContext) - Successfully stopped SparkContext
2016-06-13 14:00:43,677  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-7] (akka.remote.RemoteActorRefProvider$RemotingTerminator) - Remoting shut down.
2016-06-13 14:00:44,297  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.SparkContext) - SparkContext already stopped.
2016-06-13 14:00:44,298  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.SparkContext) - Running Spark version 1.6.0
2016-06-13 14:00:44,299  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.SecurityManager) - Changing view acls to: jatin
2016-06-13 14:00:44,300  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.SecurityManager) - Changing modify acls to: jatin
2016-06-13 14:00:44,301  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.SecurityManager) - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jatin); users with modify permissions: Set(jatin)
2016-06-13 14:00:44,321  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.util.Utils) - Successfully started service 'sparkDriver' on port 39080.
2016-06-13 14:00:44,343  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-3] (akka.event.slf4j.Slf4jLogger) - Slf4jLogger started
2016-06-13 14:00:44,346  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-5] (Remoting) - Starting remoting
2016-06-13 14:00:44,354  INFO [sparkDriverActorSystem-akka.actor.default-dispatcher-12] (Remoting) - Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:38914]
2016-06-13 14:00:44,355  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.util.Utils) - Successfully started service 'sparkDriverActorSystem' on port 38914.
2016-06-13 14:00:44,356  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.SparkEnv) - Registering MapOutputTracker
2016-06-13 14:00:44,357  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.SparkEnv) - Registering BlockManagerMaster
2016-06-13 14:00:44,357  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.storage.DiskBlockManager) - Created local directory at /tmp/blockmgr-d63f44a9-b944-4e64-8277-3870e336ca76
2016-06-13 14:00:44,361  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.storage.MemoryStore) - MemoryStore started with capacity 9.8 GB
2016-06-13 14:00:44,364  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.SparkEnv) - Registering OutputCommitCoordinator
2016-06-13 14:00:44,395  INFO [Remote-akka.actor.default-dispatcher-3] (org.spark-project.jetty.server.Server) - jetty-8.y.z-SNAPSHOT
2016-06-13 14:00:44,402  INFO [Remote-akka.actor.default-dispatcher-3] (org.spark-project.jetty.server.AbstractConnector) - Started SelectChannelConnector@0.0.0.0:4040
2016-06-13 14:00:44,403  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.util.Utils) - Successfully started service 'SparkUI' on port 4040.
2016-06-13 14:00:44,403  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.ui.SparkUI) - Started SparkUI at http://localhost:4040
2016-06-13 14:00:44,428  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.HttpFileServer) - HTTP File server directory is /tmp/spark-7d3d95e2-3c3c-4cca-8ce7-ed84b038ccf3/httpd-8644bd5d-def2-4615-a473-ca219909a471
2016-06-13 14:00:44,428  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.HttpServer) - Starting HTTP Server
2016-06-13 14:00:44,429  INFO [Remote-akka.actor.default-dispatcher-3] (org.spark-project.jetty.server.Server) - jetty-8.y.z-SNAPSHOT
2016-06-13 14:00:44,433  INFO [Remote-akka.actor.default-dispatcher-3] (org.spark-project.jetty.server.AbstractConnector) - Started SocketConnector@0.0.0.0:40063
2016-06-13 14:00:44,433  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.util.Utils) - Successfully started service 'HTTP file server' on port 40063.
2016-06-13 14:00:44,434  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.SparkContext) - Added JAR /home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/repo/org/jsoup/jsoup/1.7.2/jsoup-1.7.2.jar at http://localhost:40063/jars/jsoup-1.7.2.jar with timestamp 1465806644434
2016-06-13 14:00:44,435 ERROR [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.SparkContext) - Error adding jar (java.lang.IllegalArgumentException: /home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet cannot be a directory.), was the --addJars option used?
2016-06-13 14:00:44,437  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.SparkContext) - Added JAR file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/lib/common.common-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet.jar at http://localhost:40063/jars/common.common-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet.jar with timestamp 1465806644437
2016-06-13 14:00:44,443  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.executor.Executor) - Starting executor ID driver on host localhost
2016-06-13 14:00:44,443  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.executor.Executor) - Using REPL class URI: http://localhost:44411
2016-06-13 14:00:44,453  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.util.Utils) - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44356.
2016-06-13 14:00:44,453  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.network.netty.NettyBlockTransferService) - Server created on 44356
2016-06-13 14:00:44,453  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.storage.BlockManagerMaster) - Trying to register BlockManager
2016-06-13 14:00:44,453  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerMasterEndpoint) - Registering block manager localhost:44356 with 9.8 GB RAM, BlockManagerId(driver, localhost, 44356)
2016-06-13 14:00:44,454  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.storage.BlockManagerMaster) - Registered BlockManager
2016-06-13 14:00:46,450  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.storage.MemoryStore) - Block broadcast_0 stored as values in memory (estimated size 107.8 KB, free 107.8 KB)
2016-06-13 14:00:46,480  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.storage.MemoryStore) - Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.9 KB, free 117.7 KB)
2016-06-13 14:00:46,482  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_0_piece0 in memory on localhost:44356 (size: 9.9 KB, free: 9.8 GB)
2016-06-13 14:00:46,486  INFO [Remote-akka.actor.default-dispatcher-2] (org.apache.spark.SparkContext) - Created broadcast 0 from textFile at <console>:50
2016-06-13 14:00:48,491  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.sql.execution.datasources.json.JSONRelation) - Listing file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/jobs_huge.json on driver
2016-06-13 14:00:48,534  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.storage.MemoryStore) - Block broadcast_1 stored as values in memory (estimated size 127.4 KB, free 245.1 KB)
2016-06-13 14:00:48,549  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.storage.MemoryStore) - Block broadcast_1_piece0 stored as bytes in memory (estimated size 13.8 KB, free 258.9 KB)
2016-06-13 14:00:48,549  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_1_piece0 in memory on localhost:44356 (size: 13.8 KB, free: 9.8 GB)
2016-06-13 14:00:48,551  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.SparkContext) - Created broadcast 1 from json at <console>:54
2016-06-13 14:00:49,483  INFO [Remote-akka.actor.default-dispatcher-16] (org.apache.spark.storage.MemoryStore) - Block broadcast_2 stored as values in memory (estimated size 23.8 KB, free 282.7 KB)
2016-06-13 14:00:49,486  INFO [Remote-akka.actor.default-dispatcher-16] (org.apache.spark.storage.MemoryStore) - Block broadcast_2_piece0 stored as bytes in memory (estimated size 1991.0 B, free 284.7 KB)
2016-06-13 14:00:49,487  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_2_piece0 in memory on localhost:44356 (size: 1991.0 B, free: 9.8 GB)
2016-06-13 14:00:49,488  INFO [Remote-akka.actor.default-dispatcher-16] (org.apache.spark.SparkContext) - Created broadcast 2 from broadcast at <console>:93
2016-06-13 14:00:51,423  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_1_piece0 on localhost:44356 in memory (size: 13.8 KB, free: 9.8 GB)
2016-06-13 14:00:52,592  INFO [Remote-akka.actor.default-dispatcher-4] (org.apache.spark.sql.execution.datasources.json.JSONRelation) - Listing file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/user_history_only.json on driver
2016-06-13 14:00:52,603  INFO [Remote-akka.actor.default-dispatcher-4] (org.apache.spark.storage.MemoryStore) - Block broadcast_3 stored as values in memory (estimated size 127.4 KB, free 270.9 KB)
2016-06-13 14:00:52,635  INFO [Remote-akka.actor.default-dispatcher-4] (org.apache.spark.storage.MemoryStore) - Block broadcast_3_piece0 stored as bytes in memory (estimated size 13.8 KB, free 284.7 KB)
2016-06-13 14:00:52,636  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_3_piece0 in memory on localhost:44356 (size: 13.8 KB, free: 9.8 GB)
2016-06-13 14:00:52,640  INFO [Remote-akka.actor.default-dispatcher-4] (org.apache.spark.SparkContext) - Created broadcast 3 from json at <console>:60
2016-06-13 14:00:53,135  INFO [Remote-akka.actor.default-dispatcher-4] (org.apache.spark.sql.execution.datasources.json.JSONRelation) - Listing file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/user_profile_history.json on driver
2016-06-13 14:00:53,144  INFO [Remote-akka.actor.default-dispatcher-4] (org.apache.spark.storage.MemoryStore) - Block broadcast_4 stored as values in memory (estimated size 127.4 KB, free 412.0 KB)
2016-06-13 14:00:53,155  INFO [Remote-akka.actor.default-dispatcher-4] (org.apache.spark.storage.MemoryStore) - Block broadcast_4_piece0 stored as bytes in memory (estimated size 13.8 KB, free 425.8 KB)
2016-06-13 14:00:53,156  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_4_piece0 in memory on localhost:44356 (size: 13.8 KB, free: 9.8 GB)
2016-06-13 14:00:53,158  INFO [Remote-akka.actor.default-dispatcher-4] (org.apache.spark.SparkContext) - Created broadcast 4 from json at <console>:60
2016-06-13 14:00:53,618  INFO [Remote-akka.actor.default-dispatcher-4] (org.apache.spark.sql.execution.datasources.json.JSONRelation) - Listing file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/user_profiles_only.json on driver
2016-06-13 14:00:53,629  INFO [Remote-akka.actor.default-dispatcher-4] (org.apache.spark.storage.MemoryStore) - Block broadcast_5 stored as values in memory (estimated size 127.4 KB, free 553.1 KB)
2016-06-13 14:00:53,646  INFO [Remote-akka.actor.default-dispatcher-4] (org.apache.spark.storage.MemoryStore) - Block broadcast_5_piece0 stored as bytes in memory (estimated size 13.8 KB, free 566.9 KB)
2016-06-13 14:00:53,650  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_5_piece0 in memory on localhost:44356 (size: 13.8 KB, free: 9.8 GB)
2016-06-13 14:00:53,653  INFO [Remote-akka.actor.default-dispatcher-4] (org.apache.spark.SparkContext) - Created broadcast 5 from json at <console>:61
2016-06-13 14:02:28,778  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.MemoryStore) - Block broadcast_6 stored as values in memory (estimated size 127.3 KB, free 694.2 KB)
2016-06-13 14:02:28,789  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.MemoryStore) - Block broadcast_6_piece0 stored as bytes in memory (estimated size 13.8 KB, free 708.0 KB)
2016-06-13 14:02:28,790  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_6_piece0 in memory on localhost:44356 (size: 13.8 KB, free: 9.8 GB)
2016-06-13 14:02:28,791  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkContext) - Created broadcast 6 from textFile at <console>:65
2016-06-13 14:03:49,159  INFO [Remote-akka.actor.default-dispatcher-21] (org.apache.spark.storage.MemoryStore) - Block broadcast_7 stored as values in memory (estimated size 127.3 KB, free 835.4 KB)
2016-06-13 14:03:49,170  INFO [Remote-akka.actor.default-dispatcher-21] (org.apache.spark.storage.MemoryStore) - Block broadcast_7_piece0 stored as bytes in memory (estimated size 13.8 KB, free 849.2 KB)
2016-06-13 14:03:49,171  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_7_piece0 in memory on localhost:44356 (size: 13.8 KB, free: 9.8 GB)
2016-06-13 14:03:49,172  INFO [Remote-akka.actor.default-dispatcher-21] (org.apache.spark.SparkContext) - Created broadcast 7 from textFile at <console>:69
2016-06-13 14:03:49,189  INFO [Remote-akka.actor.default-dispatcher-21] (org.apache.hadoop.mapred.FileInputFormat) - Total input paths to process : 1
2016-06-13 14:03:49,209  INFO [Remote-akka.actor.default-dispatcher-21] (org.apache.spark.SparkContext) - Starting job: count at <console>:72
2016-06-13 14:03:49,228  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 0 (count at <console>:72) with 2 output partitions
2016-06-13 14:03:49,229  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 0 (count at <console>:72)
2016-06-13 14:03:49,229  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:03:49,235  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:03:49,242  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 0 (MapPartitionsRDD[17] at textFile at <console>:69), which has no missing parents
2016-06-13 14:03:49,283  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_8 stored as values in memory (estimated size 2.8 KB, free 852.0 KB)
2016-06-13 14:03:49,285  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_8_piece0 stored as bytes in memory (estimated size 1701.0 B, free 853.6 KB)
2016-06-13 14:03:49,288  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_8_piece0 in memory on localhost:44356 (size: 1701.0 B, free: 9.8 GB)
2016-06-13 14:03:49,289  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 8 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:03:49,294  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[17] at textFile at <console>:69)
2016-06-13 14:03:49,296  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 0.0 with 2 tasks
2016-06-13 14:03:49,370  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:03:49,373  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:03:49,381  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 0.0 (TID 0)
2016-06-13 14:03:49,386  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 0.0 (TID 1)
2016-06-13 14:03:49,388  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Fetching http://localhost:40063/jars/common.common-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet.jar with timestamp 1465806644437
2016-06-13 14:03:49,482  INFO [Executor task launch worker-0] (org.apache.spark.util.Utils) - Fetching http://localhost:40063/jars/common.common-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet.jar to /tmp/spark-7d3d95e2-3c3c-4cca-8ce7-ed84b038ccf3/userFiles-8aa9fc7f-25fc-4fcf-ae3e-116f983bde0d/fetchFileTemp7387738656889488347.tmp
2016-06-13 14:03:49,495  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Adding file:/tmp/spark-7d3d95e2-3c3c-4cca-8ce7-ed84b038ccf3/userFiles-8aa9fc7f-25fc-4fcf-ae3e-116f983bde0d/common.common-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet.jar to class loader
2016-06-13 14:03:49,495  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Fetching http://localhost:40063/jars/jsoup-1.7.2.jar with timestamp 1465806644434
2016-06-13 14:03:49,498  INFO [Executor task launch worker-0] (org.apache.spark.util.Utils) - Fetching http://localhost:40063/jars/jsoup-1.7.2.jar to /tmp/spark-7d3d95e2-3c3c-4cca-8ce7-ed84b038ccf3/userFiles-8aa9fc7f-25fc-4fcf-ae3e-116f983bde0d/fetchFileTemp2657939890339843460.tmp
2016-06-13 14:03:49,506  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Adding file:/tmp/spark-7d3d95e2-3c3c-4cca-8ce7-ed84b038ccf3/userFiles-8aa9fc7f-25fc-4fcf-ae3e-116f983bde0d/jsoup-1.7.2.jar to class loader
2016-06-13 14:03:49,528  INFO [Executor task launch worker-0] (org.apache.spark.CacheManager) - Partition rdd_17_0 not found, computing it
2016-06-13 14:03:49,529  INFO [Executor task launch worker-1] (org.apache.spark.CacheManager) - Partition rdd_17_1 not found, computing it
2016-06-13 14:03:49,534  INFO [Executor task launch worker-1] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/jobs_huge.json:15446251+15446251
2016-06-13 14:03:49,537  INFO [Executor task launch worker-0] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/jobs_huge.json:0+15446251
2016-06-13 14:03:49,554  INFO [Executor task launch worker-1] (org.apache.hadoop.conf.Configuration.deprecation) - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-06-13 14:03:49,554  INFO [Executor task launch worker-1] (org.apache.hadoop.conf.Configuration.deprecation) - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2016-06-13 14:03:49,554  INFO [Executor task launch worker-1] (org.apache.hadoop.conf.Configuration.deprecation) - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2016-06-13 14:03:49,554  INFO [Executor task launch worker-1] (org.apache.hadoop.conf.Configuration.deprecation) - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2016-06-13 14:03:49,554  INFO [Executor task launch worker-1] (org.apache.hadoop.conf.Configuration.deprecation) - mapred.job.id is deprecated. Instead, use mapreduce.job.id
2016-06-13 14:03:49,559  INFO [Executor task launch worker-0] (org.apache.hadoop.conf.Configuration.deprecation) - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2016-06-13 14:03:49,880  INFO [Executor task launch worker-1] (org.apache.spark.storage.MemoryStore) - Block rdd_17_1 stored as values in memory (estimated size 27.9 MB, free 28.8 MB)
2016-06-13 14:03:49,881  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added rdd_17_1 in memory on localhost:44356 (size: 27.9 MB, free: 9.8 GB)
2016-06-13 14:03:49,889  INFO [Executor task launch worker-0] (org.apache.spark.storage.MemoryStore) - Block rdd_17_0 stored as values in memory (estimated size 27.7 MB, free 56.5 MB)
2016-06-13 14:03:49,889  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added rdd_17_0 in memory on localhost:44356 (size: 27.7 MB, free: 9.7 GB)
2016-06-13 14:03:49,892  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 0.0 (TID 0). 2581 bytes result sent to driver
2016-06-13 14:03:49,896  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 0.0 (TID 1). 2581 bytes result sent to driver
2016-06-13 14:03:49,900  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 0.0 (TID 0) in 553 ms on localhost (1/2)
2016-06-13 14:03:49,902  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 0.0 (TID 1) in 530 ms on localhost (2/2)
2016-06-13 14:03:49,904  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2016-06-13 14:03:49,905  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 0 (count at <console>:72) finished in 0.580 s
2016-06-13 14:03:49,910  INFO [Remote-akka.actor.default-dispatcher-21] (org.apache.spark.scheduler.DAGScheduler) - Job 0 finished: count at <console>:72, took 0.699007 s
2016-06-13 14:03:52,521  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_8_piece0 on localhost:44356 in memory (size: 1701.0 B, free: 9.7 GB)
2016-06-13 14:03:52,529  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 1
2016-06-13 14:03:52,530  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_5_piece0 on localhost:44356 in memory (size: 13.8 KB, free: 9.7 GB)
2016-06-13 14:03:52,535  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_4_piece0 on localhost:44356 in memory (size: 13.8 KB, free: 9.7 GB)
2016-06-13 14:03:52,551  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_3_piece0 on localhost:44356 in memory (size: 13.8 KB, free: 9.7 GB)
2016-06-13 14:03:53,707  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.sql.execution.datasources.json.JSONRelation) - Listing file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/jobs_huge.json on driver
2016-06-13 14:03:53,724  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_9 stored as values in memory (estimated size 128.2 KB, free 56.2 MB)
2016-06-13 14:03:53,737  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_9_piece0 stored as bytes in memory (estimated size 14.2 KB, free 56.2 MB)
2016-06-13 14:03:53,738  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_9_piece0 in memory on localhost:44356 (size: 14.2 KB, free: 9.7 GB)
2016-06-13 14:03:53,739  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Created broadcast 9 from json at <console>:73
2016-06-13 14:03:53,748  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.hadoop.mapred.FileInputFormat) - Total input paths to process : 1
2016-06-13 14:03:53,771  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Starting job: json at <console>:73
2016-06-13 14:03:53,772  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 1 (json at <console>:73) with 2 output partitions
2016-06-13 14:03:53,772  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 1 (json at <console>:73)
2016-06-13 14:03:53,772  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:03:53,772  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:03:53,772  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 1 (MapPartitionsRDD[21] at json at <console>:73), which has no missing parents
2016-06-13 14:03:53,774  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_10 stored as values in memory (estimated size 4.2 KB, free 56.2 MB)
2016-06-13 14:03:53,775  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.4 KB, free 56.2 MB)
2016-06-13 14:03:53,775  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_10_piece0 in memory on localhost:44356 (size: 2.4 KB, free: 9.7 GB)
2016-06-13 14:03:53,776  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 10 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:03:53,776  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[21] at json at <console>:73)
2016-06-13 14:03:53,776  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 1.0 with 2 tasks
2016-06-13 14:03:53,783  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 1.0 (TID 2, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:03:53,784  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 1.0 (TID 3, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:03:53,785  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 1.0 (TID 3)
2016-06-13 14:03:53,785  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 1.0 (TID 2)
2016-06-13 14:03:53,790  INFO [Executor task launch worker-1] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/jobs_huge.json:0+15446251
2016-06-13 14:03:53,790  INFO [Executor task launch worker-0] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/jobs_huge.json:15446251+15446251
2016-06-13 14:03:54,238  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 1.0 (TID 2). 3140 bytes result sent to driver
2016-06-13 14:03:54,241  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 1.0 (TID 2) in 458 ms on localhost (1/2)
2016-06-13 14:03:54,245  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 1.0 (TID 3). 3140 bytes result sent to driver
2016-06-13 14:03:54,248  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 1.0 (TID 3) in 465 ms on localhost (2/2)
2016-06-13 14:03:54,248  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 1 (json at <console>:73) finished in 0.465 s
2016-06-13 14:03:54,249  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2016-06-13 14:03:54,249  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.scheduler.DAGScheduler) - Job 1 finished: json at <console>:73, took 0.478079 s
2016-06-13 14:03:55,733  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_10_piece0 on localhost:44356 in memory (size: 2.4 KB, free: 9.7 GB)
2016-06-13 14:03:55,734  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 2
2016-06-13 14:03:55,734  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_9_piece0 on localhost:44356 in memory (size: 14.2 KB, free: 9.7 GB)
2016-06-13 14:03:55,782  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_11 stored as values in memory (estimated size 59.6 KB, free 56.1 MB)
2016-06-13 14:03:55,822  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_11_piece0 stored as bytes in memory (estimated size 13.8 KB, free 56.1 MB)
2016-06-13 14:03:55,823  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_11_piece0 in memory on localhost:44356 (size: 13.8 KB, free: 9.7 GB)
2016-06-13 14:03:55,824  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Created broadcast 11 from cache at <console>:73
2016-06-13 14:03:55,851  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_12 stored as values in memory (estimated size 128.2 KB, free 56.3 MB)
2016-06-13 14:03:55,860  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_12_piece0 stored as bytes in memory (estimated size 14.2 KB, free 56.3 MB)
2016-06-13 14:03:55,860  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_12_piece0 in memory on localhost:44356 (size: 14.2 KB, free: 9.7 GB)
2016-06-13 14:03:55,861  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Created broadcast 12 from cache at <console>:73
2016-06-13 14:03:56,157 ERROR [Remote-akka.actor.default-dispatcher-17] (notebook.kernel.Repl) - Ooops, exception in the cell
java.lang.ExceptionInInitializerError
	at sun.misc.Unsafe.ensureClassInitialized(Native Method)
	at sun.reflect.UnsafeFieldAccessorFactory.newFieldAccessor(UnsafeFieldAccessorFactory.java:43)
	at sun.reflect.ReflectionFactory.newFieldAccessor(ReflectionFactory.java:142)
	at java.lang.reflect.Field.acquireFieldAccessor(Field.java:1088)
	at java.lang.reflect.Field.getFieldAccessor(Field.java:1069)
	at java.lang.reflect.Field.get(Field.java:393)
	at notebook.kernel.Repl.getModule$1(Repl.scala:203)
	at notebook.kernel.Repl.iws$1(Repl.scala:212)
	at notebook.kernel.Repl.liftedTree1$1(Repl.scala:219)
	at notebook.kernel.Repl.evaluate(Repl.scala:199)
	at notebook.client.ReplCalculator$$anonfun$15$$anon$1$$anonfun$29.apply(ReplCalculator.scala:378)
	at notebook.client.ReplCalculator$$anonfun$15$$anon$1$$anonfun$29.apply(ReplCalculator.scala:375)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: java.io.IOException: java.lang.NoSuchMethodException: org.apache.spark.io.SnappyCompressionCodec.<init>(org.apache.spark.SparkConf)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1222)
	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)
	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)
	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)
	at org.apache.spark.rdd.HadoopRDD.getJobConf(HadoopRDD.scala:144)
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:195)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.ZippedWithIndexRDD.<init>(ZippedWithIndexRDD.scala:44)
	at org.apache.spark.rdd.RDD$$anonfun$zipWithIndex$1.apply(RDD.scala:1258)
	at org.apache.spark.rdd.RDD$$anonfun$zipWithIndex$1.apply(RDD.scala:1258)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316)
	at org.apache.spark.rdd.RDD.zipWithIndex(RDD.scala:1257)
	at notebook.front.widgets.DataFrameView$class.notebook$front$widgets$DataFrameView$$json(DataFrame.scala:40)
	at notebook.front.widgets.DataFrameWidget.notebook$front$widgets$DataFrameView$$json$lzycompute(DataFrame.scala:64)
	at notebook.front.widgets.DataFrameWidget.notebook$front$widgets$DataFrameView$$json(DataFrame.scala:64)
	at notebook.front.widgets.DataFrameView$class.$init$(DataFrame.scala:41)
	at notebook.front.widgets.DataFrameWidget.<init>(DataFrame.scala:69)
	at notebook.front.ExtraLowPriorityRenderers$dataFrameAsTable$.render(renderer.scala:13)
	at notebook.front.ExtraLowPriorityRenderers$dataFrameAsTable$.render(renderer.scala:12)
	at notebook.front.Widget$.fromRenderer(Widget.scala:32)
	at $line86.$rendered$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$.<init>(<console>:70)
	at $line86.$rendered$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$.<clinit>(<console>)
	... 20 more
Caused by: java.lang.NoSuchMethodException: org.apache.spark.io.SnappyCompressionCodec.<init>(org.apache.spark.SparkConf)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.spark.io.CompressionCodec$.createCodec(CompressionCodec.scala:71)
	at org.apache.spark.io.CompressionCodec$.createCodec(CompressionCodec.scala:65)
	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$setConf(TorrentBroadcast.scala:73)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:167)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1219)
	... 78 more
2016-06-13 14:03:57,072  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.hadoop.mapred.FileInputFormat) - Total input paths to process : 1
2016-06-13 14:03:57,076  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Starting job: show at <console>:74
2016-06-13 14:03:57,077  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 2 (show at <console>:74) with 1 output partitions
2016-06-13 14:03:57,077  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 2 (show at <console>:74)
2016-06-13 14:03:57,077  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:03:57,077  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:03:57,078  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 2 (MapPartitionsRDD[32] at show at <console>:74), which has no missing parents
2016-06-13 14:03:57,094  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_13 stored as values in memory (estimated size 11.6 KB, free 56.3 MB)
2016-06-13 14:03:57,095  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_13_piece0 stored as bytes in memory (estimated size 5.3 KB, free 56.3 MB)
2016-06-13 14:03:57,096  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_13_piece0 in memory on localhost:44356 (size: 5.3 KB, free: 9.7 GB)
2016-06-13 14:03:57,096  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 13 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:03:57,096  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[32] at show at <console>:74)
2016-06-13 14:03:57,096  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 2.0 with 1 tasks
2016-06-13 14:03:57,098  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 2.0 (TID 4, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:03:57,099  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 2.0 (TID 4)
2016-06-13 14:03:57,104  INFO [Executor task launch worker-0] (org.apache.spark.CacheManager) - Partition rdd_26_0 not found, computing it
2016-06-13 14:03:57,104  INFO [Executor task launch worker-0] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/jobs_huge.json:0+15446251
2016-06-13 14:03:57,360  INFO [Executor task launch worker-0] (org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection) - Code generated in 203.470592 ms
2016-06-13 14:03:57,879  INFO [Executor task launch worker-0] (org.apache.spark.storage.MemoryStore) - Block rdd_26_0 stored as values in memory (estimated size 14.4 MB, free 70.7 MB)
2016-06-13 14:03:57,880  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added rdd_26_0 in memory on localhost:44356 (size: 14.4 MB, free: 9.7 GB)
2016-06-13 14:03:57,894  INFO [Executor task launch worker-0] (org.apache.spark.sql.catalyst.expressions.codegen.GeneratePredicate) - Code generated in 7.829792 ms
2016-06-13 14:03:57,945  INFO [Executor task launch worker-0] (org.apache.spark.sql.execution.columnar.GenerateColumnAccessor) - Code generated in 40.819368 ms
2016-06-13 14:03:57,980  INFO [Executor task launch worker-0] (org.apache.spark.sql.catalyst.expressions.codegen.GenerateSafeProjection) - Code generated in 24.482322 ms
2016-06-13 14:03:57,996  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 2.0 (TID 4). 342775 bytes result sent to driver
2016-06-13 14:03:57,999  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 2.0 (TID 4) in 902 ms on localhost (1/1)
2016-06-13 14:03:57,999  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2016-06-13 14:03:57,999  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 2 (show at <console>:74) finished in 0.902 s
2016-06-13 14:03:57,999  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.scheduler.DAGScheduler) - Job 2 finished: show at <console>:74, took 0.923196 s
2016-06-13 14:04:06,236  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkContext) - Starting job: take at <console>:76
2016-06-13 14:04:06,237  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 3 (take at <console>:76) with 1 output partitions
2016-06-13 14:04:06,237  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 3 (take at <console>:76)
2016-06-13 14:04:06,237  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:06,241  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:06,241  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 3 (MapPartitionsRDD[33] at rdd at <console>:74), which has no missing parents
2016-06-13 14:04:06,244  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_14 stored as values in memory (estimated size 11.7 KB, free 70.7 MB)
2016-06-13 14:04:06,246  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_14_piece0 stored as bytes in memory (estimated size 5.4 KB, free 70.7 MB)
2016-06-13 14:04:06,249  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_14_piece0 in memory on localhost:44356 (size: 5.4 KB, free: 9.7 GB)
2016-06-13 14:04:06,252  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 14 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:06,253  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[33] at rdd at <console>:74)
2016-06-13 14:04:06,254  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 3.0 with 1 tasks
2016-06-13 14:04:06,260  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 3.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:06,261  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 3.0 (TID 5)
2016-06-13 14:04:06,271  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_26_0 locally
2016-06-13 14:04:06,288  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 3.0 (TID 5). 11650 bytes result sent to driver
2016-06-13 14:04:06,291  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 3.0 (TID 5) in 32 ms on localhost (1/1)
2016-06-13 14:04:06,291  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2016-06-13 14:04:06,293  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 3 (take at <console>:76) finished in 0.034 s
2016-06-13 14:04:06,293  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.scheduler.DAGScheduler) - Job 3 finished: take at <console>:76, took 0.056751 s
2016-06-13 14:04:07,568  INFO [Remote-akka.actor.default-dispatcher-21] (org.apache.spark.SparkContext) - Starting job: count at <console>:75
2016-06-13 14:04:07,570  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 4 (count at <console>:75) with 2 output partitions
2016-06-13 14:04:07,570  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 4 (count at <console>:75)
2016-06-13 14:04:07,570  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:07,572  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:07,572  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 4 (MapPartitionsRDD[33] at rdd at <console>:74), which has no missing parents
2016-06-13 14:04:07,574  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_15 stored as values in memory (estimated size 11.5 KB, free 70.8 MB)
2016-06-13 14:04:07,575  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_15_piece0 stored as bytes in memory (estimated size 5.3 KB, free 70.8 MB)
2016-06-13 14:04:07,578  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_15_piece0 in memory on localhost:44356 (size: 5.3 KB, free: 9.7 GB)
2016-06-13 14:04:07,579  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 15 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:07,580  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 4 (MapPartitionsRDD[33] at rdd at <console>:74)
2016-06-13 14:04:07,580  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 4.0 with 2 tasks
2016-06-13 14:04:07,581  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 4.0 (TID 6, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:07,582  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 4.0 (TID 7, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:07,582  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 4.0 (TID 7)
2016-06-13 14:04:07,584  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 4.0 (TID 6)
2016-06-13 14:04:07,595  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_26_0 locally
2016-06-13 14:04:07,602  INFO [Executor task launch worker-1] (org.apache.spark.CacheManager) - Partition rdd_26_1 not found, computing it
2016-06-13 14:04:07,603  INFO [Executor task launch worker-1] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/jobs_huge.json:15446251+15446251
2016-06-13 14:04:07,773  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 4.0 (TID 6). 2261 bytes result sent to driver
2016-06-13 14:04:07,774  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 4.0 (TID 6) in 194 ms on localhost (1/2)
2016-06-13 14:04:08,023  INFO [Executor task launch worker-1] (org.apache.spark.storage.MemoryStore) - Block rdd_26_1 stored as values in memory (estimated size 14.4 MB, free 85.2 MB)
2016-06-13 14:04:08,023  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added rdd_26_1 in memory on localhost:44356 (size: 14.4 MB, free: 9.7 GB)
2016-06-13 14:04:08,053  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_14_piece0 on localhost:44356 in memory (size: 5.4 KB, free: 9.7 GB)
2016-06-13 14:04:08,055  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 5
2016-06-13 14:04:08,056  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_13_piece0 on localhost:44356 in memory (size: 5.3 KB, free: 9.7 GB)
2016-06-13 14:04:08,058  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 4
2016-06-13 14:04:08,060  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_11_piece0 on localhost:44356 in memory (size: 13.8 KB, free: 9.7 GB)
2016-06-13 14:04:08,081  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 4.0 (TID 7). 77443 bytes result sent to driver
2016-06-13 14:04:08,084  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 4.0 (TID 7) in 503 ms on localhost (2/2)
2016-06-13 14:04:08,084  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 4 (count at <console>:75) finished in 0.500 s
2016-06-13 14:04:08,084  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 4.0, whose tasks have all completed, from pool 
2016-06-13 14:04:08,084  INFO [Remote-akka.actor.default-dispatcher-21] (org.apache.spark.scheduler.DAGScheduler) - Job 4 finished: count at <console>:75, took 0.515428 s
2016-06-13 14:04:09,881  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_16 stored as values in memory (estimated size 23.8 KB, free 85.1 MB)
2016-06-13 14:04:09,885  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.storage.MemoryStore) - Block broadcast_16_piece0 stored as bytes in memory (estimated size 1991.0 B, free 85.1 MB)
2016-06-13 14:04:09,885  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_16_piece0 in memory on localhost:44356 (size: 1991.0 B, free: 9.7 GB)
2016-06-13 14:04:09,886  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Created broadcast 16 from broadcast at <console>:113
2016-06-13 14:04:13,320  INFO [Remote-akka.actor.default-dispatcher-22] (org.apache.spark.SparkContext) - Starting job: take at <console>:87
2016-06-13 14:04:13,323  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 5 (take at <console>:87) with 1 output partitions
2016-06-13 14:04:13,324  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 5 (take at <console>:87)
2016-06-13 14:04:13,324  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:13,324  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:13,324  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 5 (MapPartitionsRDD[34] at map at <console>:85), which has no missing parents
2016-06-13 14:04:13,325  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_17 stored as values in memory (estimated size 11.9 KB, free 85.1 MB)
2016-06-13 14:04:13,326  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_17_piece0 stored as bytes in memory (estimated size 5.5 KB, free 85.1 MB)
2016-06-13 14:04:13,327  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_17_piece0 in memory on localhost:44356 (size: 5.5 KB, free: 9.7 GB)
2016-06-13 14:04:13,328  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 17 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:13,328  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[34] at map at <console>:85)
2016-06-13 14:04:13,328  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 5.0 with 1 tasks
2016-06-13 14:04:13,329  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 5.0 (TID 8, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:13,329  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 5.0 (TID 8)
2016-06-13 14:04:13,334  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_26_0 locally
2016-06-13 14:04:13,409  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 5.0 (TID 8). 15994 bytes result sent to driver
2016-06-13 14:04:13,412  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 5.0 (TID 8) in 84 ms on localhost (1/1)
2016-06-13 14:04:13,412  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 5.0, whose tasks have all completed, from pool 
2016-06-13 14:04:13,412  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 5 (take at <console>:87) finished in 0.084 s
2016-06-13 14:04:13,413  INFO [Remote-akka.actor.default-dispatcher-22] (org.apache.spark.scheduler.DAGScheduler) - Job 5 finished: take at <console>:87, took 0.090057 s
2016-06-13 14:04:15,395  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.SparkContext) - Starting job: collectAsMap at <console>:90
2016-06-13 14:04:15,396  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 6 (collectAsMap at <console>:90) with 2 output partitions
2016-06-13 14:04:15,396  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 6 (collectAsMap at <console>:90)
2016-06-13 14:04:15,396  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:15,397  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:15,397  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 6 (MapPartitionsRDD[37] at zipWithUniqueId at <console>:90), which has no missing parents
2016-06-13 14:04:15,399  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_18 stored as values in memory (estimated size 12.7 KB, free 85.1 MB)
2016-06-13 14:04:15,400  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_18_piece0 stored as bytes in memory (estimated size 5.7 KB, free 85.1 MB)
2016-06-13 14:04:15,401  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_18_piece0 in memory on localhost:44356 (size: 5.7 KB, free: 9.7 GB)
2016-06-13 14:04:15,401  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 18 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:15,402  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 6 (MapPartitionsRDD[37] at zipWithUniqueId at <console>:90)
2016-06-13 14:04:15,402  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 6.0 with 2 tasks
2016-06-13 14:04:15,402  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 6.0 (TID 9, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:15,403  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 6.0 (TID 10, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:15,403  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 6.0 (TID 9)
2016-06-13 14:04:15,407  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 6.0 (TID 10)
2016-06-13 14:04:15,409  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_26_0 locally
2016-06-13 14:04:15,413  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_26_1 locally
2016-06-13 14:04:17,887  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 6
2016-06-13 14:04:17,889  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_17_piece0 on localhost:44356 in memory (size: 5.5 KB, free: 9.7 GB)
2016-06-13 14:04:17,891  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 7
2016-06-13 14:04:17,892  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_15_piece0 on localhost:44356 in memory (size: 5.3 KB, free: 9.7 GB)
2016-06-13 14:04:27,156  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 6.0 (TID 10). 74627 bytes result sent to driver
2016-06-13 14:04:27,167  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 6.0 (TID 10) in 11764 ms on localhost (1/2)
2016-06-13 14:04:28,020  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 6.0 (TID 9). 82504 bytes result sent to driver
2016-06-13 14:04:28,024  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 6 (collectAsMap at <console>:90) finished in 12.622 s
2016-06-13 14:04:28,025  INFO [Remote-akka.actor.default-dispatcher-17] (org.apache.spark.scheduler.DAGScheduler) - Job 6 finished: collectAsMap at <console>:90, took 12.629293 s
2016-06-13 14:04:28,028  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 6.0 (TID 9) in 12622 ms on localhost (2/2)
2016-06-13 14:04:28,029  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 6.0, whose tasks have all completed, from pool 
2016-06-13 14:04:28,920  INFO [Remote-akka.actor.default-dispatcher-20] (org.apache.spark.SparkContext) - Starting job: sortByKey at <console>:89
2016-06-13 14:04:28,929  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Registering RDD 39 (values at <console>:93)
2016-06-13 14:04:28,930  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Registering RDD 42 (map at <console>:89)
2016-06-13 14:04:28,931  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 7 (sortByKey at <console>:89) with 2 output partitions
2016-06-13 14:04:28,933  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 9 (sortByKey at <console>:89)
2016-06-13 14:04:28,933  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List(ShuffleMapStage 8)
2016-06-13 14:04:28,933  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List(ShuffleMapStage 8)
2016-06-13 14:04:28,938  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ShuffleMapStage 7 (MapPartitionsRDD[39] at values at <console>:93), which has no missing parents
2016-06-13 14:04:28,945  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_19 stored as values in memory (estimated size 13.5 KB, free 85.1 MB)
2016-06-13 14:04:28,947  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_19_piece0 stored as bytes in memory (estimated size 6.0 KB, free 85.1 MB)
2016-06-13 14:04:28,948  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_19_piece0 in memory on localhost:44356 (size: 6.0 KB, free: 9.7 GB)
2016-06-13 14:04:28,949  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 19 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:28,951  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[39] at values at <console>:93)
2016-06-13 14:04:28,952  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 7.0 with 2 tasks
2016-06-13 14:04:28,953  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 7.0 (TID 11, localhost, partition 0,PROCESS_LOCAL, 2308 bytes)
2016-06-13 14:04:28,954  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 7.0 (TID 12, localhost, partition 1,PROCESS_LOCAL, 2308 bytes)
2016-06-13 14:04:28,954  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 7.0 (TID 11)
2016-06-13 14:04:28,958  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 7.0 (TID 12)
2016-06-13 14:04:28,959  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_26_0 locally
2016-06-13 14:04:28,962  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_26_1 locally
2016-06-13 14:04:31,124  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_18_piece0 on localhost:44356 in memory (size: 5.7 KB, free: 9.7 GB)
2016-06-13 14:04:31,126  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 8
2016-06-13 14:04:36,940  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 7.0 (TID 12). 2433 bytes result sent to driver
2016-06-13 14:04:36,942  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 7.0 (TID 12) in 7989 ms on localhost (1/2)
2016-06-13 14:04:37,361  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 7.0 (TID 11). 2433 bytes result sent to driver
2016-06-13 14:04:37,362  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 7.0 (TID 11) in 8410 ms on localhost (2/2)
2016-06-13 14:04:37,362  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 7.0, whose tasks have all completed, from pool 
2016-06-13 14:04:37,363  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ShuffleMapStage 7 (values at <console>:93) finished in 8.411 s
2016-06-13 14:04:37,363  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - looking for newly runnable stages
2016-06-13 14:04:37,364  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - running: Set()
2016-06-13 14:04:37,364  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - waiting: Set(ResultStage 9, ShuffleMapStage 8)
2016-06-13 14:04:37,365  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - failed: Set()
2016-06-13 14:04:37,367  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ShuffleMapStage 8 (MapPartitionsRDD[42] at map at <console>:89), which has no missing parents
2016-06-13 14:04:37,374  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_20 stored as values in memory (estimated size 3.2 KB, free 85.1 MB)
2016-06-13 14:04:37,377  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_20_piece0 stored as bytes in memory (estimated size 1737.0 B, free 85.1 MB)
2016-06-13 14:04:37,377  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_20_piece0 in memory on localhost:44356 (size: 1737.0 B, free: 9.7 GB)
2016-06-13 14:04:37,379  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 20 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:37,379  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[42] at map at <console>:89)
2016-06-13 14:04:37,379  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 8.0 with 2 tasks
2016-06-13 14:04:37,383  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 8.0 (TID 13, localhost, partition 0,NODE_LOCAL, 1977 bytes)
2016-06-13 14:04:37,383  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 8.0 (TID 14, localhost, partition 1,NODE_LOCAL, 1977 bytes)
2016-06-13 14:04:37,384  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 8.0 (TID 13)
2016-06-13 14:04:37,387  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 8.0 (TID 14)
2016-06-13 14:04:37,387  INFO [Executor task launch worker-1] (org.apache.spark.CacheManager) - Partition rdd_40_0 not found, computing it
2016-06-13 14:04:37,395  INFO [Executor task launch worker-0] (org.apache.spark.CacheManager) - Partition rdd_40_1 not found, computing it
2016-06-13 14:04:37,402  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 2 non-empty blocks out of 2 blocks
2016-06-13 14:04:37,402  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 2 non-empty blocks out of 2 blocks
2016-06-13 14:04:37,441  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 43 ms
2016-06-13 14:04:37,441  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_19_piece0 on localhost:44356 in memory (size: 6.0 KB, free: 9.7 GB)
2016-06-13 14:04:37,443  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 45 ms
2016-06-13 14:04:37,686  INFO [Executor task launch worker-0] (org.apache.spark.storage.MemoryStore) - Block rdd_40_1 stored as values in memory (estimated size 702.9 KB, free 85.8 MB)
2016-06-13 14:04:37,688  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added rdd_40_1 in memory on localhost:44356 (size: 702.9 KB, free: 9.7 GB)
2016-06-13 14:04:37,701  INFO [Executor task launch worker-1] (org.apache.spark.storage.MemoryStore) - Block rdd_40_0 stored as values in memory (estimated size 662.9 KB, free 86.4 MB)
2016-06-13 14:04:37,701  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added rdd_40_0 in memory on localhost:44356 (size: 662.9 KB, free: 9.7 GB)
2016-06-13 14:04:37,733  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 8.0 (TID 14). 1874 bytes result sent to driver
2016-06-13 14:04:37,735  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 8.0 (TID 14) in 351 ms on localhost (1/2)
2016-06-13 14:04:37,738  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 8.0 (TID 13). 1874 bytes result sent to driver
2016-06-13 14:04:37,739  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 8.0 (TID 13) in 357 ms on localhost (2/2)
2016-06-13 14:04:37,739  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 8.0, whose tasks have all completed, from pool 
2016-06-13 14:04:37,743  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ShuffleMapStage 8 (map at <console>:89) finished in 0.361 s
2016-06-13 14:04:37,743  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - looking for newly runnable stages
2016-06-13 14:04:37,743  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - running: Set()
2016-06-13 14:04:37,743  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - waiting: Set(ResultStage 9)
2016-06-13 14:04:37,743  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - failed: Set()
2016-06-13 14:04:37,743  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 9 (MapPartitionsRDD[45] at sortByKey at <console>:89), which has no missing parents
2016-06-13 14:04:37,745  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_21 stored as values in memory (estimated size 3.3 KB, free 86.4 MB)
2016-06-13 14:04:37,756  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_21_piece0 stored as bytes in memory (estimated size 1897.0 B, free 86.4 MB)
2016-06-13 14:04:37,756  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_21_piece0 in memory on localhost:44356 (size: 1897.0 B, free: 9.7 GB)
2016-06-13 14:04:37,757  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 21 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:37,757  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 9 (MapPartitionsRDD[45] at sortByKey at <console>:89)
2016-06-13 14:04:37,757  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 9.0 with 2 tasks
2016-06-13 14:04:37,759  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 9.0 (TID 15, localhost, partition 0,NODE_LOCAL, 1988 bytes)
2016-06-13 14:04:37,759  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 9.0 (TID 16, localhost, partition 1,NODE_LOCAL, 1988 bytes)
2016-06-13 14:04:37,759  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 9.0 (TID 15)
2016-06-13 14:04:37,759  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 9.0 (TID 16)
2016-06-13 14:04:37,762  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 2 non-empty blocks out of 2 blocks
2016-06-13 14:04:37,762  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 2 non-empty blocks out of 2 blocks
2016-06-13 14:04:37,762  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2016-06-13 14:04:37,762  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2016-06-13 14:04:37,782  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 9.0 (TID 15). 1630 bytes result sent to driver
2016-06-13 14:04:37,784  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 9.0 (TID 15) in 25 ms on localhost (1/2)
2016-06-13 14:04:37,786  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 9.0 (TID 16). 1630 bytes result sent to driver
2016-06-13 14:04:37,789  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 9.0 (TID 16) in 29 ms on localhost (2/2)
2016-06-13 14:04:37,789  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 9.0, whose tasks have all completed, from pool 
2016-06-13 14:04:37,789  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 9 (sortByKey at <console>:89) finished in 0.031 s
2016-06-13 14:04:37,794  INFO [Remote-akka.actor.default-dispatcher-20] (org.apache.spark.scheduler.DAGScheduler) - Job 7 finished: sortByKey at <console>:89, took 8.873397 s
2016-06-13 14:04:38,164  INFO [Remote-akka.actor.default-dispatcher-20] (org.apache.spark.SparkContext) - Starting job: count at <console>:89
2016-06-13 14:04:38,169  INFO [dag-scheduler-event-loop] (org.apache.spark.MapOutputTrackerMaster) - Size of output statuses for shuffle 1 is 155 bytes
2016-06-13 14:04:38,174  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 8 (count at <console>:89) with 2 output partitions
2016-06-13 14:04:38,174  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 11 (count at <console>:89)
2016-06-13 14:04:38,174  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List(ShuffleMapStage 10)
2016-06-13 14:04:38,178  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:38,180  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 11 (ShuffledRDD[40] at reduceByKey at <console>:93), which has no missing parents
2016-06-13 14:04:38,184  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_22 stored as values in memory (estimated size 2.4 KB, free 86.4 MB)
2016-06-13 14:04:38,187  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_22_piece0 stored as bytes in memory (estimated size 1476.0 B, free 86.4 MB)
2016-06-13 14:04:38,187  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_22_piece0 in memory on localhost:44356 (size: 1476.0 B, free: 9.7 GB)
2016-06-13 14:04:38,190  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 22 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:38,192  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 11 (ShuffledRDD[40] at reduceByKey at <console>:93)
2016-06-13 14:04:38,192  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 11.0 with 2 tasks
2016-06-13 14:04:38,195  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 11.0 (TID 17, localhost, partition 0,PROCESS_LOCAL, 1988 bytes)
2016-06-13 14:04:38,195  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 11.0 (TID 18, localhost, partition 1,PROCESS_LOCAL, 1988 bytes)
2016-06-13 14:04:38,196  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 11.0 (TID 18)
2016-06-13 14:04:38,196  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 11.0 (TID 17)
2016-06-13 14:04:38,198  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_40_1 locally
2016-06-13 14:04:38,198  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_40_0 locally
2016-06-13 14:04:38,205  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 11.0 (TID 17). 2082 bytes result sent to driver
2016-06-13 14:04:38,207  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 11.0 (TID 18). 2082 bytes result sent to driver
2016-06-13 14:04:38,208  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 11.0 (TID 17) in 13 ms on localhost (1/2)
2016-06-13 14:04:38,210  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 11.0 (TID 18) in 15 ms on localhost (2/2)
2016-06-13 14:04:38,210  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 11.0, whose tasks have all completed, from pool 
2016-06-13 14:04:38,210  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 11 (count at <console>:89) finished in 0.015 s
2016-06-13 14:04:38,210  INFO [Remote-akka.actor.default-dispatcher-20] (org.apache.spark.scheduler.DAGScheduler) - Job 8 finished: count at <console>:89, took 0.046719 s
2016-06-13 14:04:38,880  INFO [Remote-akka.actor.default-dispatcher-20] (org.apache.spark.SparkContext) - Starting job: sortByKey at <console>:90
2016-06-13 14:04:38,882  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Registering RDD 48 (map at <console>:90)
2016-06-13 14:04:38,882  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 9 (sortByKey at <console>:90) with 2 output partitions
2016-06-13 14:04:38,882  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 14 (sortByKey at <console>:90)
2016-06-13 14:04:38,882  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List(ShuffleMapStage 13)
2016-06-13 14:04:38,882  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List(ShuffleMapStage 13)
2016-06-13 14:04:38,883  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ShuffleMapStage 13 (MapPartitionsRDD[48] at map at <console>:90), which has no missing parents
2016-06-13 14:04:38,884  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_23 stored as values in memory (estimated size 3.2 KB, free 86.4 MB)
2016-06-13 14:04:38,885  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_23_piece0 stored as bytes in memory (estimated size 1737.0 B, free 86.4 MB)
2016-06-13 14:04:38,885  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_23_piece0 in memory on localhost:44356 (size: 1737.0 B, free: 9.7 GB)
2016-06-13 14:04:38,887  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 23 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:38,888  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[48] at map at <console>:90)
2016-06-13 14:04:38,888  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 13.0 with 2 tasks
2016-06-13 14:04:38,889  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 13.0 (TID 19, localhost, partition 0,PROCESS_LOCAL, 1977 bytes)
2016-06-13 14:04:38,890  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 13.0 (TID 20, localhost, partition 1,PROCESS_LOCAL, 1977 bytes)
2016-06-13 14:04:38,890  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 13.0 (TID 20)
2016-06-13 14:04:38,890  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 13.0 (TID 19)
2016-06-13 14:04:38,894  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_40_0 locally
2016-06-13 14:04:38,894  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_40_1 locally
2016-06-13 14:04:38,939  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 13.0 (TID 19). 2254 bytes result sent to driver
2016-06-13 14:04:38,940  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 13.0 (TID 19) in 51 ms on localhost (1/2)
2016-06-13 14:04:38,943  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 13.0 (TID 20). 2254 bytes result sent to driver
2016-06-13 14:04:38,944  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 13.0 (TID 20) in 54 ms on localhost (2/2)
2016-06-13 14:04:38,944  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 13.0, whose tasks have all completed, from pool 
2016-06-13 14:04:38,945  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ShuffleMapStage 13 (map at <console>:90) finished in 0.055 s
2016-06-13 14:04:38,945  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - looking for newly runnable stages
2016-06-13 14:04:38,945  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - running: Set()
2016-06-13 14:04:38,945  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - waiting: Set(ResultStage 14)
2016-06-13 14:04:38,945  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - failed: Set()
2016-06-13 14:04:38,946  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 14 (MapPartitionsRDD[51] at sortByKey at <console>:90), which has no missing parents
2016-06-13 14:04:38,948  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_24 stored as values in memory (estimated size 3.3 KB, free 86.5 MB)
2016-06-13 14:04:38,949  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_24_piece0 stored as bytes in memory (estimated size 1872.0 B, free 86.5 MB)
2016-06-13 14:04:38,950  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_24_piece0 in memory on localhost:44356 (size: 1872.0 B, free: 9.7 GB)
2016-06-13 14:04:38,950  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 24 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:38,950  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 14 (MapPartitionsRDD[51] at sortByKey at <console>:90)
2016-06-13 14:04:38,950  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 14.0 with 2 tasks
2016-06-13 14:04:38,951  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 14.0 (TID 21, localhost, partition 0,NODE_LOCAL, 1988 bytes)
2016-06-13 14:04:38,951  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 14.0 (TID 22, localhost, partition 1,NODE_LOCAL, 1988 bytes)
2016-06-13 14:04:38,951  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 14.0 (TID 22)
2016-06-13 14:04:38,952  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 14.0 (TID 21)
2016-06-13 14:04:38,954  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 2 non-empty blocks out of 2 blocks
2016-06-13 14:04:38,954  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2016-06-13 14:04:38,954  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 2 non-empty blocks out of 2 blocks
2016-06-13 14:04:38,955  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2016-06-13 14:04:38,967  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 14.0 (TID 22). 1630 bytes result sent to driver
2016-06-13 14:04:38,968  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 14.0 (TID 22) in 17 ms on localhost (1/2)
2016-06-13 14:04:38,972  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 14.0 (TID 21). 1630 bytes result sent to driver
2016-06-13 14:04:38,973  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 14.0 (TID 21) in 22 ms on localhost (2/2)
2016-06-13 14:04:38,973  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 14 (sortByKey at <console>:90) finished in 0.022 s
2016-06-13 14:04:38,973  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 14.0, whose tasks have all completed, from pool 
2016-06-13 14:04:38,973  INFO [Remote-akka.actor.default-dispatcher-20] (org.apache.spark.scheduler.DAGScheduler) - Job 9 finished: sortByKey at <console>:90, took 0.092786 s
2016-06-13 14:04:38,994  INFO [Remote-akka.actor.default-dispatcher-20] (org.apache.spark.SparkContext) - Starting job: collect at <console>:90
2016-06-13 14:04:38,995  INFO [dag-scheduler-event-loop] (org.apache.spark.MapOutputTrackerMaster) - Size of output statuses for shuffle 1 is 155 bytes
2016-06-13 14:04:38,996  INFO [dag-scheduler-event-loop] (org.apache.spark.MapOutputTrackerMaster) - Size of output statuses for shuffle 2 is 155 bytes
2016-06-13 14:04:38,996  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Registering RDD 49 (reduceByKey at <console>:90)
2016-06-13 14:04:38,996  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 10 (collect at <console>:90) with 2 output partitions
2016-06-13 14:04:38,996  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 18 (collect at <console>:90)
2016-06-13 14:04:38,997  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List(ShuffleMapStage 17)
2016-06-13 14:04:38,997  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List(ShuffleMapStage 17)
2016-06-13 14:04:38,997  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ShuffleMapStage 17 (ShuffledRDD[49] at reduceByKey at <console>:90), which has no missing parents
2016-06-13 14:04:38,999  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_25 stored as values in memory (estimated size 2.9 KB, free 86.5 MB)
2016-06-13 14:04:39,000  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_25_piece0 stored as bytes in memory (estimated size 1690.0 B, free 86.5 MB)
2016-06-13 14:04:39,000  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_25_piece0 in memory on localhost:44356 (size: 1690.0 B, free: 9.7 GB)
2016-06-13 14:04:39,002  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 25 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:39,002  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ShuffleMapStage 17 (ShuffledRDD[49] at reduceByKey at <console>:90)
2016-06-13 14:04:39,002  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 17.0 with 2 tasks
2016-06-13 14:04:39,003  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 17.0 (TID 23, localhost, partition 0,NODE_LOCAL, 1977 bytes)
2016-06-13 14:04:39,003  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 17.0 (TID 24, localhost, partition 1,NODE_LOCAL, 1977 bytes)
2016-06-13 14:04:39,003  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 17.0 (TID 24)
2016-06-13 14:04:39,004  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 17.0 (TID 23)
2016-06-13 14:04:39,012  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 2 non-empty blocks out of 2 blocks
2016-06-13 14:04:39,012  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2016-06-13 14:04:39,035  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 2 non-empty blocks out of 2 blocks
2016-06-13 14:04:39,035  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2016-06-13 14:04:39,070  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 17.0 (TID 24). 1375 bytes result sent to driver
2016-06-13 14:04:39,070  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 17.0 (TID 23). 1375 bytes result sent to driver
2016-06-13 14:04:39,071  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 17.0 (TID 24) in 67 ms on localhost (1/2)
2016-06-13 14:04:39,072  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 17.0 (TID 23) in 70 ms on localhost (2/2)
2016-06-13 14:04:39,072  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 17.0, whose tasks have all completed, from pool 
2016-06-13 14:04:39,072  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ShuffleMapStage 17 (reduceByKey at <console>:90) finished in 0.070 s
2016-06-13 14:04:39,072  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - looking for newly runnable stages
2016-06-13 14:04:39,072  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - running: Set()
2016-06-13 14:04:39,072  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - waiting: Set(ResultStage 18)
2016-06-13 14:04:39,073  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - failed: Set()
2016-06-13 14:04:39,073  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 18 (MapPartitionsRDD[53] at mapValues at <console>:90), which has no missing parents
2016-06-13 14:04:39,074  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_26 stored as values in memory (estimated size 3.2 KB, free 86.5 MB)
2016-06-13 14:04:39,075  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_26_piece0 stored as bytes in memory (estimated size 1866.0 B, free 86.5 MB)
2016-06-13 14:04:39,076  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_26_piece0 in memory on localhost:44356 (size: 1866.0 B, free: 9.7 GB)
2016-06-13 14:04:39,076  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 26 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:39,077  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 18 (MapPartitionsRDD[53] at mapValues at <console>:90)
2016-06-13 14:04:39,077  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 18.0 with 2 tasks
2016-06-13 14:04:39,078  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 18.0 (TID 25, localhost, partition 0,NODE_LOCAL, 1988 bytes)
2016-06-13 14:04:39,078  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 18.0 (TID 26, localhost, partition 1,NODE_LOCAL, 1988 bytes)
2016-06-13 14:04:39,078  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 18.0 (TID 25)
2016-06-13 14:04:39,079  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 18.0 (TID 26)
2016-06-13 14:04:39,081  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 2 non-empty blocks out of 2 blocks
2016-06-13 14:04:39,081  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 2 non-empty blocks out of 2 blocks
2016-06-13 14:04:39,082  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2016-06-13 14:04:39,082  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 1 ms
2016-06-13 14:04:39,108  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 18.0 (TID 26). 14469 bytes result sent to driver
2016-06-13 14:04:39,110  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 18.0 (TID 26) in 32 ms on localhost (1/2)
2016-06-13 14:04:39,114  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 18.0 (TID 25). 18359 bytes result sent to driver
2016-06-13 14:04:39,122  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 18.0 (TID 25) in 44 ms on localhost (2/2)
2016-06-13 14:04:39,122  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 18.0, whose tasks have all completed, from pool 
2016-06-13 14:04:39,122  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 18 (collect at <console>:90) finished in 0.044 s
2016-06-13 14:04:39,122  INFO [Remote-akka.actor.default-dispatcher-20] (org.apache.spark.scheduler.DAGScheduler) - Job 10 finished: collect at <console>:90, took 0.127889 s
2016-06-13 14:04:40,179  INFO [Remote-akka.actor.default-dispatcher-22] (org.apache.spark.SparkContext) - Starting job: collect at <console>:89
2016-06-13 14:04:40,181  INFO [dag-scheduler-event-loop] (org.apache.spark.MapOutputTrackerMaster) - Size of output statuses for shuffle 1 is 155 bytes
2016-06-13 14:04:40,181  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 11 (collect at <console>:89) with 2 output partitions
2016-06-13 14:04:40,181  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 20 (collect at <console>:89)
2016-06-13 14:04:40,181  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List(ShuffleMapStage 19)
2016-06-13 14:04:40,182  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:40,182  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 20 (MapPartitionsRDD[54] at filter at <console>:89), which has no missing parents
2016-06-13 14:04:40,183  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_27 stored as values in memory (estimated size 3.1 KB, free 86.5 MB)
2016-06-13 14:04:40,185  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_27_piece0 stored as bytes in memory (estimated size 1727.0 B, free 86.5 MB)
2016-06-13 14:04:40,186  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_27_piece0 in memory on localhost:44356 (size: 1727.0 B, free: 9.7 GB)
2016-06-13 14:04:40,187  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 27 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:40,187  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 20 (MapPartitionsRDD[54] at filter at <console>:89)
2016-06-13 14:04:40,187  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 20.0 with 2 tasks
2016-06-13 14:04:40,188  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 20.0 (TID 27, localhost, partition 0,PROCESS_LOCAL, 1988 bytes)
2016-06-13 14:04:40,188  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 20.0 (TID 28, localhost, partition 1,PROCESS_LOCAL, 1988 bytes)
2016-06-13 14:04:40,188  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 20.0 (TID 27)
2016-06-13 14:04:40,188  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 20.0 (TID 28)
2016-06-13 14:04:40,191  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_40_0 locally
2016-06-13 14:04:40,196  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_40_1 locally
2016-06-13 14:04:40,204  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 20.0 (TID 28). 64275 bytes result sent to driver
2016-06-13 14:04:40,210  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 20.0 (TID 27). 63147 bytes result sent to driver
2016-06-13 14:04:40,225  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 20.0 (TID 28) in 36 ms on localhost (1/2)
2016-06-13 14:04:40,231  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 20 (collect at <console>:89) finished in 0.044 s
2016-06-13 14:04:40,232  INFO [Remote-akka.actor.default-dispatcher-22] (org.apache.spark.scheduler.DAGScheduler) - Job 11 finished: collect at <console>:89, took 0.052434 s
2016-06-13 14:04:40,239  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 20.0 (TID 27) in 43 ms on localhost (2/2)
2016-06-13 14:04:40,239  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 20.0, whose tasks have all completed, from pool 
2016-06-13 14:04:40,278  INFO [Remote-akka.actor.default-dispatcher-22] (org.apache.spark.storage.MemoryStore) - Block broadcast_28 stored as values in memory (estimated size 803.0 KB, free 87.3 MB)
2016-06-13 14:04:40,301  INFO [Remote-akka.actor.default-dispatcher-22] (org.apache.spark.storage.MemoryStore) - Block broadcast_28_piece0 stored as bytes in memory (estimated size 65.0 KB, free 87.3 MB)
2016-06-13 14:04:40,303  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_28_piece0 in memory on localhost:44356 (size: 65.0 KB, free: 9.7 GB)
2016-06-13 14:04:40,303  INFO [Remote-akka.actor.default-dispatcher-22] (org.apache.spark.SparkContext) - Created broadcast 28 from broadcast at <console>:97
2016-06-13 14:04:40,346  INFO [Remote-akka.actor.default-dispatcher-22] (org.apache.spark.storage.MemoryStore) - Block broadcast_29 stored as values in memory (estimated size 761.4 KB, free 88.1 MB)
2016-06-13 14:04:40,360  INFO [Remote-akka.actor.default-dispatcher-22] (org.apache.spark.storage.MemoryStore) - Block broadcast_29_piece0 stored as bytes in memory (estimated size 60.7 KB, free 88.1 MB)
2016-06-13 14:04:40,360  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_29_piece0 in memory on localhost:44356 (size: 60.7 KB, free: 9.7 GB)
2016-06-13 14:04:40,361  INFO [Remote-akka.actor.default-dispatcher-22] (org.apache.spark.SparkContext) - Created broadcast 29 from broadcast at <console>:101
2016-06-13 14:04:41,133  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.SparkContext) - Starting job: zipWithIndex at <console>:89
2016-06-13 14:04:41,135  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 12 (zipWithIndex at <console>:89) with 1 output partitions
2016-06-13 14:04:41,135  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 22 (zipWithIndex at <console>:89)
2016-06-13 14:04:41,135  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List(ShuffleMapStage 21)
2016-06-13 14:04:41,135  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:41,135  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 22 (ShuffledRDD[40] at reduceByKey at <console>:93), which has no missing parents
2016-06-13 14:04:41,136  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_30 stored as values in memory (estimated size 2.4 KB, free 88.1 MB)
2016-06-13 14:04:41,138  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_30_piece0 stored as bytes in memory (estimated size 1486.0 B, free 88.1 MB)
2016-06-13 14:04:41,138  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_30_piece0 in memory on localhost:44356 (size: 1486.0 B, free: 9.7 GB)
2016-06-13 14:04:41,138  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 30 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:41,139  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 1 missing tasks from ResultStage 22 (ShuffledRDD[40] at reduceByKey at <console>:93)
2016-06-13 14:04:41,139  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 22.0 with 1 tasks
2016-06-13 14:04:41,139  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 22.0 (TID 29, localhost, partition 0,PROCESS_LOCAL, 1988 bytes)
2016-06-13 14:04:41,140  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 22.0 (TID 29)
2016-06-13 14:04:41,141  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_40_0 locally
2016-06-13 14:04:41,143  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 22.0 (TID 29). 2082 bytes result sent to driver
2016-06-13 14:04:41,144  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 22.0 (TID 29) in 5 ms on localhost (1/1)
2016-06-13 14:04:41,144  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 22 (zipWithIndex at <console>:89) finished in 0.005 s
2016-06-13 14:04:41,144  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 22.0, whose tasks have all completed, from pool 
2016-06-13 14:04:41,144  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.scheduler.DAGScheduler) - Job 12 finished: zipWithIndex at <console>:89, took 0.010774 s
2016-06-13 14:04:41,165  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.rdd.ShuffledRDD) - Removing RDD 40 from persistence list
2016-06-13 14:04:41,171  INFO [block-manager-slave-async-thread-pool-5] (org.apache.spark.storage.BlockManager) - Removing RDD 40
2016-06-13 14:04:42,196  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: count at <console>:104
2016-06-13 14:04:42,197  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 13 (count at <console>:104) with 2 output partitions
2016-06-13 14:04:42,197  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 23 (count at <console>:104)
2016-06-13 14:04:42,197  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:42,201  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:42,201  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 23 (MapPartitionsRDD[57] at mapValues at <console>:102), which has no missing parents
2016-06-13 14:04:42,214  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_31 stored as values in memory (estimated size 12.3 KB, free 86.8 MB)
2016-06-13 14:04:42,216  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_31_piece0 stored as bytes in memory (estimated size 5.5 KB, free 86.8 MB)
2016-06-13 14:04:42,218  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_31_piece0 in memory on localhost:44356 (size: 5.5 KB, free: 9.7 GB)
2016-06-13 14:04:42,219  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 31 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:42,222  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 23 (MapPartitionsRDD[57] at mapValues at <console>:102)
2016-06-13 14:04:42,223  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 23.0 with 2 tasks
2016-06-13 14:04:42,224  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 23.0 (TID 30, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:42,225  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 23.0 (TID 31, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:42,225  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 23.0 (TID 30)
2016-06-13 14:04:42,225  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 23.0 (TID 31)
2016-06-13 14:04:42,237  INFO [Executor task launch worker-1] (org.apache.spark.CacheManager) - Partition rdd_57_1 not found, computing it
2016-06-13 14:04:42,238  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_26_1 locally
2016-06-13 14:04:42,241  INFO [Executor task launch worker-0] (org.apache.spark.CacheManager) - Partition rdd_57_0 not found, computing it
2016-06-13 14:04:42,242  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_26_0 locally
2016-06-13 14:04:44,961  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_30_piece0 on localhost:44356 in memory (size: 1486.0 B, free: 9.7 GB)
2016-06-13 14:04:44,962  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 18
2016-06-13 14:04:44,963  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_27_piece0 on localhost:44356 in memory (size: 1727.0 B, free: 9.7 GB)
2016-06-13 14:04:44,964  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 17
2016-06-13 14:04:44,965  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_26_piece0 on localhost:44356 in memory (size: 1866.0 B, free: 9.7 GB)
2016-06-13 14:04:44,965  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 16
2016-06-13 14:04:44,966  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_25_piece0 on localhost:44356 in memory (size: 1690.0 B, free: 9.7 GB)
2016-06-13 14:04:44,967  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 15
2016-06-13 14:04:44,973  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned shuffle 3
2016-06-13 14:04:44,976  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_24_piece0 on localhost:44356 in memory (size: 1872.0 B, free: 9.7 GB)
2016-06-13 14:04:44,977  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 14
2016-06-13 14:04:44,978  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_23_piece0 on localhost:44356 in memory (size: 1737.0 B, free: 9.7 GB)
2016-06-13 14:04:44,978  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 13
2016-06-13 14:04:44,979  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned shuffle 2
2016-06-13 14:04:44,980  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_22_piece0 on localhost:44356 in memory (size: 1476.0 B, free: 9.7 GB)
2016-06-13 14:04:44,990  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 12
2016-06-13 14:04:44,991  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_21_piece0 on localhost:44356 in memory (size: 1897.0 B, free: 9.7 GB)
2016-06-13 14:04:44,991  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 11
2016-06-13 14:04:44,992  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_20_piece0 on localhost:44356 in memory (size: 1737.0 B, free: 9.7 GB)
2016-06-13 14:04:44,993  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 10
2016-06-13 14:04:44,993  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 9
2016-06-13 14:04:51,122  INFO [Executor task launch worker-1] (org.apache.spark.storage.MemoryStore) - Block rdd_57_1 stored as values in memory (estimated size 1843.5 KB, free 88.6 MB)
2016-06-13 14:04:51,123  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added rdd_57_1 in memory on localhost:44356 (size: 1843.5 KB, free: 9.7 GB)
2016-06-13 14:04:51,123  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 23.0 (TID 31). 2760 bytes result sent to driver
2016-06-13 14:04:51,124  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 23.0 (TID 31) in 8900 ms on localhost (1/2)
2016-06-13 14:04:51,405  INFO [Executor task launch worker-0] (org.apache.spark.storage.MemoryStore) - Block rdd_57_0 stored as values in memory (estimated size 2011.9 KB, free 90.5 MB)
2016-06-13 14:04:51,405  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added rdd_57_0 in memory on localhost:44356 (size: 2011.9 KB, free: 9.7 GB)
2016-06-13 14:04:51,406  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 23.0 (TID 30). 2760 bytes result sent to driver
2016-06-13 14:04:51,407  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 23.0 (TID 30) in 9183 ms on localhost (2/2)
2016-06-13 14:04:51,407  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 23.0, whose tasks have all completed, from pool 
2016-06-13 14:04:51,407  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 23 (count at <console>:104) finished in 9.155 s
2016-06-13 14:04:51,408  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 13 finished: count at <console>:104, took 9.211548 s
2016-06-13 14:04:51,408  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.rdd.ShuffledRDD) - Removing RDD 40 from persistence list
2016-06-13 14:04:51,410  INFO [block-manager-slave-async-thread-pool-7] (org.apache.spark.storage.BlockManager) - Removing RDD 40
2016-06-13 14:04:51,423  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: count at RowMatrix.scala:75
2016-06-13 14:04:51,424  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 14 (count at RowMatrix.scala:75) with 2 output partitions
2016-06-13 14:04:51,424  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 24 (count at RowMatrix.scala:75)
2016-06-13 14:04:51,424  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:51,425  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:51,425  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 24 (MapPartitionsRDD[58] at values at <console>:107), which has no missing parents
2016-06-13 14:04:51,428  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_32 stored as values in memory (estimated size 12.5 KB, free 90.5 MB)
2016-06-13 14:04:51,429  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_32_piece0 stored as bytes in memory (estimated size 5.6 KB, free 90.5 MB)
2016-06-13 14:04:51,429  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_32_piece0 in memory on localhost:44356 (size: 5.6 KB, free: 9.7 GB)
2016-06-13 14:04:51,430  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 32 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:51,430  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 24 (MapPartitionsRDD[58] at values at <console>:107)
2016-06-13 14:04:51,430  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 24.0 with 2 tasks
2016-06-13 14:04:51,431  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 24.0 (TID 32, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:51,431  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 24.0 (TID 33, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:51,432  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 24.0 (TID 33)
2016-06-13 14:04:51,433  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 24.0 (TID 32)
2016-06-13 14:04:51,436  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:51,436  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 24.0 (TID 33). 2261 bytes result sent to driver
2016-06-13 14:04:51,437  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 24.0 (TID 33) in 6 ms on localhost (1/2)
2016-06-13 14:04:51,439  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:51,440  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 24.0 (TID 32). 2261 bytes result sent to driver
2016-06-13 14:04:51,441  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 24.0 (TID 32) in 11 ms on localhost (2/2)
2016-06-13 14:04:51,441  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 24.0, whose tasks have all completed, from pool 
2016-06-13 14:04:51,441  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 24 (count at RowMatrix.scala:75) finished in 0.011 s
2016-06-13 14:04:51,441  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 14 finished: count at RowMatrix.scala:75, took 0.017950 s
2016-06-13 14:04:51,446  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: first at RowMatrix.scala:61
2016-06-13 14:04:51,447  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 15 (first at RowMatrix.scala:61) with 1 output partitions
2016-06-13 14:04:51,447  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 25 (first at RowMatrix.scala:61)
2016-06-13 14:04:51,447  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:51,447  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:51,447  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 25 (MapPartitionsRDD[58] at values at <console>:107), which has no missing parents
2016-06-13 14:04:51,448  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_33 stored as values in memory (estimated size 12.7 KB, free 90.6 MB)
2016-06-13 14:04:51,450  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_33_piece0 stored as bytes in memory (estimated size 5.7 KB, free 90.6 MB)
2016-06-13 14:04:51,450  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_33_piece0 in memory on localhost:44356 (size: 5.7 KB, free: 9.7 GB)
2016-06-13 14:04:51,451  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 33 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:51,451  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[58] at values at <console>:107)
2016-06-13 14:04:51,452  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 25.0 with 1 tasks
2016-06-13 14:04:51,452  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 25.0 (TID 34, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:51,452  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 25.0 (TID 34)
2016-06-13 14:04:51,456  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:51,457  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 25.0 (TID 34). 2871 bytes result sent to driver
2016-06-13 14:04:51,458  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 25.0 (TID 34) in 6 ms on localhost (1/1)
2016-06-13 14:04:51,458  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 25.0, whose tasks have all completed, from pool 
2016-06-13 14:04:51,458  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 25 (first at RowMatrix.scala:61) finished in 0.006 s
2016-06-13 14:04:51,459  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 15 finished: first at RowMatrix.scala:61, took 0.013083 s
2016-06-13 14:04:51,462  WARN [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.mllib.linalg.distributed.RowMatrix) - The input data is not directly cached, which may hurt performance if its parent RDDs are also uncached.
2016-06-13 14:04:51,468  WARN [Remote-akka.actor.default-dispatcher-18] (com.github.fommil.netlib.ARPACK) - Failed to load implementation from: com.github.fommil.netlib.NativeSystemARPACK
2016-06-13 14:04:51,468  WARN [Remote-akka.actor.default-dispatcher-18] (com.github.fommil.netlib.ARPACK) - Failed to load implementation from: com.github.fommil.netlib.NativeRefARPACK
2016-06-13 14:04:51,864  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_34 stored as values in memory (estimated size 124.9 KB, free 90.7 MB)
2016-06-13 14:04:51,887  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_34_piece0 stored as bytes in memory (estimated size 85.4 KB, free 90.8 MB)
2016-06-13 14:04:51,887  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_34_piece0 in memory on localhost:44356 (size: 85.4 KB, free: 9.7 GB)
2016-06-13 14:04:51,888  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 34 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:51,901  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:51,902  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 16 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:51,902  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 26 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:51,902  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:51,902  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:51,902  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 26 (MapPartitionsRDD[59] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:51,904  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_35 stored as values in memory (estimated size 55.2 KB, free 90.8 MB)
2016-06-13 14:04:51,906  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_35_piece0 stored as bytes in memory (estimated size 8.1 KB, free 90.8 MB)
2016-06-13 14:04:51,906  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_35_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:51,907  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 35 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:51,907  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 26 (MapPartitionsRDD[59] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:51,907  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 26.0 with 2 tasks
2016-06-13 14:04:51,908  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 26.0 (TID 35, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:51,908  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 26.0 (TID 36, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:51,908  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 26.0 (TID 35)
2016-06-13 14:04:51,908  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 26.0 (TID 36)
2016-06-13 14:04:51,912  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:51,916  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:52,530  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 26.0 (TID 36). 45217 bytes result sent to driver
2016-06-13 14:04:52,532  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 26.0 (TID 36) in 623 ms on localhost (1/2)
2016-06-13 14:04:52,532  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 26.0 (TID 35). 45217 bytes result sent to driver
2016-06-13 14:04:52,533  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 26.0 (TID 35) in 625 ms on localhost (2/2)
2016-06-13 14:04:52,533  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 26.0, whose tasks have all completed, from pool 
2016-06-13 14:04:52,533  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 26 (treeAggregate at RowMatrix.scala:93) finished in 0.625 s
2016-06-13 14:04:52,539  WARN [dag-scheduler-event-loop] (com.github.fommil.netlib.BLAS) - Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS
2016-06-13 14:04:52,540  WARN [dag-scheduler-event-loop] (com.github.fommil.netlib.BLAS) - Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS
2016-06-13 14:04:52,547  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 16 finished: treeAggregate at RowMatrix.scala:93, took 0.645704 s
2016-06-13 14:04:52,555  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_36 stored as values in memory (estimated size 124.9 KB, free 91.0 MB)
2016-06-13 14:04:52,556  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_36_piece0 stored as bytes in memory (estimated size 125.0 KB, free 91.1 MB)
2016-06-13 14:04:52,557  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_36_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:52,558  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 36 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:52,566  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:52,566  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 17 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:52,566  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 27 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:52,566  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:52,567  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:52,567  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 27 (MapPartitionsRDD[60] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:52,569  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_37 stored as values in memory (estimated size 55.2 KB, free 91.1 MB)
2016-06-13 14:04:52,571  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_37_piece0 stored as bytes in memory (estimated size 8.1 KB, free 91.1 MB)
2016-06-13 14:04:52,571  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_37_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:52,572  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 37 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:52,572  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 27 (MapPartitionsRDD[60] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:52,572  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 27.0 with 2 tasks
2016-06-13 14:04:52,573  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 27.0 (TID 37, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:52,577  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 27.0 (TID 38, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:52,578  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 27.0 (TID 37)
2016-06-13 14:04:52,579  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 27.0 (TID 38)
2016-06-13 14:04:52,581  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:52,583  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:52,603  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 27.0 (TID 38). 45217 bytes result sent to driver
2016-06-13 14:04:52,604  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 27.0 (TID 38) in 30 ms on localhost (1/2)
2016-06-13 14:04:52,605  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 27.0 (TID 37). 45217 bytes result sent to driver
2016-06-13 14:04:52,606  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 27.0 (TID 37) in 33 ms on localhost (2/2)
2016-06-13 14:04:52,606  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 27.0, whose tasks have all completed, from pool 
2016-06-13 14:04:52,607  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 27 (treeAggregate at RowMatrix.scala:93) finished in 0.035 s
2016-06-13 14:04:52,607  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 17 finished: treeAggregate at RowMatrix.scala:93, took 0.041562 s
2016-06-13 14:04:52,619  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_38 stored as values in memory (estimated size 124.9 KB, free 91.3 MB)
2016-06-13 14:04:52,621  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_38_piece0 stored as bytes in memory (estimated size 125.0 KB, free 91.4 MB)
2016-06-13 14:04:52,622  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_38_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:52,625  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 38 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:52,634  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:52,634  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 18 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:52,635  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 28 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:52,635  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:52,635  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:52,635  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 28 (MapPartitionsRDD[61] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:52,637  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_39 stored as values in memory (estimated size 55.2 KB, free 91.4 MB)
2016-06-13 14:04:52,638  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_39_piece0 stored as bytes in memory (estimated size 8.1 KB, free 91.4 MB)
2016-06-13 14:04:52,639  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_39_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:52,640  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 39 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:52,640  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 28 (MapPartitionsRDD[61] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:52,640  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 28.0 with 2 tasks
2016-06-13 14:04:52,641  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 28.0 (TID 39, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:52,641  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 28.0 (TID 40, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:52,641  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 28.0 (TID 40)
2016-06-13 14:04:52,641  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 28.0 (TID 39)
2016-06-13 14:04:52,645  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:52,645  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:52,649  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 28.0 (TID 40). 45217 bytes result sent to driver
2016-06-13 14:04:52,652  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 28.0 (TID 39). 45217 bytes result sent to driver
2016-06-13 14:04:52,653  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 28.0 (TID 39) in 12 ms on localhost (1/2)
2016-06-13 14:04:52,653  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 28.0 (TID 40) in 12 ms on localhost (2/2)
2016-06-13 14:04:52,653  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 28.0, whose tasks have all completed, from pool 
2016-06-13 14:04:52,653  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 28 (treeAggregate at RowMatrix.scala:93) finished in 0.012 s
2016-06-13 14:04:52,654  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 18 finished: treeAggregate at RowMatrix.scala:93, took 0.020131 s
2016-06-13 14:04:52,669  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_40 stored as values in memory (estimated size 124.9 KB, free 91.6 MB)
2016-06-13 14:04:52,671  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_40_piece0 stored as bytes in memory (estimated size 125.0 KB, free 91.7 MB)
2016-06-13 14:04:52,672  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_40_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:52,673  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 40 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:52,681  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:52,682  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 19 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:52,682  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 29 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:52,682  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:52,683  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:52,683  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 29 (MapPartitionsRDD[62] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:52,684  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_41 stored as values in memory (estimated size 55.2 KB, free 91.7 MB)
2016-06-13 14:04:52,686  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_41_piece0 stored as bytes in memory (estimated size 8.1 KB, free 91.7 MB)
2016-06-13 14:04:52,687  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_41_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:52,687  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 41 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:52,688  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 29 (MapPartitionsRDD[62] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:52,688  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 29.0 with 2 tasks
2016-06-13 14:04:52,692  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 29.0 (TID 41, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:52,692  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 29.0 (TID 42, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:52,692  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 29.0 (TID 41)
2016-06-13 14:04:52,692  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 29.0 (TID 42)
2016-06-13 14:04:52,698  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:52,699  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:52,703  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 29.0 (TID 41). 45217 bytes result sent to driver
2016-06-13 14:04:52,705  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 29.0 (TID 42). 45217 bytes result sent to driver
2016-06-13 14:04:52,707  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 29.0 (TID 42) in 15 ms on localhost (1/2)
2016-06-13 14:04:52,709  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 29.0 (TID 41) in 17 ms on localhost (2/2)
2016-06-13 14:04:52,709  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 29 (treeAggregate at RowMatrix.scala:93) finished in 0.021 s
2016-06-13 14:04:52,709  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 29.0, whose tasks have all completed, from pool 
2016-06-13 14:04:52,711  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 19 finished: treeAggregate at RowMatrix.scala:93, took 0.029286 s
2016-06-13 14:04:52,728  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_42 stored as values in memory (estimated size 124.9 KB, free 91.9 MB)
2016-06-13 14:04:52,730  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_42_piece0 stored as bytes in memory (estimated size 125.0 KB, free 92.0 MB)
2016-06-13 14:04:52,730  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_42_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:52,730  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 42 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:52,737  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:52,738  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 20 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:52,738  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 30 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:52,738  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:52,738  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:52,738  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 30 (MapPartitionsRDD[63] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:52,742  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_43 stored as values in memory (estimated size 55.2 KB, free 92.0 MB)
2016-06-13 14:04:52,744  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_43_piece0 stored as bytes in memory (estimated size 8.1 KB, free 92.1 MB)
2016-06-13 14:04:52,744  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_43_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:52,744  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 43 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:52,745  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 30 (MapPartitionsRDD[63] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:52,745  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 30.0 with 2 tasks
2016-06-13 14:04:52,745  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 30.0 (TID 43, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:52,746  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 30.0 (TID 44, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:52,746  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 30.0 (TID 43)
2016-06-13 14:04:52,746  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 30.0 (TID 44)
2016-06-13 14:04:52,749  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:52,749  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:52,764  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 30.0 (TID 43). 45217 bytes result sent to driver
2016-06-13 14:04:52,764  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 30.0 (TID 44). 45217 bytes result sent to driver
2016-06-13 14:04:52,765  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 30.0 (TID 43) in 20 ms on localhost (1/2)
2016-06-13 14:04:52,765  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 30.0 (TID 44) in 20 ms on localhost (2/2)
2016-06-13 14:04:52,765  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 30.0, whose tasks have all completed, from pool 
2016-06-13 14:04:52,765  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 30 (treeAggregate at RowMatrix.scala:93) finished in 0.020 s
2016-06-13 14:04:52,766  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 20 finished: treeAggregate at RowMatrix.scala:93, took 0.029295 s
2016-06-13 14:04:52,775  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_44 stored as values in memory (estimated size 124.9 KB, free 92.2 MB)
2016-06-13 14:04:52,777  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_44_piece0 stored as bytes in memory (estimated size 125.0 KB, free 92.3 MB)
2016-06-13 14:04:52,777  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_44_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:52,778  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 44 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:52,792  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:52,793  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 21 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:52,793  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 31 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:52,793  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:52,807  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:52,807  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 31 (MapPartitionsRDD[64] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:52,809  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_45 stored as values in memory (estimated size 55.2 KB, free 92.4 MB)
2016-06-13 14:04:52,810  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_45_piece0 stored as bytes in memory (estimated size 8.1 KB, free 92.4 MB)
2016-06-13 14:04:52,818  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_45_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:52,819  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 45 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:52,819  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 31 (MapPartitionsRDD[64] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:52,819  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 31.0 with 2 tasks
2016-06-13 14:04:52,820  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 31.0 (TID 45, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:52,820  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 31.0 (TID 46, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:52,820  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 31.0 (TID 45)
2016-06-13 14:04:52,823  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:52,826  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 31.0 (TID 46)
2016-06-13 14:04:52,829  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:52,832  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 31.0 (TID 46). 45217 bytes result sent to driver
2016-06-13 14:04:52,832  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 31.0 (TID 45). 45217 bytes result sent to driver
2016-06-13 14:04:52,833  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 31.0 (TID 46) in 13 ms on localhost (1/2)
2016-06-13 14:04:52,834  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 31.0 (TID 45) in 15 ms on localhost (2/2)
2016-06-13 14:04:52,834  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 31 (treeAggregate at RowMatrix.scala:93) finished in 0.015 s
2016-06-13 14:04:52,836  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 21 finished: treeAggregate at RowMatrix.scala:93, took 0.043279 s
2016-06-13 14:04:52,842  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_46 stored as values in memory (estimated size 124.9 KB, free 92.5 MB)
2016-06-13 14:04:52,834  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 31.0, whose tasks have all completed, from pool 
2016-06-13 14:04:52,847  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_46_piece0 stored as bytes in memory (estimated size 125.0 KB, free 92.6 MB)
2016-06-13 14:04:52,847  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_46_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:52,850  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 46 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:52,859  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:52,868  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 22 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:52,868  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 32 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:52,868  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:52,869  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:52,869  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 32 (MapPartitionsRDD[65] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:52,871  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_47 stored as values in memory (estimated size 55.2 KB, free 92.7 MB)
2016-06-13 14:04:52,872  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_47_piece0 stored as bytes in memory (estimated size 8.1 KB, free 92.7 MB)
2016-06-13 14:04:52,873  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_47_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:52,873  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 47 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:52,873  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 32 (MapPartitionsRDD[65] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:52,873  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 32.0 with 2 tasks
2016-06-13 14:04:52,874  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 32.0 (TID 47, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:52,874  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 32.0 (TID 48, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:52,875  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 32.0 (TID 47)
2016-06-13 14:04:52,875  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 32.0 (TID 48)
2016-06-13 14:04:52,879  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:52,885  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 32.0 (TID 48). 45217 bytes result sent to driver
2016-06-13 14:04:52,882  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:52,887  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 32.0 (TID 48) in 13 ms on localhost (1/2)
2016-06-13 14:04:52,889  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 32.0 (TID 47). 45217 bytes result sent to driver
2016-06-13 14:04:52,890  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 32.0 (TID 47) in 16 ms on localhost (2/2)
2016-06-13 14:04:52,890  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 32 (treeAggregate at RowMatrix.scala:93) finished in 0.005 s
2016-06-13 14:04:52,891  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 32.0, whose tasks have all completed, from pool 
2016-06-13 14:04:52,893  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 22 finished: treeAggregate at RowMatrix.scala:93, took 0.027256 s
2016-06-13 14:04:52,901  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_48 stored as values in memory (estimated size 124.9 KB, free 92.8 MB)
2016-06-13 14:04:52,903  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_48_piece0 stored as bytes in memory (estimated size 125.0 KB, free 92.9 MB)
2016-06-13 14:04:52,906  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_48_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:52,907  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 48 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:52,916  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:52,918  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 23 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:52,918  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 33 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:52,918  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:52,918  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:52,918  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 33 (MapPartitionsRDD[66] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:52,920  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_49 stored as values in memory (estimated size 55.2 KB, free 93.0 MB)
2016-06-13 14:04:52,921  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_49_piece0 stored as bytes in memory (estimated size 8.1 KB, free 93.0 MB)
2016-06-13 14:04:52,923  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_49_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:52,923  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 49 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:52,923  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 33 (MapPartitionsRDD[66] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:52,924  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 33.0 with 2 tasks
2016-06-13 14:04:52,925  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 33.0 (TID 49, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:52,927  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 33.0 (TID 50, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:52,927  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 33.0 (TID 49)
2016-06-13 14:04:52,927  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 33.0 (TID 50)
2016-06-13 14:04:52,935  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:52,937  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:52,940  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 33.0 (TID 50). 45217 bytes result sent to driver
2016-06-13 14:04:52,940  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 33.0 (TID 49). 45217 bytes result sent to driver
2016-06-13 14:04:52,941  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 33.0 (TID 50) in 16 ms on localhost (1/2)
2016-06-13 14:04:52,941  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 33.0 (TID 49) in 16 ms on localhost (2/2)
2016-06-13 14:04:52,942  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 33.0, whose tasks have all completed, from pool 
2016-06-13 14:04:52,942  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 33 (treeAggregate at RowMatrix.scala:93) finished in 0.017 s
2016-06-13 14:04:52,942  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 23 finished: treeAggregate at RowMatrix.scala:93, took 0.025213 s
2016-06-13 14:04:52,947  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_50 stored as values in memory (estimated size 124.9 KB, free 93.1 MB)
2016-06-13 14:04:52,949  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_50_piece0 stored as bytes in memory (estimated size 125.0 KB, free 93.2 MB)
2016-06-13 14:04:52,949  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_50_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:52,950  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 50 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:52,957  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:52,958  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 24 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:52,958  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 34 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:52,958  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:52,958  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:52,958  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 34 (MapPartitionsRDD[67] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:52,959  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_51 stored as values in memory (estimated size 55.2 KB, free 93.3 MB)
2016-06-13 14:04:52,960  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_51_piece0 stored as bytes in memory (estimated size 8.1 KB, free 93.3 MB)
2016-06-13 14:04:52,961  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_51_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:52,962  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 51 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:52,964  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 34 (MapPartitionsRDD[67] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:52,965  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 34.0 with 2 tasks
2016-06-13 14:04:52,965  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 34.0 (TID 51, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:52,965  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 34.0 (TID 52, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:52,966  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 34.0 (TID 51)
2016-06-13 14:04:52,966  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 34.0 (TID 52)
2016-06-13 14:04:52,969  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:52,969  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:52,972  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 34.0 (TID 52). 45217 bytes result sent to driver
2016-06-13 14:04:52,972  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 34.0 (TID 52) in 7 ms on localhost (1/2)
2016-06-13 14:04:52,972  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 34.0 (TID 51). 45217 bytes result sent to driver
2016-06-13 14:04:52,974  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 34.0 (TID 51) in 9 ms on localhost (2/2)
2016-06-13 14:04:52,974  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 34 (treeAggregate at RowMatrix.scala:93) finished in 0.008 s
2016-06-13 14:04:52,974  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 34.0, whose tasks have all completed, from pool 
2016-06-13 14:04:52,974  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 24 finished: treeAggregate at RowMatrix.scala:93, took 0.017035 s
2016-06-13 14:04:52,981  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_52 stored as values in memory (estimated size 124.9 KB, free 93.4 MB)
2016-06-13 14:04:52,983  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_52_piece0 stored as bytes in memory (estimated size 125.0 KB, free 93.5 MB)
2016-06-13 14:04:52,983  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_52_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:52,984  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 52 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:52,992  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:52,993  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 25 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:52,993  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 35 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:52,993  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:52,994  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:52,994  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 35 (MapPartitionsRDD[68] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:53,002  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_53 stored as values in memory (estimated size 55.2 KB, free 93.6 MB)
2016-06-13 14:04:53,004  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_53_piece0 stored as bytes in memory (estimated size 8.1 KB, free 93.6 MB)
2016-06-13 14:04:53,004  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_53_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,005  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 53 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:53,005  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 35 (MapPartitionsRDD[68] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,005  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 35.0 with 2 tasks
2016-06-13 14:04:53,006  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 35.0 (TID 53, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,006  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 35.0 (TID 54, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,006  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 35.0 (TID 53)
2016-06-13 14:04:53,007  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 35.0 (TID 54)
2016-06-13 14:04:53,010  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:53,012  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:53,013  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 35.0 (TID 54). 45217 bytes result sent to driver
2016-06-13 14:04:53,014  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 35.0 (TID 54) in 8 ms on localhost (1/2)
2016-06-13 14:04:53,014  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 35.0 (TID 53). 45217 bytes result sent to driver
2016-06-13 14:04:53,016  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 35.0 (TID 53) in 10 ms on localhost (2/2)
2016-06-13 14:04:53,016  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 35.0, whose tasks have all completed, from pool 
2016-06-13 14:04:53,016  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 35 (treeAggregate at RowMatrix.scala:93) finished in 0.003 s
2016-06-13 14:04:53,017  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 25 finished: treeAggregate at RowMatrix.scala:93, took 0.024174 s
2016-06-13 14:04:53,038  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_54 stored as values in memory (estimated size 124.9 KB, free 93.7 MB)
2016-06-13 14:04:53,040  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_54_piece0 stored as bytes in memory (estimated size 125.0 KB, free 93.8 MB)
2016-06-13 14:04:53,041  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_54_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,041  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 54 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:53,052  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:53,053  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 26 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:53,053  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 36 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,053  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:53,054  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:53,054  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 36 (MapPartitionsRDD[69] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:53,059  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_55 stored as values in memory (estimated size 55.2 KB, free 93.9 MB)
2016-06-13 14:04:53,060  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_55_piece0 stored as bytes in memory (estimated size 8.1 KB, free 93.9 MB)
2016-06-13 14:04:53,061  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_55_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,061  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 55 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:53,061  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 36 (MapPartitionsRDD[69] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,062  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 36.0 with 2 tasks
2016-06-13 14:04:53,062  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 36.0 (TID 55, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,063  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 36.0 (TID 56, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,063  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 36.0 (TID 55)
2016-06-13 14:04:53,064  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 36.0 (TID 56)
2016-06-13 14:04:53,066  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:53,067  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:53,069  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 36.0 (TID 55). 45217 bytes result sent to driver
2016-06-13 14:04:53,069  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 36.0 (TID 56). 45217 bytes result sent to driver
2016-06-13 14:04:53,070  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 36.0 (TID 56) in 8 ms on localhost (1/2)
2016-06-13 14:04:53,070  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 36.0 (TID 55) in 8 ms on localhost (2/2)
2016-06-13 14:04:53,071  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 36.0, whose tasks have all completed, from pool 
2016-06-13 14:04:53,077  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 36 (treeAggregate at RowMatrix.scala:93) finished in 0.015 s
2016-06-13 14:04:53,078  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 26 finished: treeAggregate at RowMatrix.scala:93, took 0.025271 s
2016-06-13 14:04:53,083  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_56 stored as values in memory (estimated size 124.9 KB, free 94.0 MB)
2016-06-13 14:04:53,085  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_56_piece0 stored as bytes in memory (estimated size 125.0 KB, free 94.1 MB)
2016-06-13 14:04:53,086  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_56_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,086  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 56 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:53,093  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:53,094  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 27 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:53,094  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 37 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,094  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:53,094  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:53,094  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 37 (MapPartitionsRDD[70] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:53,097  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_57 stored as values in memory (estimated size 55.2 KB, free 94.2 MB)
2016-06-13 14:04:53,099  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_57_piece0 stored as bytes in memory (estimated size 8.1 KB, free 94.2 MB)
2016-06-13 14:04:53,099  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_57_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,100  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 57 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:53,100  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 37 (MapPartitionsRDD[70] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,101  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 37.0 with 2 tasks
2016-06-13 14:04:53,102  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 37.0 (TID 57, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,102  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 37.0 (TID 58, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,102  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 37.0 (TID 57)
2016-06-13 14:04:53,105  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:53,107  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 37.0 (TID 58)
2016-06-13 14:04:53,108  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 37.0 (TID 57). 45217 bytes result sent to driver
2016-06-13 14:04:53,109  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:53,111  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 37.0 (TID 57) in 10 ms on localhost (1/2)
2016-06-13 14:04:53,114  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 37.0 (TID 58). 45217 bytes result sent to driver
2016-06-13 14:04:53,115  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 37.0 (TID 58) in 13 ms on localhost (2/2)
2016-06-13 14:04:53,115  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 37.0, whose tasks have all completed, from pool 
2016-06-13 14:04:53,116  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 37 (treeAggregate at RowMatrix.scala:93) finished in 0.014 s
2016-06-13 14:04:53,117  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 27 finished: treeAggregate at RowMatrix.scala:93, took 0.023742 s
2016-06-13 14:04:53,126  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_58 stored as values in memory (estimated size 124.9 KB, free 94.3 MB)
2016-06-13 14:04:53,128  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_58_piece0 stored as bytes in memory (estimated size 125.0 KB, free 94.4 MB)
2016-06-13 14:04:53,129  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_58_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,129  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 58 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:53,137  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:53,139  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 28 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:53,139  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 38 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,139  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:53,139  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:53,140  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 38 (MapPartitionsRDD[71] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:53,141  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_59 stored as values in memory (estimated size 55.2 KB, free 94.5 MB)
2016-06-13 14:04:53,143  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_59_piece0 stored as bytes in memory (estimated size 8.1 KB, free 94.5 MB)
2016-06-13 14:04:53,143  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_59_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,144  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 59 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:53,144  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 38 (MapPartitionsRDD[71] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,144  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 38.0 with 2 tasks
2016-06-13 14:04:53,145  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 38.0 (TID 59, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,146  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 38.0 (TID 60, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,146  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 38.0 (TID 59)
2016-06-13 14:04:53,149  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:53,149  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 38.0 (TID 60)
2016-06-13 14:04:53,152  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 38.0 (TID 59). 45217 bytes result sent to driver
2016-06-13 14:04:53,152  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:53,156  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 38.0 (TID 59) in 11 ms on localhost (1/2)
2016-06-13 14:04:53,159  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 38.0 (TID 60). 45217 bytes result sent to driver
2016-06-13 14:04:53,160  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 38.0 (TID 60) in 15 ms on localhost (2/2)
2016-06-13 14:04:53,161  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 38.0, whose tasks have all completed, from pool 
2016-06-13 14:04:53,161  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 38 (treeAggregate at RowMatrix.scala:93) finished in 0.016 s
2016-06-13 14:04:53,162  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 28 finished: treeAggregate at RowMatrix.scala:93, took 0.023938 s
2016-06-13 14:04:53,165  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_60 stored as values in memory (estimated size 124.9 KB, free 94.6 MB)
2016-06-13 14:04:53,166  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_60_piece0 stored as bytes in memory (estimated size 125.0 KB, free 94.7 MB)
2016-06-13 14:04:53,173  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_60_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,174  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 60 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:53,186  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:53,187  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 29 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:53,187  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 39 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,187  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:53,188  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:53,188  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 39 (MapPartitionsRDD[72] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:53,190  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_61 stored as values in memory (estimated size 55.2 KB, free 94.8 MB)
2016-06-13 14:04:53,191  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_61_piece0 stored as bytes in memory (estimated size 8.1 KB, free 94.8 MB)
2016-06-13 14:04:53,193  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_61_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,193  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 61 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:53,194  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 39 (MapPartitionsRDD[72] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,194  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 39.0 with 2 tasks
2016-06-13 14:04:53,195  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 39.0 (TID 61, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,195  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 39.0 (TID 62, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,196  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 39.0 (TID 61)
2016-06-13 14:04:53,198  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 39.0 (TID 62)
2016-06-13 14:04:53,198  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:53,201  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 39.0 (TID 61). 45217 bytes result sent to driver
2016-06-13 14:04:53,203  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 39.0 (TID 61) in 8 ms on localhost (1/2)
2016-06-13 14:04:53,204  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:53,206  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 39.0 (TID 62). 45217 bytes result sent to driver
2016-06-13 14:04:53,208  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 39.0 (TID 62) in 13 ms on localhost (2/2)
2016-06-13 14:04:53,208  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 39 (treeAggregate at RowMatrix.scala:93) finished in 0.013 s
2016-06-13 14:04:53,208  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 39.0, whose tasks have all completed, from pool 
2016-06-13 14:04:53,208  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 29 finished: treeAggregate at RowMatrix.scala:93, took 0.022142 s
2016-06-13 14:04:53,211  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_62 stored as values in memory (estimated size 124.9 KB, free 94.9 MB)
2016-06-13 14:04:53,213  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_62_piece0 stored as bytes in memory (estimated size 125.0 KB, free 95.1 MB)
2016-06-13 14:04:53,214  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_62_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,214  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 62 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:53,227  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:53,228  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 30 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:53,228  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 40 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,228  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:53,230  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:53,230  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 40 (MapPartitionsRDD[73] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:53,232  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_63 stored as values in memory (estimated size 55.2 KB, free 95.1 MB)
2016-06-13 14:04:53,234  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_63_piece0 stored as bytes in memory (estimated size 8.1 KB, free 95.1 MB)
2016-06-13 14:04:53,242  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_63_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,243  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 63 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:53,243  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 40 (MapPartitionsRDD[73] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,243  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 40.0 with 2 tasks
2016-06-13 14:04:53,245  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 40.0 (TID 63, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,245  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 40.0 (TID 64, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,246  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 40.0 (TID 63)
2016-06-13 14:04:53,249  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:53,250  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 40.0 (TID 64)
2016-06-13 14:04:53,253  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:53,256  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 40.0 (TID 64). 45217 bytes result sent to driver
2016-06-13 14:04:53,258  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 40.0 (TID 63). 45217 bytes result sent to driver
2016-06-13 14:04:53,263  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 40.0 (TID 64) in 18 ms on localhost (1/2)
2016-06-13 14:04:53,271  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 40.0 (TID 63) in 26 ms on localhost (2/2)
2016-06-13 14:04:53,271  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 40 (treeAggregate at RowMatrix.scala:93) finished in 0.026 s
2016-06-13 14:04:53,271  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 40.0, whose tasks have all completed, from pool 
2016-06-13 14:04:53,272  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 30 finished: treeAggregate at RowMatrix.scala:93, took 0.044745 s
2016-06-13 14:04:53,276  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_64 stored as values in memory (estimated size 124.9 KB, free 95.2 MB)
2016-06-13 14:04:53,278  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_64_piece0 stored as bytes in memory (estimated size 125.0 KB, free 95.4 MB)
2016-06-13 14:04:53,278  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_64_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,279  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 64 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:53,290  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:53,295  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 31 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:53,295  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 41 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,295  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:53,295  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:53,296  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 41 (MapPartitionsRDD[74] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:53,297  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_65 stored as values in memory (estimated size 55.2 KB, free 95.4 MB)
2016-06-13 14:04:53,300  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_65_piece0 stored as bytes in memory (estimated size 8.1 KB, free 95.4 MB)
2016-06-13 14:04:53,300  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_65_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,300  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 65 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:53,301  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 41 (MapPartitionsRDD[74] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,301  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 41.0 with 2 tasks
2016-06-13 14:04:53,302  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 41.0 (TID 65, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,303  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 41.0 (TID 66, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,303  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 41.0 (TID 65)
2016-06-13 14:04:53,306  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:53,306  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 41.0 (TID 66)
2016-06-13 14:04:53,308  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 41.0 (TID 65). 45217 bytes result sent to driver
2016-06-13 14:04:53,309  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:53,309  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 41.0 (TID 65) in 7 ms on localhost (1/2)
2016-06-13 14:04:53,311  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 41.0 (TID 66). 45217 bytes result sent to driver
2016-06-13 14:04:53,313  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 41.0 (TID 66) in 11 ms on localhost (2/2)
2016-06-13 14:04:53,313  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 41.0, whose tasks have all completed, from pool 
2016-06-13 14:04:53,314  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 41 (treeAggregate at RowMatrix.scala:93) finished in 0.012 s
2016-06-13 14:04:53,316  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 31 finished: treeAggregate at RowMatrix.scala:93, took 0.021799 s
2016-06-13 14:04:53,322  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_66 stored as values in memory (estimated size 124.9 KB, free 95.5 MB)
2016-06-13 14:04:53,324  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_66_piece0 stored as bytes in memory (estimated size 125.0 KB, free 95.7 MB)
2016-06-13 14:04:53,325  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_66_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,328  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 66 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:53,337  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:53,337  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 32 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:53,337  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 42 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,337  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:53,338  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:53,338  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 42 (MapPartitionsRDD[75] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:53,340  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_67 stored as values in memory (estimated size 55.2 KB, free 95.7 MB)
2016-06-13 14:04:53,341  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_67_piece0 stored as bytes in memory (estimated size 8.1 KB, free 95.7 MB)
2016-06-13 14:04:53,342  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_67_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,342  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 67 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:53,342  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 42 (MapPartitionsRDD[75] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,342  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 42.0 with 2 tasks
2016-06-13 14:04:53,343  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 42.0 (TID 67, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,344  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 42.0 (TID 68, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,344  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 42.0 (TID 67)
2016-06-13 14:04:53,344  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 42.0 (TID 68)
2016-06-13 14:04:53,348  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:53,348  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:53,351  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 42.0 (TID 68). 45217 bytes result sent to driver
2016-06-13 14:04:53,352  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 42.0 (TID 67). 45217 bytes result sent to driver
2016-06-13 14:04:53,352  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 42.0 (TID 68) in 9 ms on localhost (1/2)
2016-06-13 14:04:53,353  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 42.0 (TID 67) in 10 ms on localhost (2/2)
2016-06-13 14:04:53,353  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 42.0, whose tasks have all completed, from pool 
2016-06-13 14:04:53,353  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 42 (treeAggregate at RowMatrix.scala:93) finished in 0.005 s
2016-06-13 14:04:53,358  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 32 finished: treeAggregate at RowMatrix.scala:93, took 0.021088 s
2016-06-13 14:04:53,361  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_68 stored as values in memory (estimated size 124.9 KB, free 95.8 MB)
2016-06-13 14:04:53,363  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_68_piece0 stored as bytes in memory (estimated size 125.0 KB, free 96.0 MB)
2016-06-13 14:04:53,363  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_68_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,364  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 68 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:53,372  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:53,373  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 33 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:53,373  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 43 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,373  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:53,373  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:53,373  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 43 (MapPartitionsRDD[76] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:53,375  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_69 stored as values in memory (estimated size 55.2 KB, free 96.0 MB)
2016-06-13 14:04:53,376  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_69_piece0 stored as bytes in memory (estimated size 8.1 KB, free 96.0 MB)
2016-06-13 14:04:53,377  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_69_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,377  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 69 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:53,377  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 43 (MapPartitionsRDD[76] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,377  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 43.0 with 2 tasks
2016-06-13 14:04:53,378  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 43.0 (TID 69, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,378  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 43.0 (TID 70, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,379  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 43.0 (TID 70)
2016-06-13 14:04:53,379  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 43.0 (TID 69)
2016-06-13 14:04:53,381  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:53,382  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:53,385  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 43.0 (TID 70). 45217 bytes result sent to driver
2016-06-13 14:04:53,386  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 43.0 (TID 70) in 8 ms on localhost (1/2)
2016-06-13 14:04:53,388  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 43.0 (TID 69). 45217 bytes result sent to driver
2016-06-13 14:04:53,389  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 43.0 (TID 69) in 11 ms on localhost (2/2)
2016-06-13 14:04:53,389  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 43.0, whose tasks have all completed, from pool 
2016-06-13 14:04:53,390  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 43 (treeAggregate at RowMatrix.scala:93) finished in 0.012 s
2016-06-13 14:04:53,391  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 33 finished: treeAggregate at RowMatrix.scala:93, took 0.018584 s
2016-06-13 14:04:53,393  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_70 stored as values in memory (estimated size 124.9 KB, free 96.2 MB)
2016-06-13 14:04:53,395  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_70_piece0 stored as bytes in memory (estimated size 125.0 KB, free 96.3 MB)
2016-06-13 14:04:53,396  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_70_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,397  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 70 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:53,407  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:53,408  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 34 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:53,408  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 44 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,408  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:53,409  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:53,409  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 44 (MapPartitionsRDD[77] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:53,410  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_71 stored as values in memory (estimated size 55.2 KB, free 96.3 MB)
2016-06-13 14:04:53,412  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_71_piece0 stored as bytes in memory (estimated size 8.1 KB, free 96.3 MB)
2016-06-13 14:04:53,412  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_71_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,412  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 71 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:53,413  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 44 (MapPartitionsRDD[77] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,413  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 44.0 with 2 tasks
2016-06-13 14:04:53,414  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 44.0 (TID 71, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,414  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 44.0 (TID 72, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,414  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 44.0 (TID 71)
2016-06-13 14:04:53,415  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 44.0 (TID 72)
2016-06-13 14:04:53,420  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:53,423  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 44.0 (TID 72). 45217 bytes result sent to driver
2016-06-13 14:04:53,424  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:53,424  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 44.0 (TID 72) in 10 ms on localhost (1/2)
2016-06-13 14:04:53,426  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 44.0 (TID 71). 45217 bytes result sent to driver
2016-06-13 14:04:53,427  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 44.0 (TID 71) in 13 ms on localhost (2/2)
2016-06-13 14:04:53,428  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 44.0, whose tasks have all completed, from pool 
2016-06-13 14:04:53,428  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 44 (treeAggregate at RowMatrix.scala:93) finished in 0.005 s
2016-06-13 14:04:53,429  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 34 finished: treeAggregate at RowMatrix.scala:93, took 0.021429 s
2016-06-13 14:04:53,432  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_72 stored as values in memory (estimated size 124.9 KB, free 96.5 MB)
2016-06-13 14:04:53,433  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_72_piece0 stored as bytes in memory (estimated size 125.0 KB, free 96.6 MB)
2016-06-13 14:04:53,434  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_72_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,435  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 72 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:53,447  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:53,447  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 35 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:53,447  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 45 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,447  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:53,448  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:53,448  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 45 (MapPartitionsRDD[78] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:53,449  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_73 stored as values in memory (estimated size 55.2 KB, free 96.6 MB)
2016-06-13 14:04:53,451  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_73_piece0 stored as bytes in memory (estimated size 8.1 KB, free 96.6 MB)
2016-06-13 14:04:53,455  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_73_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,455  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 73 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:53,455  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 45 (MapPartitionsRDD[78] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,456  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 45.0 with 2 tasks
2016-06-13 14:04:53,457  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 45.0 (TID 73, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,457  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 45.0 (TID 74, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,457  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 45.0 (TID 73)
2016-06-13 14:04:53,460  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:53,462  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 45.0 (TID 74)
2016-06-13 14:04:53,465  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:53,468  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 45.0 (TID 74). 45217 bytes result sent to driver
2016-06-13 14:04:53,469  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 45.0 (TID 73). 45217 bytes result sent to driver
2016-06-13 14:04:53,470  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 45.0 (TID 74) in 13 ms on localhost (1/2)
2016-06-13 14:04:53,470  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 45.0 (TID 73) in 14 ms on localhost (2/2)
2016-06-13 14:04:53,470  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 45.0, whose tasks have all completed, from pool 
2016-06-13 14:04:53,471  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 45 (treeAggregate at RowMatrix.scala:93) finished in 0.014 s
2016-06-13 14:04:53,471  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 35 finished: treeAggregate at RowMatrix.scala:93, took 0.024245 s
2016-06-13 14:04:53,474  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_74 stored as values in memory (estimated size 124.9 KB, free 96.8 MB)
2016-06-13 14:04:53,475  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_74_piece0 stored as bytes in memory (estimated size 125.0 KB, free 96.9 MB)
2016-06-13 14:04:53,475  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_74_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,476  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 74 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:53,494  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:53,494  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 36 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:53,494  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 46 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,494  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:53,495  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:53,495  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 46 (MapPartitionsRDD[79] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:53,497  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_75 stored as values in memory (estimated size 55.2 KB, free 96.9 MB)
2016-06-13 14:04:53,498  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_75_piece0 stored as bytes in memory (estimated size 8.1 KB, free 96.9 MB)
2016-06-13 14:04:53,498  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_75_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,499  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 75 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:53,499  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 46 (MapPartitionsRDD[79] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,499  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 46.0 with 2 tasks
2016-06-13 14:04:53,502  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 46.0 (TID 75, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,503  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 46.0 (TID 76, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,503  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 46.0 (TID 75)
2016-06-13 14:04:53,505  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:53,506  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 46.0 (TID 76)
2016-06-13 14:04:53,509  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:53,520  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 46.0 (TID 75). 45217 bytes result sent to driver
2016-06-13 14:04:53,522  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 46.0 (TID 76). 45217 bytes result sent to driver
2016-06-13 14:04:53,530  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 46.0 (TID 75) in 28 ms on localhost (1/2)
2016-06-13 14:04:53,530  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 46.0 (TID 76) in 27 ms on localhost (2/2)
2016-06-13 14:04:53,530  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 46 (treeAggregate at RowMatrix.scala:93) finished in 0.028 s
2016-06-13 14:04:53,530  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 46.0, whose tasks have all completed, from pool 
2016-06-13 14:04:53,531  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 36 finished: treeAggregate at RowMatrix.scala:93, took 0.037081 s
2016-06-13 14:04:53,533  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_76 stored as values in memory (estimated size 124.9 KB, free 97.1 MB)
2016-06-13 14:04:53,536  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_76_piece0 stored as bytes in memory (estimated size 125.0 KB, free 97.2 MB)
2016-06-13 14:04:53,539  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_76_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,539  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 76 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:53,548  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:53,549  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 37 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:53,549  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 47 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,549  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:53,550  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:53,550  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 47 (MapPartitionsRDD[80] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:53,552  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_77 stored as values in memory (estimated size 55.2 KB, free 97.2 MB)
2016-06-13 14:04:53,553  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_77_piece0 stored as bytes in memory (estimated size 8.1 KB, free 97.3 MB)
2016-06-13 14:04:53,554  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_77_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,554  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 77 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:53,555  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 47 (MapPartitionsRDD[80] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,555  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 47.0 with 2 tasks
2016-06-13 14:04:53,556  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 47.0 (TID 77, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,556  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 47.0 (TID 78, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,556  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 47.0 (TID 77)
2016-06-13 14:04:53,556  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 47.0 (TID 78)
2016-06-13 14:04:53,559  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:53,562  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 47.0 (TID 78). 45217 bytes result sent to driver
2016-06-13 14:04:53,565  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:53,567  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 47.0 (TID 78) in 11 ms on localhost (1/2)
2016-06-13 14:04:53,568  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 47.0 (TID 77). 45217 bytes result sent to driver
2016-06-13 14:04:53,569  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 47.0 (TID 77) in 13 ms on localhost (2/2)
2016-06-13 14:04:53,569  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 47 (treeAggregate at RowMatrix.scala:93) finished in 0.003 s
2016-06-13 14:04:53,569  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 47.0, whose tasks have all completed, from pool 
2016-06-13 14:04:53,569  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 37 finished: treeAggregate at RowMatrix.scala:93, took 0.020598 s
2016-06-13 14:04:53,571  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_78 stored as values in memory (estimated size 124.9 KB, free 97.4 MB)
2016-06-13 14:04:53,572  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_78_piece0 stored as bytes in memory (estimated size 125.0 KB, free 97.5 MB)
2016-06-13 14:04:53,573  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_78_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,574  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 78 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:53,578  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:53,579  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 38 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:53,579  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 48 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,579  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:53,579  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:53,579  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 48 (MapPartitionsRDD[81] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:53,581  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_79 stored as values in memory (estimated size 55.2 KB, free 97.6 MB)
2016-06-13 14:04:53,582  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_79_piece0 stored as bytes in memory (estimated size 8.1 KB, free 97.6 MB)
2016-06-13 14:04:53,582  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_79_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,583  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 79 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:53,583  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 48 (MapPartitionsRDD[81] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,583  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 48.0 with 2 tasks
2016-06-13 14:04:53,584  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 48.0 (TID 79, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,584  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 48.0 (TID 80, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,584  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 48.0 (TID 79)
2016-06-13 14:04:53,584  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 48.0 (TID 80)
2016-06-13 14:04:53,590  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:53,590  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:53,593  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 48.0 (TID 80). 45217 bytes result sent to driver
2016-06-13 14:04:53,594  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 48.0 (TID 80) in 10 ms on localhost (1/2)
2016-06-13 14:04:53,596  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 48.0 (TID 79). 45217 bytes result sent to driver
2016-06-13 14:04:53,597  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 48.0 (TID 79) in 14 ms on localhost (2/2)
2016-06-13 14:04:53,598  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 48.0, whose tasks have all completed, from pool 
2016-06-13 14:04:53,598  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 48 (treeAggregate at RowMatrix.scala:93) finished in 0.012 s
2016-06-13 14:04:53,598  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 38 finished: treeAggregate at RowMatrix.scala:93, took 0.020141 s
2016-06-13 14:04:53,601  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_80 stored as values in memory (estimated size 124.9 KB, free 97.7 MB)
2016-06-13 14:04:53,602  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_80_piece0 stored as bytes in memory (estimated size 125.0 KB, free 97.8 MB)
2016-06-13 14:04:53,603  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_80_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,603  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 80 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:53,610  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:53,613  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 39 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:53,613  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 49 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,613  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:53,614  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:53,614  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 49 (MapPartitionsRDD[82] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:53,616  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_81 stored as values in memory (estimated size 55.2 KB, free 97.9 MB)
2016-06-13 14:04:53,617  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_81_piece0 stored as bytes in memory (estimated size 8.1 KB, free 97.9 MB)
2016-06-13 14:04:53,617  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_81_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,618  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 81 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:53,618  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 49 (MapPartitionsRDD[82] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,618  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 49.0 with 2 tasks
2016-06-13 14:04:53,619  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 49.0 (TID 81, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,619  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 49.0 (TID 82, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,619  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 49.0 (TID 82)
2016-06-13 14:04:53,622  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:53,622  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 49.0 (TID 81)
2016-06-13 14:04:53,625  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:53,625  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 49.0 (TID 82). 45217 bytes result sent to driver
2016-06-13 14:04:53,626  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 49.0 (TID 82) in 7 ms on localhost (1/2)
2016-06-13 14:04:53,628  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 49.0 (TID 81). 45217 bytes result sent to driver
2016-06-13 14:04:53,643  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 49.0 (TID 81) in 24 ms on localhost (2/2)
2016-06-13 14:04:53,643  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 49 (treeAggregate at RowMatrix.scala:93) finished in 0.024 s
2016-06-13 14:04:53,643  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 49.0, whose tasks have all completed, from pool 
2016-06-13 14:04:53,644  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 39 finished: treeAggregate at RowMatrix.scala:93, took 0.033884 s
2016-06-13 14:04:53,646  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_82 stored as values in memory (estimated size 124.9 KB, free 98.0 MB)
2016-06-13 14:04:53,648  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_82_piece0 stored as bytes in memory (estimated size 125.0 KB, free 98.1 MB)
2016-06-13 14:04:53,648  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_82_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,649  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 82 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:53,658  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:53,659  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 40 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:53,659  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 50 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,659  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:53,659  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:53,660  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 50 (MapPartitionsRDD[83] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:53,661  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_83 stored as values in memory (estimated size 55.2 KB, free 98.2 MB)
2016-06-13 14:04:53,664  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_83_piece0 stored as bytes in memory (estimated size 8.1 KB, free 98.2 MB)
2016-06-13 14:04:53,664  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_83_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,665  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 83 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:53,665  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 50 (MapPartitionsRDD[83] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,666  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 50.0 with 2 tasks
2016-06-13 14:04:53,668  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 50.0 (TID 83, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,668  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 50.0 (TID 84, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,668  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 50.0 (TID 83)
2016-06-13 14:04:53,668  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 50.0 (TID 84)
2016-06-13 14:04:53,672  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:53,672  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:53,675  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 50.0 (TID 84). 45217 bytes result sent to driver
2016-06-13 14:04:53,678  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 50.0 (TID 83). 45217 bytes result sent to driver
2016-06-13 14:04:53,679  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 50.0 (TID 84) in 11 ms on localhost (1/2)
2016-06-13 14:04:53,680  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 50.0 (TID 83) in 13 ms on localhost (2/2)
2016-06-13 14:04:53,680  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 50.0, whose tasks have all completed, from pool 
2016-06-13 14:04:53,680  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 50 (treeAggregate at RowMatrix.scala:93) finished in 0.011 s
2016-06-13 14:04:53,681  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 40 finished: treeAggregate at RowMatrix.scala:93, took 0.022670 s
2016-06-13 14:04:53,685  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_84 stored as values in memory (estimated size 124.9 KB, free 98.3 MB)
2016-06-13 14:04:53,691  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_84_piece0 stored as bytes in memory (estimated size 125.0 KB, free 98.4 MB)
2016-06-13 14:04:53,692  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_84_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,692  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 84 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:53,700  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:53,701  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 41 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:53,701  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 51 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,701  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:53,701  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:53,702  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 51 (MapPartitionsRDD[84] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:53,703  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_85 stored as values in memory (estimated size 55.2 KB, free 98.5 MB)
2016-06-13 14:04:53,704  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_85_piece0 stored as bytes in memory (estimated size 8.1 KB, free 98.5 MB)
2016-06-13 14:04:53,705  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_85_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,705  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 85 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:53,705  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 51 (MapPartitionsRDD[84] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,706  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 51.0 with 2 tasks
2016-06-13 14:04:53,707  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 51.0 (TID 85, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,707  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 51.0 (TID 86, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,707  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 51.0 (TID 85)
2016-06-13 14:04:53,707  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 51.0 (TID 86)
2016-06-13 14:04:53,712  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:53,718  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 51.0 (TID 86). 45217 bytes result sent to driver
2016-06-13 14:04:53,721  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 51.0 (TID 86) in 14 ms on localhost (1/2)
2016-06-13 14:04:53,725  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:53,728  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 51.0 (TID 85). 45217 bytes result sent to driver
2016-06-13 14:04:53,731  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 51.0 (TID 85) in 25 ms on localhost (2/2)
2016-06-13 14:04:53,731  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 51.0, whose tasks have all completed, from pool 
2016-06-13 14:04:53,731  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 51 (treeAggregate at RowMatrix.scala:93) finished in 0.011 s
2016-06-13 14:04:53,733  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 41 finished: treeAggregate at RowMatrix.scala:93, took 0.032562 s
2016-06-13 14:04:53,740  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_86 stored as values in memory (estimated size 124.9 KB, free 98.6 MB)
2016-06-13 14:04:53,741  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_86_piece0 stored as bytes in memory (estimated size 125.0 KB, free 98.7 MB)
2016-06-13 14:04:53,742  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_86_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,742  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 86 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:53,753  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:53,753  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 42 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:53,753  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 52 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,753  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:53,754  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:53,754  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 52 (MapPartitionsRDD[85] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:53,756  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_87 stored as values in memory (estimated size 55.2 KB, free 98.8 MB)
2016-06-13 14:04:53,757  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_87_piece0 stored as bytes in memory (estimated size 8.1 KB, free 98.8 MB)
2016-06-13 14:04:53,757  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_87_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,758  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 87 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:53,758  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 52 (MapPartitionsRDD[85] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,758  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 52.0 with 2 tasks
2016-06-13 14:04:53,759  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 52.0 (TID 87, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,759  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 52.0 (TID 88, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,760  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 52.0 (TID 87)
2016-06-13 14:04:53,761  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 52.0 (TID 88)
2016-06-13 14:04:53,763  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:53,763  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:53,766  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 52.0 (TID 87). 45217 bytes result sent to driver
2016-06-13 14:04:53,768  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 52.0 (TID 88). 45217 bytes result sent to driver
2016-06-13 14:04:53,840  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 52.0 (TID 88) in 80 ms on localhost (1/2)
2016-06-13 14:04:53,840  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 52.0 (TID 87) in 81 ms on localhost (2/2)
2016-06-13 14:04:53,840  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 52.0, whose tasks have all completed, from pool 
2016-06-13 14:04:53,844  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 52 (treeAggregate at RowMatrix.scala:93) finished in 0.085 s
2016-06-13 14:04:53,846  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 42 finished: treeAggregate at RowMatrix.scala:93, took 0.092639 s
2016-06-13 14:04:53,847  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_85_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,848  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_88 stored as values in memory (estimated size 124.9 KB, free 98.8 MB)
2016-06-13 14:04:53,850  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_88_piece0 stored as bytes in memory (estimated size 125.0 KB, free 99.0 MB)
2016-06-13 14:04:53,850  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_88_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,850  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 47
2016-06-13 14:04:53,851  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_84_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,852  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_83_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,852  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 46
2016-06-13 14:04:53,853  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_82_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,853  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 88 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:53,854  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_81_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,855  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 45
2016-06-13 14:04:53,855  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_80_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,856  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_79_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,857  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 44
2016-06-13 14:04:53,857  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_78_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,858  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_77_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,859  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 43
2016-06-13 14:04:53,860  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_76_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,861  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_75_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,861  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 42
2016-06-13 14:04:53,862  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_74_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,863  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_73_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,863  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 41
2016-06-13 14:04:53,864  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_72_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,864  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_71_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,865  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 40
2016-06-13 14:04:53,865  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_70_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,866  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_69_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,867  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 39
2016-06-13 14:04:53,868  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_68_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,869  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_67_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,869  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 38
2016-06-13 14:04:53,870  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_66_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,871  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_65_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,871  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 37
2016-06-13 14:04:53,872  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_64_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,873  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_63_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,873  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 36
2016-06-13 14:04:53,874  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_62_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,875  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_61_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,876  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 35
2016-06-13 14:04:53,876  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:53,877  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 43 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:53,877  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 53 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,877  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:53,877  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_60_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,877  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:53,877  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 53 (MapPartitionsRDD[86] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:53,879  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_89 stored as values in memory (estimated size 55.2 KB, free 95.2 MB)
2016-06-13 14:04:53,880  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_89_piece0 stored as bytes in memory (estimated size 8.1 KB, free 95.2 MB)
2016-06-13 14:04:53,882  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_89_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,883  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 89 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:53,883  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 53 (MapPartitionsRDD[86] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,883  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 53.0 with 2 tasks
2016-06-13 14:04:53,884  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 53.0 (TID 89, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,884  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 53.0 (TID 90, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,884  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 53.0 (TID 89)
2016-06-13 14:04:53,884  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 53.0 (TID 90)
2016-06-13 14:04:53,887  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:53,887  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:53,889  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 53.0 (TID 89). 45217 bytes result sent to driver
2016-06-13 14:04:53,892  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_59_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,892  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 53.0 (TID 90). 45217 bytes result sent to driver
2016-06-13 14:04:53,893  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 34
2016-06-13 14:04:53,893  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 53.0 (TID 90) in 9 ms on localhost (1/2)
2016-06-13 14:04:53,894  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 53.0 (TID 89) in 10 ms on localhost (2/2)
2016-06-13 14:04:53,894  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 53.0, whose tasks have all completed, from pool 
2016-06-13 14:04:53,894  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_58_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,894  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 53 (treeAggregate at RowMatrix.scala:93) finished in 0.011 s
2016-06-13 14:04:53,894  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_57_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,895  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 33
2016-06-13 14:04:53,895  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_56_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,896  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_55_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,897  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 32
2016-06-13 14:04:53,897  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_54_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,898  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_53_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,899  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 31
2016-06-13 14:04:53,899  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 43 finished: treeAggregate at RowMatrix.scala:93, took 0.022357 s
2016-06-13 14:04:53,899  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_52_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,900  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_51_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,900  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 30
2016-06-13 14:04:53,901  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_50_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,902  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_49_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,903  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 29
2016-06-13 14:04:53,903  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_48_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,905  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_47_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,905  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 28
2016-06-13 14:04:53,905  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_90 stored as values in memory (estimated size 124.9 KB, free 93.3 MB)
2016-06-13 14:04:53,906  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_46_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,907  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_45_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,908  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 27
2016-06-13 14:04:53,907  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_90_piece0 stored as bytes in memory (estimated size 125.0 KB, free 93.2 MB)
2016-06-13 14:04:53,909  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_44_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,910  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_43_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,911  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 26
2016-06-13 14:04:53,911  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_42_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,912  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_41_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,913  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 25
2016-06-13 14:04:53,914  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_40_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,915  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_39_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,915  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 24
2016-06-13 14:04:53,916  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_38_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,918  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_90_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,918  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_37_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,919  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 23
2016-06-13 14:04:53,920  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_36_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:53,919  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 90 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:53,921  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_35_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,924  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 22
2016-06-13 14:04:53,924  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_34_piece0 on localhost:44356 in memory (size: 85.4 KB, free: 9.7 GB)
2016-06-13 14:04:53,927  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_33_piece0 on localhost:44356 in memory (size: 5.7 KB, free: 9.7 GB)
2016-06-13 14:04:53,927  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 21
2016-06-13 14:04:53,928  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_32_piece0 on localhost:44356 in memory (size: 5.6 KB, free: 9.7 GB)
2016-06-13 14:04:53,936  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:53,936  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 44 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:53,937  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 54 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,937  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:53,937  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:53,937  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 54 (MapPartitionsRDD[87] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:53,939  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_91 stored as values in memory (estimated size 55.2 KB, free 91.4 MB)
2016-06-13 14:04:53,940  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_91_piece0 stored as bytes in memory (estimated size 8.1 KB, free 91.4 MB)
2016-06-13 14:04:53,941  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 20
2016-06-13 14:04:53,942  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_91_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,942  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_31_piece0 on localhost:44356 in memory (size: 5.5 KB, free: 9.7 GB)
2016-06-13 14:04:53,943  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 19
2016-06-13 14:04:53,943  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 91 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:53,944  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 54 (MapPartitionsRDD[87] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,944  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 54.0 with 2 tasks
2016-06-13 14:04:53,945  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 54.0 (TID 91, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,945  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 54.0 (TID 92, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,945  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 54.0 (TID 91)
2016-06-13 14:04:53,945  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 54.0 (TID 92)
2016-06-13 14:04:53,948  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:53,953  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:53,953  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 54.0 (TID 92). 45217 bytes result sent to driver
2016-06-13 14:04:53,954  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 54.0 (TID 92) in 9 ms on localhost (1/2)
2016-06-13 14:04:53,956  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 54.0 (TID 91). 45217 bytes result sent to driver
2016-06-13 14:04:53,963  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 54.0 (TID 91) in 19 ms on localhost (2/2)
2016-06-13 14:04:53,963  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 54 (treeAggregate at RowMatrix.scala:93) finished in 0.018 s
2016-06-13 14:04:53,963  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 54.0, whose tasks have all completed, from pool 
2016-06-13 14:04:53,964  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 44 finished: treeAggregate at RowMatrix.scala:93, took 0.027877 s
2016-06-13 14:04:53,967  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_92 stored as values in memory (estimated size 124.9 KB, free 91.5 MB)
2016-06-13 14:04:53,968  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_92_piece0 stored as bytes in memory (estimated size 124.9 KB, free 91.7 MB)
2016-06-13 14:04:53,969  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_92_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:53,969  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 92 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:53,981  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:53,982  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 45 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:53,982  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 55 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,982  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:53,983  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:53,983  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 55 (MapPartitionsRDD[88] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:53,985  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_93 stored as values in memory (estimated size 55.2 KB, free 91.7 MB)
2016-06-13 14:04:53,986  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_93_piece0 stored as bytes in memory (estimated size 8.1 KB, free 91.7 MB)
2016-06-13 14:04:53,987  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_93_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:53,987  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 93 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:53,987  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 55 (MapPartitionsRDD[88] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:53,988  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 55.0 with 2 tasks
2016-06-13 14:04:53,988  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 55.0 (TID 93, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,989  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 55.0 (TID 94, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:53,989  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 55.0 (TID 93)
2016-06-13 14:04:53,989  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 55.0 (TID 94)
2016-06-13 14:04:53,992  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:53,996  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:54,000  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 55.0 (TID 94). 45217 bytes result sent to driver
2016-06-13 14:04:54,001  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 55.0 (TID 93). 45217 bytes result sent to driver
2016-06-13 14:04:54,002  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 55.0 (TID 94) in 13 ms on localhost (1/2)
2016-06-13 14:04:54,002  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 55.0 (TID 93) in 14 ms on localhost (2/2)
2016-06-13 14:04:54,002  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 55.0, whose tasks have all completed, from pool 
2016-06-13 14:04:54,003  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 55 (treeAggregate at RowMatrix.scala:93) finished in 0.001 s
2016-06-13 14:04:54,004  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 45 finished: treeAggregate at RowMatrix.scala:93, took 0.021744 s
2016-06-13 14:04:54,006  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_94 stored as values in memory (estimated size 124.9 KB, free 91.9 MB)
2016-06-13 14:04:54,008  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_94_piece0 stored as bytes in memory (estimated size 125.0 KB, free 92.0 MB)
2016-06-13 14:04:54,008  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_94_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:54,008  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 94 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:54,013  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:54,013  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 46 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:54,013  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 56 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,013  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:54,014  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:54,014  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 56 (MapPartitionsRDD[89] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:54,015  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_95 stored as values in memory (estimated size 55.2 KB, free 92.0 MB)
2016-06-13 14:04:54,016  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_95_piece0 stored as bytes in memory (estimated size 8.1 KB, free 92.0 MB)
2016-06-13 14:04:54,016  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_95_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:54,017  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 95 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:54,017  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 56 (MapPartitionsRDD[89] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,017  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 56.0 with 2 tasks
2016-06-13 14:04:54,018  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 56.0 (TID 95, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,018  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 56.0 (TID 96, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,018  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 56.0 (TID 95)
2016-06-13 14:04:54,021  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:54,022  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 56.0 (TID 96)
2016-06-13 14:04:54,023  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 56.0 (TID 95). 45217 bytes result sent to driver
2016-06-13 14:04:54,024  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:54,026  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 56.0 (TID 96). 45217 bytes result sent to driver
2016-06-13 14:04:54,027  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 56.0 (TID 95) in 10 ms on localhost (1/2)
2016-06-13 14:04:54,027  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 56.0 (TID 96) in 9 ms on localhost (2/2)
2016-06-13 14:04:54,027  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 56 (treeAggregate at RowMatrix.scala:93) finished in 0.010 s
2016-06-13 14:04:54,027  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 56.0, whose tasks have all completed, from pool 
2016-06-13 14:04:54,029  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 46 finished: treeAggregate at RowMatrix.scala:93, took 0.015677 s
2016-06-13 14:04:54,034  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_96 stored as values in memory (estimated size 124.9 KB, free 92.2 MB)
2016-06-13 14:04:54,037  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_96_piece0 stored as bytes in memory (estimated size 125.0 KB, free 92.3 MB)
2016-06-13 14:04:54,038  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_96_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:54,042  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 96 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:54,050  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:54,051  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 47 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:54,051  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 57 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,051  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:54,051  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:54,052  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 57 (MapPartitionsRDD[90] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:54,054  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_97 stored as values in memory (estimated size 55.2 KB, free 92.3 MB)
2016-06-13 14:04:54,055  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_97_piece0 stored as bytes in memory (estimated size 8.1 KB, free 92.3 MB)
2016-06-13 14:04:54,056  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_97_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:54,056  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 97 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:54,056  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 57 (MapPartitionsRDD[90] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,056  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 57.0 with 2 tasks
2016-06-13 14:04:54,057  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 57.0 (TID 97, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,057  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 57.0 (TID 98, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,057  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 57.0 (TID 97)
2016-06-13 14:04:54,057  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 57.0 (TID 98)
2016-06-13 14:04:54,061  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:54,066  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:54,068  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 57.0 (TID 98). 45217 bytes result sent to driver
2016-06-13 14:04:54,069  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 57.0 (TID 97). 45217 bytes result sent to driver
2016-06-13 14:04:54,069  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 57.0 (TID 98) in 12 ms on localhost (1/2)
2016-06-13 14:04:54,070  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 57.0 (TID 97) in 13 ms on localhost (2/2)
2016-06-13 14:04:54,070  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 57.0, whose tasks have all completed, from pool 
2016-06-13 14:04:54,073  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 57 (treeAggregate at RowMatrix.scala:93) finished in 0.004 s
2016-06-13 14:04:54,075  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 47 finished: treeAggregate at RowMatrix.scala:93, took 0.024395 s
2016-06-13 14:04:54,078  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_98 stored as values in memory (estimated size 124.9 KB, free 92.5 MB)
2016-06-13 14:04:54,079  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_98_piece0 stored as bytes in memory (estimated size 125.0 KB, free 92.6 MB)
2016-06-13 14:04:54,080  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_98_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:54,081  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 98 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:54,089  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:54,093  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 48 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:54,093  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 58 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,093  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:54,094  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:54,094  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 58 (MapPartitionsRDD[91] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:54,096  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_99 stored as values in memory (estimated size 55.2 KB, free 92.6 MB)
2016-06-13 14:04:54,097  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_99_piece0 stored as bytes in memory (estimated size 8.1 KB, free 92.7 MB)
2016-06-13 14:04:54,098  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_99_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:54,098  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 99 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:54,099  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 58 (MapPartitionsRDD[91] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,099  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 58.0 with 2 tasks
2016-06-13 14:04:54,100  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 58.0 (TID 99, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,100  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 58.0 (TID 100, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,100  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 58.0 (TID 99)
2016-06-13 14:04:54,100  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 58.0 (TID 100)
2016-06-13 14:04:54,103  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:54,105  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 58.0 (TID 100). 45217 bytes result sent to driver
2016-06-13 14:04:54,106  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 58.0 (TID 100) in 6 ms on localhost (1/2)
2016-06-13 14:04:54,108  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:54,111  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 58.0 (TID 99). 45217 bytes result sent to driver
2016-06-13 14:04:54,113  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 58.0 (TID 99) in 14 ms on localhost (2/2)
2016-06-13 14:04:54,113  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 58.0, whose tasks have all completed, from pool 
2016-06-13 14:04:54,118  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 58 (treeAggregate at RowMatrix.scala:93) finished in 0.006 s
2016-06-13 14:04:54,120  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 48 finished: treeAggregate at RowMatrix.scala:93, took 0.027772 s
2016-06-13 14:04:54,122  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_100 stored as values in memory (estimated size 124.9 KB, free 92.8 MB)
2016-06-13 14:04:54,124  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_100_piece0 stored as bytes in memory (estimated size 125.0 KB, free 92.9 MB)
2016-06-13 14:04:54,124  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_100_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:54,125  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 100 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:54,132  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:54,134  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 49 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:54,135  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 59 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,135  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:54,136  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:54,136  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 59 (MapPartitionsRDD[92] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:54,138  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_101 stored as values in memory (estimated size 55.2 KB, free 92.9 MB)
2016-06-13 14:04:54,139  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_101_piece0 stored as bytes in memory (estimated size 8.1 KB, free 93.0 MB)
2016-06-13 14:04:54,140  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_101_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:54,140  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 101 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:54,140  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 59 (MapPartitionsRDD[92] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,140  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 59.0 with 2 tasks
2016-06-13 14:04:54,141  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 59.0 (TID 101, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,141  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 59.0 (TID 102, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,141  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 59.0 (TID 101)
2016-06-13 14:04:54,141  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 59.0 (TID 102)
2016-06-13 14:04:54,148  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:54,149  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:54,151  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 59.0 (TID 101). 45217 bytes result sent to driver
2016-06-13 14:04:54,151  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 59.0 (TID 102). 45217 bytes result sent to driver
2016-06-13 14:04:54,151  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 59.0 (TID 101) in 10 ms on localhost (1/2)
2016-06-13 14:04:54,152  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 59.0 (TID 102) in 11 ms on localhost (2/2)
2016-06-13 14:04:54,152  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 59.0, whose tasks have all completed, from pool 
2016-06-13 14:04:54,154  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 59 (treeAggregate at RowMatrix.scala:93) finished in 0.007 s
2016-06-13 14:04:54,154  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 49 finished: treeAggregate at RowMatrix.scala:93, took 0.022000 s
2016-06-13 14:04:54,156  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_102 stored as values in memory (estimated size 124.9 KB, free 93.1 MB)
2016-06-13 14:04:54,158  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_102_piece0 stored as bytes in memory (estimated size 125.0 KB, free 93.2 MB)
2016-06-13 14:04:54,158  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_102_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:54,159  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 102 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:54,166  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:54,166  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 50 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:54,166  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 60 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,167  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:54,167  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:54,167  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 60 (MapPartitionsRDD[93] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:54,170  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_103 stored as values in memory (estimated size 55.2 KB, free 93.3 MB)
2016-06-13 14:04:54,172  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_103_piece0 stored as bytes in memory (estimated size 8.1 KB, free 93.3 MB)
2016-06-13 14:04:54,172  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_103_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:54,173  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 103 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:54,173  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 60 (MapPartitionsRDD[93] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,173  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 60.0 with 2 tasks
2016-06-13 14:04:54,176  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 60.0 (TID 103, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,177  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 60.0 (TID 104, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,177  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 60.0 (TID 104)
2016-06-13 14:04:54,179  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:54,182  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 60.0 (TID 104). 45217 bytes result sent to driver
2016-06-13 14:04:54,182  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 60.0 (TID 103)
2016-06-13 14:04:54,184  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 60.0 (TID 104) in 8 ms on localhost (1/2)
2016-06-13 14:04:54,185  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:54,191  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 60.0 (TID 103). 45217 bytes result sent to driver
2016-06-13 14:04:54,192  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 60.0 (TID 103) in 16 ms on localhost (2/2)
2016-06-13 14:04:54,192  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 60.0, whose tasks have all completed, from pool 
2016-06-13 14:04:54,192  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 60 (treeAggregate at RowMatrix.scala:93) finished in 0.018 s
2016-06-13 14:04:54,194  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 50 finished: treeAggregate at RowMatrix.scala:93, took 0.027571 s
2016-06-13 14:04:54,196  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_104 stored as values in memory (estimated size 124.9 KB, free 93.4 MB)
2016-06-13 14:04:54,198  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_104_piece0 stored as bytes in memory (estimated size 125.0 KB, free 93.5 MB)
2016-06-13 14:04:54,198  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_104_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:54,199  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 104 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:54,207  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:54,215  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 51 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:54,215  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 61 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,215  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:54,215  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:54,215  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 61 (MapPartitionsRDD[94] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:54,217  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_105 stored as values in memory (estimated size 55.2 KB, free 93.6 MB)
2016-06-13 14:04:54,219  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_105_piece0 stored as bytes in memory (estimated size 8.1 KB, free 93.6 MB)
2016-06-13 14:04:54,223  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_105_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:54,226  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 105 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:54,227  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 61 (MapPartitionsRDD[94] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,228  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 61.0 with 2 tasks
2016-06-13 14:04:54,229  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 61.0 (TID 105, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,230  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 61.0 (TID 106, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,230  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 61.0 (TID 105)
2016-06-13 14:04:54,230  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 61.0 (TID 106)
2016-06-13 14:04:54,235  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:54,238  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 61.0 (TID 106). 45217 bytes result sent to driver
2016-06-13 14:04:54,239  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:54,243  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 61.0 (TID 105). 45217 bytes result sent to driver
2016-06-13 14:04:54,244  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 61.0 (TID 105) in 15 ms on localhost (1/2)
2016-06-13 14:04:54,245  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 61.0 (TID 106) in 16 ms on localhost (2/2)
2016-06-13 14:04:54,245  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 61 (treeAggregate at RowMatrix.scala:93) finished in 0.003 s
2016-06-13 14:04:54,245  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 61.0, whose tasks have all completed, from pool 
2016-06-13 14:04:54,246  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 51 finished: treeAggregate at RowMatrix.scala:93, took 0.031855 s
2016-06-13 14:04:54,249  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_106 stored as values in memory (estimated size 124.9 KB, free 93.7 MB)
2016-06-13 14:04:54,250  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_106_piece0 stored as bytes in memory (estimated size 124.9 KB, free 93.8 MB)
2016-06-13 14:04:54,250  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_106_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:54,251  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 106 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:54,258  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:54,259  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 52 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:54,260  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 62 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,260  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:54,260  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:54,261  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 62 (MapPartitionsRDD[95] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:54,262  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_107 stored as values in memory (estimated size 55.2 KB, free 93.9 MB)
2016-06-13 14:04:54,264  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_107_piece0 stored as bytes in memory (estimated size 8.1 KB, free 93.9 MB)
2016-06-13 14:04:54,264  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_107_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:54,265  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 107 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:54,265  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 62 (MapPartitionsRDD[95] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,265  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 62.0 with 2 tasks
2016-06-13 14:04:54,266  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 62.0 (TID 107, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,266  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 62.0 (TID 108, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,267  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 62.0 (TID 107)
2016-06-13 14:04:54,267  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 62.0 (TID 108)
2016-06-13 14:04:54,270  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:54,275  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 62.0 (TID 108). 45217 bytes result sent to driver
2016-06-13 14:04:54,273  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:54,279  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 62.0 (TID 107). 45217 bytes result sent to driver
2016-06-13 14:04:54,280  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 62.0 (TID 107) in 13 ms on localhost (1/2)
2016-06-13 14:04:54,281  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 62.0 (TID 108) in 14 ms on localhost (2/2)
2016-06-13 14:04:54,281  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 62.0, whose tasks have all completed, from pool 
2016-06-13 14:04:54,281  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 62 (treeAggregate at RowMatrix.scala:93) finished in 0.001 s
2016-06-13 14:04:54,285  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 52 finished: treeAggregate at RowMatrix.scala:93, took 0.026071 s
2016-06-13 14:04:54,287  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_108 stored as values in memory (estimated size 124.9 KB, free 94.0 MB)
2016-06-13 14:04:54,289  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_108_piece0 stored as bytes in memory (estimated size 125.0 KB, free 94.1 MB)
2016-06-13 14:04:54,289  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_108_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:54,290  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 108 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:54,298  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:54,298  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 53 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:54,298  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 63 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,298  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:54,299  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:54,299  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 63 (MapPartitionsRDD[96] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:54,301  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_109 stored as values in memory (estimated size 55.2 KB, free 94.2 MB)
2016-06-13 14:04:54,303  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_109_piece0 stored as bytes in memory (estimated size 8.1 KB, free 94.2 MB)
2016-06-13 14:04:54,304  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_109_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:54,304  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 109 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:54,304  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 63 (MapPartitionsRDD[96] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,305  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 63.0 with 2 tasks
2016-06-13 14:04:54,305  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 63.0 (TID 109, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,306  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 63.0 (TID 110, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,306  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 63.0 (TID 109)
2016-06-13 14:04:54,306  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 63.0 (TID 110)
2016-06-13 14:04:54,309  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:54,313  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:54,317  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 63.0 (TID 109). 45217 bytes result sent to driver
2016-06-13 14:04:54,319  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 63.0 (TID 110). 45217 bytes result sent to driver
2016-06-13 14:04:54,320  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 63.0 (TID 109) in 15 ms on localhost (1/2)
2016-06-13 14:04:54,335  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 63.0 (TID 110) in 30 ms on localhost (2/2)
2016-06-13 14:04:54,335  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 63 (treeAggregate at RowMatrix.scala:93) finished in 0.016 s
2016-06-13 14:04:54,335  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 63.0, whose tasks have all completed, from pool 
2016-06-13 14:04:54,336  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 53 finished: treeAggregate at RowMatrix.scala:93, took 0.037665 s
2016-06-13 14:04:54,338  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_110 stored as values in memory (estimated size 124.9 KB, free 94.3 MB)
2016-06-13 14:04:54,340  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_110_piece0 stored as bytes in memory (estimated size 125.0 KB, free 94.4 MB)
2016-06-13 14:04:54,340  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_110_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:54,341  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 110 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:54,348  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:54,353  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 54 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:54,353  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 64 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,353  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:54,354  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:54,354  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 64 (MapPartitionsRDD[97] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:54,355  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_111 stored as values in memory (estimated size 55.2 KB, free 94.5 MB)
2016-06-13 14:04:54,357  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_111_piece0 stored as bytes in memory (estimated size 8.1 KB, free 94.5 MB)
2016-06-13 14:04:54,361  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_111_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:54,362  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 111 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:54,362  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 64 (MapPartitionsRDD[97] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,362  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 64.0 with 2 tasks
2016-06-13 14:04:54,363  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 64.0 (TID 111, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,363  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 64.0 (TID 112, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,363  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 64.0 (TID 111)
2016-06-13 14:04:54,364  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 64.0 (TID 112)
2016-06-13 14:04:54,368  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:54,371  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:54,374  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 64.0 (TID 112). 45217 bytes result sent to driver
2016-06-13 14:04:54,374  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 64.0 (TID 111). 45217 bytes result sent to driver
2016-06-13 14:04:54,375  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 64.0 (TID 112) in 12 ms on localhost (1/2)
2016-06-13 14:04:54,376  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 64.0 (TID 111) in 13 ms on localhost (2/2)
2016-06-13 14:04:54,377  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 64.0, whose tasks have all completed, from pool 
2016-06-13 14:04:54,377  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 64 (treeAggregate at RowMatrix.scala:93) finished in 0.010 s
2016-06-13 14:04:54,378  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 54 finished: treeAggregate at RowMatrix.scala:93, took 0.024919 s
2016-06-13 14:04:54,380  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_112 stored as values in memory (estimated size 124.9 KB, free 94.6 MB)
2016-06-13 14:04:54,382  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_112_piece0 stored as bytes in memory (estimated size 125.0 KB, free 94.7 MB)
2016-06-13 14:04:54,382  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_112_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:54,383  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 112 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:54,417  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:54,418  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 55 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:54,418  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 65 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,418  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:54,418  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:54,418  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 65 (MapPartitionsRDD[98] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:54,420  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_113 stored as values in memory (estimated size 55.2 KB, free 94.8 MB)
2016-06-13 14:04:54,421  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_113_piece0 stored as bytes in memory (estimated size 8.1 KB, free 94.8 MB)
2016-06-13 14:04:54,422  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_113_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:54,422  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 113 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:54,422  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 65 (MapPartitionsRDD[98] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,423  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 65.0 with 2 tasks
2016-06-13 14:04:54,423  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 65.0 (TID 113, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,423  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 65.0 (TID 114, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,423  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 65.0 (TID 113)
2016-06-13 14:04:54,425  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:54,426  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 65.0 (TID 114)
2016-06-13 14:04:54,428  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 65.0 (TID 113). 45217 bytes result sent to driver
2016-06-13 14:04:54,429  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 65.0 (TID 113) in 5 ms on localhost (1/2)
2016-06-13 14:04:54,429  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:54,431  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 65.0 (TID 114). 45217 bytes result sent to driver
2016-06-13 14:04:54,432  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 65.0 (TID 114) in 9 ms on localhost (2/2)
2016-06-13 14:04:54,432  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 65 (treeAggregate at RowMatrix.scala:93) finished in 0.009 s
2016-06-13 14:04:54,432  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 65.0, whose tasks have all completed, from pool 
2016-06-13 14:04:54,433  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 55 finished: treeAggregate at RowMatrix.scala:93, took 0.015300 s
2016-06-13 14:04:54,436  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_114 stored as values in memory (estimated size 124.9 KB, free 94.9 MB)
2016-06-13 14:04:54,437  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_114_piece0 stored as bytes in memory (estimated size 124.9 KB, free 95.0 MB)
2016-06-13 14:04:54,438  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_114_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:54,438  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 114 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:54,446  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:54,447  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 56 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:54,447  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 66 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,447  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:54,447  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:54,447  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 66 (MapPartitionsRDD[99] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:54,449  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_115 stored as values in memory (estimated size 55.2 KB, free 95.1 MB)
2016-06-13 14:04:54,450  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_115_piece0 stored as bytes in memory (estimated size 8.1 KB, free 95.1 MB)
2016-06-13 14:04:54,451  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_115_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:54,451  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 115 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:54,451  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 66 (MapPartitionsRDD[99] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,452  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 66.0 with 2 tasks
2016-06-13 14:04:54,452  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 66.0 (TID 115, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,453  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 66.0 (TID 116, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,453  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 66.0 (TID 115)
2016-06-13 14:04:54,453  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 66.0 (TID 116)
2016-06-13 14:04:54,456  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:54,458  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 66.0 (TID 116). 45217 bytes result sent to driver
2016-06-13 14:04:54,460  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:54,462  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 66.0 (TID 115). 45217 bytes result sent to driver
2016-06-13 14:04:54,463  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 66.0 (TID 115) in 11 ms on localhost (1/2)
2016-06-13 14:04:54,463  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 66.0 (TID 116) in 11 ms on localhost (2/2)
2016-06-13 14:04:54,463  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 66.0, whose tasks have all completed, from pool 
2016-06-13 14:04:54,464  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 66 (treeAggregate at RowMatrix.scala:93) finished in 0.002 s
2016-06-13 14:04:54,464  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 56 finished: treeAggregate at RowMatrix.scala:93, took 0.017873 s
2016-06-13 14:04:54,481  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_116 stored as values in memory (estimated size 124.9 KB, free 95.2 MB)
2016-06-13 14:04:54,484  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_116_piece0 stored as bytes in memory (estimated size 125.0 KB, free 95.3 MB)
2016-06-13 14:04:54,484  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_116_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:54,485  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 116 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:54,505  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:54,510  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 57 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:54,510  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 67 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,510  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:54,511  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:54,511  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 67 (MapPartitionsRDD[100] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:54,513  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_117 stored as values in memory (estimated size 55.2 KB, free 95.4 MB)
2016-06-13 14:04:54,514  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_117_piece0 stored as bytes in memory (estimated size 8.1 KB, free 95.4 MB)
2016-06-13 14:04:54,514  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_117_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:54,515  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 117 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:54,515  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 67 (MapPartitionsRDD[100] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,515  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 67.0 with 2 tasks
2016-06-13 14:04:54,516  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 67.0 (TID 117, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,516  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 67.0 (TID 118, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,516  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 67.0 (TID 117)
2016-06-13 14:04:54,516  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 67.0 (TID 118)
2016-06-13 14:04:54,519  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:54,519  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:54,521  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 67.0 (TID 117). 45217 bytes result sent to driver
2016-06-13 14:04:54,522  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 67.0 (TID 117) in 7 ms on localhost (1/2)
2016-06-13 14:04:54,525  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 67.0 (TID 118). 45217 bytes result sent to driver
2016-06-13 14:04:54,526  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 67.0 (TID 118) in 10 ms on localhost (2/2)
2016-06-13 14:04:54,526  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 67.0, whose tasks have all completed, from pool 
2016-06-13 14:04:54,528  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 67 (treeAggregate at RowMatrix.scala:93) finished in 0.006 s
2016-06-13 14:04:54,529  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 57 finished: treeAggregate at RowMatrix.scala:93, took 0.023724 s
2016-06-13 14:04:54,531  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_118 stored as values in memory (estimated size 124.9 KB, free 95.5 MB)
2016-06-13 14:04:54,534  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_118_piece0 stored as bytes in memory (estimated size 125.0 KB, free 95.6 MB)
2016-06-13 14:04:54,534  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_118_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:54,535  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 118 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:54,541  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:54,542  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 58 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:54,542  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 68 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,542  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:54,543  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:54,543  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 68 (MapPartitionsRDD[101] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:54,545  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_119 stored as values in memory (estimated size 55.2 KB, free 95.7 MB)
2016-06-13 14:04:54,546  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_119_piece0 stored as bytes in memory (estimated size 8.1 KB, free 95.7 MB)
2016-06-13 14:04:54,546  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_119_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:54,547  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 119 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:54,547  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 68 (MapPartitionsRDD[101] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,547  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 68.0 with 2 tasks
2016-06-13 14:04:54,548  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 68.0 (TID 119, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,548  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 68.0 (TID 120, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,548  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 68.0 (TID 119)
2016-06-13 14:04:54,550  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 68.0 (TID 120)
2016-06-13 14:04:54,551  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:54,553  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:54,554  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 68.0 (TID 119). 45217 bytes result sent to driver
2016-06-13 14:04:54,555  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 68.0 (TID 120). 45217 bytes result sent to driver
2016-06-13 14:04:54,556  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 68.0 (TID 119) in 9 ms on localhost (1/2)
2016-06-13 14:04:54,557  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 68.0 (TID 120) in 9 ms on localhost (2/2)
2016-06-13 14:04:54,557  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 68.0, whose tasks have all completed, from pool 
2016-06-13 14:04:54,557  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 68 (treeAggregate at RowMatrix.scala:93) finished in 0.010 s
2016-06-13 14:04:54,557  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 58 finished: treeAggregate at RowMatrix.scala:93, took 0.015682 s
2016-06-13 14:04:54,567  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_120 stored as values in memory (estimated size 124.9 KB, free 95.8 MB)
2016-06-13 14:04:54,569  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_120_piece0 stored as bytes in memory (estimated size 125.0 KB, free 96.0 MB)
2016-06-13 14:04:54,570  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_120_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:54,570  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 120 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:54,587  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:54,588  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 59 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:54,588  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 69 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,588  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:54,588  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:54,589  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 69 (MapPartitionsRDD[102] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:54,593  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_121 stored as values in memory (estimated size 55.2 KB, free 96.0 MB)
2016-06-13 14:04:54,594  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_121_piece0 stored as bytes in memory (estimated size 8.1 KB, free 96.0 MB)
2016-06-13 14:04:54,595  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_121_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:54,596  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 121 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:54,596  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 69 (MapPartitionsRDD[102] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,596  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 69.0 with 2 tasks
2016-06-13 14:04:54,597  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 69.0 (TID 121, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,597  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 69.0 (TID 122, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,598  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 69.0 (TID 122)
2016-06-13 14:04:54,598  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 69.0 (TID 121)
2016-06-13 14:04:54,601  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:54,605  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 69.0 (TID 122). 45217 bytes result sent to driver
2016-06-13 14:04:54,610  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 69.0 (TID 122) in 13 ms on localhost (1/2)
2016-06-13 14:04:54,611  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:54,617  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 69.0 (TID 121). 45217 bytes result sent to driver
2016-06-13 14:04:54,621  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 69.0 (TID 121) in 24 ms on localhost (2/2)
2016-06-13 14:04:54,621  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 69.0, whose tasks have all completed, from pool 
2016-06-13 14:04:54,621  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 69 (treeAggregate at RowMatrix.scala:93) finished in 0.004 s
2016-06-13 14:04:54,622  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 59 finished: treeAggregate at RowMatrix.scala:93, took 0.034779 s
2016-06-13 14:04:54,627  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_122 stored as values in memory (estimated size 124.9 KB, free 96.1 MB)
2016-06-13 14:04:54,629  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_122_piece0 stored as bytes in memory (estimated size 124.9 KB, free 96.3 MB)
2016-06-13 14:04:54,630  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_122_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:54,632  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 122 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:54,641  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:54,643  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 60 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:54,643  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 70 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,643  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:54,644  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:54,644  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 70 (MapPartitionsRDD[103] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:54,645  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_123 stored as values in memory (estimated size 55.2 KB, free 96.3 MB)
2016-06-13 14:04:54,647  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_123_piece0 stored as bytes in memory (estimated size 8.1 KB, free 96.3 MB)
2016-06-13 14:04:54,651  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_123_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:54,652  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 123 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:54,652  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 70 (MapPartitionsRDD[103] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,653  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 70.0 with 2 tasks
2016-06-13 14:04:54,655  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 70.0 (TID 123, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,655  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 70.0 (TID 124, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,655  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 70.0 (TID 123)
2016-06-13 14:04:54,655  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 70.0 (TID 124)
2016-06-13 14:04:54,659  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:54,665  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:54,669  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 70.0 (TID 124). 45217 bytes result sent to driver
2016-06-13 14:04:54,669  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 70.0 (TID 123). 45217 bytes result sent to driver
2016-06-13 14:04:54,670  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 70.0 (TID 124) in 15 ms on localhost (1/2)
2016-06-13 14:04:54,671  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 70.0 (TID 123) in 17 ms on localhost (2/2)
2016-06-13 14:04:54,671  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 70.0, whose tasks have all completed, from pool 
2016-06-13 14:04:54,671  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 70 (treeAggregate at RowMatrix.scala:93) finished in 0.003 s
2016-06-13 14:04:54,672  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 60 finished: treeAggregate at RowMatrix.scala:93, took 0.029741 s
2016-06-13 14:04:54,675  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_124 stored as values in memory (estimated size 124.9 KB, free 96.4 MB)
2016-06-13 14:04:54,677  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_124_piece0 stored as bytes in memory (estimated size 124.9 KB, free 96.6 MB)
2016-06-13 14:04:54,677  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_124_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:54,678  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 124 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:54,686  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:54,687  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 61 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:54,687  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 71 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,687  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:54,687  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:54,688  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 71 (MapPartitionsRDD[104] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:54,689  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_125 stored as values in memory (estimated size 55.2 KB, free 96.6 MB)
2016-06-13 14:04:54,691  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_125_piece0 stored as bytes in memory (estimated size 8.1 KB, free 96.6 MB)
2016-06-13 14:04:54,691  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_125_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:54,692  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 125 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:54,692  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 71 (MapPartitionsRDD[104] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,692  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 71.0 with 2 tasks
2016-06-13 14:04:54,693  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 71.0 (TID 125, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,693  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 71.0 (TID 126, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,693  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 71.0 (TID 125)
2016-06-13 14:04:54,694  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 71.0 (TID 126)
2016-06-13 14:04:54,698  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:54,701  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 71.0 (TID 125). 45217 bytes result sent to driver
2016-06-13 14:04:54,701  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 71.0 (TID 125) in 8 ms on localhost (1/2)
2016-06-13 14:04:54,703  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:54,706  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 71.0 (TID 126). 45217 bytes result sent to driver
2016-06-13 14:04:54,706  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 71.0 (TID 126) in 13 ms on localhost (2/2)
2016-06-13 14:04:54,706  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 71.0, whose tasks have all completed, from pool 
2016-06-13 14:04:54,706  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 71 (treeAggregate at RowMatrix.scala:93) finished in 0.013 s
2016-06-13 14:04:54,708  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 61 finished: treeAggregate at RowMatrix.scala:93, took 0.021376 s
2016-06-13 14:04:54,712  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_126 stored as values in memory (estimated size 124.9 KB, free 96.7 MB)
2016-06-13 14:04:54,714  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_126_piece0 stored as bytes in memory (estimated size 124.9 KB, free 96.9 MB)
2016-06-13 14:04:54,714  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_126_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:54,715  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 126 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:54,725  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:54,726  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 62 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:54,726  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 72 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,726  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:54,726  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:54,727  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 72 (MapPartitionsRDD[105] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:54,729  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_127 stored as values in memory (estimated size 55.2 KB, free 96.9 MB)
2016-06-13 14:04:54,730  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_127_piece0 stored as bytes in memory (estimated size 8.1 KB, free 96.9 MB)
2016-06-13 14:04:54,730  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_127_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:54,731  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 127 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:54,731  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 72 (MapPartitionsRDD[105] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,731  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 72.0 with 2 tasks
2016-06-13 14:04:54,733  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 72.0 (TID 127, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,733  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 72.0 (TID 128, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,733  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 72.0 (TID 128)
2016-06-13 14:04:54,736  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:54,736  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 72.0 (TID 127)
2016-06-13 14:04:54,738  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 72.0 (TID 128). 45217 bytes result sent to driver
2016-06-13 14:04:54,739  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:54,740  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 72.0 (TID 128) in 7 ms on localhost (1/2)
2016-06-13 14:04:54,741  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 72.0 (TID 127). 45217 bytes result sent to driver
2016-06-13 14:04:54,742  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 72.0 (TID 127) in 10 ms on localhost (2/2)
2016-06-13 14:04:54,742  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 72.0, whose tasks have all completed, from pool 
2016-06-13 14:04:54,743  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 72 (treeAggregate at RowMatrix.scala:93) finished in 0.012 s
2016-06-13 14:04:54,743  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 62 finished: treeAggregate at RowMatrix.scala:93, took 0.017919 s
2016-06-13 14:04:54,746  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_128 stored as values in memory (estimated size 124.9 KB, free 97.1 MB)
2016-06-13 14:04:54,749  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_128_piece0 stored as bytes in memory (estimated size 124.9 KB, free 97.2 MB)
2016-06-13 14:04:54,749  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_128_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:54,752  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 128 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:54,776  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:54,776  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 63 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:54,776  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 73 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,776  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:54,777  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:54,777  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 73 (MapPartitionsRDD[106] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:54,778  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_129 stored as values in memory (estimated size 55.2 KB, free 97.2 MB)
2016-06-13 14:04:54,779  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_129_piece0 stored as bytes in memory (estimated size 8.1 KB, free 97.2 MB)
2016-06-13 14:04:54,780  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_129_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:54,780  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 129 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:54,780  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 73 (MapPartitionsRDD[106] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,781  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 73.0 with 2 tasks
2016-06-13 14:04:54,781  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 73.0 (TID 129, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,781  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 73.0 (TID 130, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,781  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 73.0 (TID 129)
2016-06-13 14:04:54,781  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 73.0 (TID 130)
2016-06-13 14:04:54,786  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:54,786  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:54,791  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 73.0 (TID 129). 45217 bytes result sent to driver
2016-06-13 14:04:54,793  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 73.0 (TID 129) in 12 ms on localhost (1/2)
2016-06-13 14:04:54,794  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 73.0 (TID 130). 45217 bytes result sent to driver
2016-06-13 14:04:54,799  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 73.0 (TID 130) in 18 ms on localhost (2/2)
2016-06-13 14:04:54,799  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 73 (treeAggregate at RowMatrix.scala:93) finished in 0.015 s
2016-06-13 14:04:54,799  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 73.0, whose tasks have all completed, from pool 
2016-06-13 14:04:54,799  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 63 finished: treeAggregate at RowMatrix.scala:93, took 0.023503 s
2016-06-13 14:04:54,802  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_130 stored as values in memory (estimated size 124.9 KB, free 97.4 MB)
2016-06-13 14:04:54,804  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_130_piece0 stored as bytes in memory (estimated size 125.0 KB, free 97.5 MB)
2016-06-13 14:04:54,804  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_130_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:54,804  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 130 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:54,811  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:54,811  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 64 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:54,812  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 74 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,812  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:54,812  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:54,813  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 74 (MapPartitionsRDD[107] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:54,814  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_131 stored as values in memory (estimated size 55.2 KB, free 97.5 MB)
2016-06-13 14:04:54,816  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_131_piece0 stored as bytes in memory (estimated size 8.1 KB, free 97.5 MB)
2016-06-13 14:04:54,816  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_131_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:54,816  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 131 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:54,817  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 74 (MapPartitionsRDD[107] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,817  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 74.0 with 2 tasks
2016-06-13 14:04:54,817  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 74.0 (TID 131, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,817  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 74.0 (TID 132, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,818  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 74.0 (TID 132)
2016-06-13 14:04:54,818  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 74.0 (TID 131)
2016-06-13 14:04:54,821  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:54,824  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:54,825  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 74.0 (TID 131). 45217 bytes result sent to driver
2016-06-13 14:04:54,825  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 74.0 (TID 131) in 8 ms on localhost (1/2)
2016-06-13 14:04:54,827  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 74.0 (TID 132). 45217 bytes result sent to driver
2016-06-13 14:04:54,828  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 74.0 (TID 132) in 11 ms on localhost (2/2)
2016-06-13 14:04:54,829  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 74.0, whose tasks have all completed, from pool 
2016-06-13 14:04:54,829  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 74 (treeAggregate at RowMatrix.scala:93) finished in 0.008 s
2016-06-13 14:04:54,831  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 64 finished: treeAggregate at RowMatrix.scala:93, took 0.020122 s
2016-06-13 14:04:54,835  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_132 stored as values in memory (estimated size 124.9 KB, free 97.7 MB)
2016-06-13 14:04:54,838  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_132_piece0 stored as bytes in memory (estimated size 124.9 KB, free 97.8 MB)
2016-06-13 14:04:54,838  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_132_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:54,843  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 132 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:54,851  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:54,851  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 65 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:54,851  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 75 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,851  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:54,852  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:54,852  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 75 (MapPartitionsRDD[108] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:54,854  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_133 stored as values in memory (estimated size 55.2 KB, free 97.8 MB)
2016-06-13 14:04:54,855  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_133_piece0 stored as bytes in memory (estimated size 8.1 KB, free 97.8 MB)
2016-06-13 14:04:54,860  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_133_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:54,861  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 133 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:54,861  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 75 (MapPartitionsRDD[108] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,861  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 75.0 with 2 tasks
2016-06-13 14:04:54,865  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 75.0 (TID 133, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,865  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 75.0 (TID 134, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,866  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 75.0 (TID 133)
2016-06-13 14:04:54,866  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 75.0 (TID 134)
2016-06-13 14:04:54,869  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:54,873  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:54,876  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 75.0 (TID 133). 45217 bytes result sent to driver
2016-06-13 14:04:54,877  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 75.0 (TID 134). 45217 bytes result sent to driver
2016-06-13 14:04:54,879  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 75.0 (TID 133) in 14 ms on localhost (1/2)
2016-06-13 14:04:54,879  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 75.0 (TID 134) in 14 ms on localhost (2/2)
2016-06-13 14:04:54,879  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 75.0, whose tasks have all completed, from pool 
2016-06-13 14:04:54,880  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 75 (treeAggregate at RowMatrix.scala:93) finished in 0.003 s
2016-06-13 14:04:54,880  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 65 finished: treeAggregate at RowMatrix.scala:93, took 0.029291 s
2016-06-13 14:04:54,891  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_134 stored as values in memory (estimated size 124.9 KB, free 98.0 MB)
2016-06-13 14:04:54,893  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_134_piece0 stored as bytes in memory (estimated size 125.0 KB, free 98.1 MB)
2016-06-13 14:04:54,893  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_134_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:54,895  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 134 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:54,902  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:54,904  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 66 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:54,904  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 76 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,904  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:54,905  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:54,905  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 76 (MapPartitionsRDD[109] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:54,906  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_135 stored as values in memory (estimated size 55.2 KB, free 98.1 MB)
2016-06-13 14:04:54,908  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_135_piece0 stored as bytes in memory (estimated size 8.1 KB, free 98.2 MB)
2016-06-13 14:04:54,908  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_135_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:54,908  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 135 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:54,909  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 76 (MapPartitionsRDD[109] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,909  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 76.0 with 2 tasks
2016-06-13 14:04:54,909  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 76.0 (TID 135, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,910  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 76.0 (TID 136, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,910  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 76.0 (TID 135)
2016-06-13 14:04:54,910  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 76.0 (TID 136)
2016-06-13 14:04:54,913  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:54,916  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:54,919  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 76.0 (TID 135). 45217 bytes result sent to driver
2016-06-13 14:04:54,921  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 76.0 (TID 136). 45217 bytes result sent to driver
2016-06-13 14:04:54,922  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 76.0 (TID 135) in 13 ms on localhost (1/2)
2016-06-13 14:04:54,924  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 76.0 (TID 136) in 15 ms on localhost (2/2)
2016-06-13 14:04:54,924  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 76.0, whose tasks have all completed, from pool 
2016-06-13 14:04:54,925  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 76 (treeAggregate at RowMatrix.scala:93) finished in 0.003 s
2016-06-13 14:04:54,925  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 66 finished: treeAggregate at RowMatrix.scala:93, took 0.023395 s
2016-06-13 14:04:54,928  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_136 stored as values in memory (estimated size 124.9 KB, free 98.3 MB)
2016-06-13 14:04:54,930  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_136_piece0 stored as bytes in memory (estimated size 124.9 KB, free 98.4 MB)
2016-06-13 14:04:54,930  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_136_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:54,931  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 136 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:54,942  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:54,943  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 67 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:54,943  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 77 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,943  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:54,943  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:54,944  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 77 (MapPartitionsRDD[110] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:54,946  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_137 stored as values in memory (estimated size 55.2 KB, free 98.5 MB)
2016-06-13 14:04:54,947  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_137_piece0 stored as bytes in memory (estimated size 8.1 KB, free 98.5 MB)
2016-06-13 14:04:54,948  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_137_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:54,948  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 137 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:54,948  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 77 (MapPartitionsRDD[110] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,948  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 77.0 with 2 tasks
2016-06-13 14:04:54,949  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 77.0 (TID 137, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,949  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 77.0 (TID 138, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:54,950  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 77.0 (TID 137)
2016-06-13 14:04:54,950  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 77.0 (TID 138)
2016-06-13 14:04:54,953  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:54,956  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:54,959  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 77.0 (TID 137). 45217 bytes result sent to driver
2016-06-13 14:04:54,961  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 77.0 (TID 138). 45217 bytes result sent to driver
2016-06-13 14:04:54,962  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 77.0 (TID 137) in 13 ms on localhost (1/2)
2016-06-13 14:04:54,963  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 77.0 (TID 138) in 13 ms on localhost (2/2)
2016-06-13 14:04:54,963  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 77.0, whose tasks have all completed, from pool 
2016-06-13 14:04:54,963  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 77 (treeAggregate at RowMatrix.scala:93) finished in 0.001 s
2016-06-13 14:04:54,964  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 67 finished: treeAggregate at RowMatrix.scala:93, took 0.021520 s
2016-06-13 14:04:54,967  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_138 stored as values in memory (estimated size 124.9 KB, free 98.6 MB)
2016-06-13 14:04:54,969  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_138_piece0 stored as bytes in memory (estimated size 124.9 KB, free 98.7 MB)
2016-06-13 14:04:54,969  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_138_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:54,970  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 138 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:54,992  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:54,994  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 68 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:54,994  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 78 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,994  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:54,995  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:54,995  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 78 (MapPartitionsRDD[111] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:54,996  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_139 stored as values in memory (estimated size 55.2 KB, free 98.8 MB)
2016-06-13 14:04:54,998  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_139_piece0 stored as bytes in memory (estimated size 8.1 KB, free 98.8 MB)
2016-06-13 14:04:54,998  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_139_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:54,998  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 139 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:54,999  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 78 (MapPartitionsRDD[111] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:54,999  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 78.0 with 2 tasks
2016-06-13 14:04:55,000  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 78.0 (TID 139, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,000  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 78.0 (TID 140, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,000  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 78.0 (TID 139)
2016-06-13 14:04:55,000  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 78.0 (TID 140)
2016-06-13 14:04:55,004  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:55,007  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:55,011  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 78.0 (TID 140). 45217 bytes result sent to driver
2016-06-13 14:04:55,012  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 78.0 (TID 139). 45217 bytes result sent to driver
2016-06-13 14:04:55,013  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 78.0 (TID 140) in 13 ms on localhost (1/2)
2016-06-13 14:04:55,014  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 78.0 (TID 139) in 15 ms on localhost (2/2)
2016-06-13 14:04:55,014  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 78.0, whose tasks have all completed, from pool 
2016-06-13 14:04:55,014  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 78 (treeAggregate at RowMatrix.scala:93) finished in 0.003 s
2016-06-13 14:04:55,014  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 68 finished: treeAggregate at RowMatrix.scala:93, took 0.020668 s
2016-06-13 14:04:55,017  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_140 stored as values in memory (estimated size 124.9 KB, free 98.9 MB)
2016-06-13 14:04:55,018  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_140_piece0 stored as bytes in memory (estimated size 124.9 KB, free 99.0 MB)
2016-06-13 14:04:55,018  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_140_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:55,019  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 140 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:55,025  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:55,026  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 69 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:55,026  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 79 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,026  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:55,026  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:55,026  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 79 (MapPartitionsRDD[112] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:55,028  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_141 stored as values in memory (estimated size 55.2 KB, free 99.1 MB)
2016-06-13 14:04:55,029  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_141_piece0 stored as bytes in memory (estimated size 8.1 KB, free 99.1 MB)
2016-06-13 14:04:55,030  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_141_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:55,031  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 141 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:55,031  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 79 (MapPartitionsRDD[112] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,031  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 79.0 with 2 tasks
2016-06-13 14:04:55,032  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 79.0 (TID 141, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,032  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 79.0 (TID 142, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,032  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 79.0 (TID 141)
2016-06-13 14:04:55,032  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 79.0 (TID 142)
2016-06-13 14:04:55,035  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:55,037  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:55,038  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 79.0 (TID 141). 45217 bytes result sent to driver
2016-06-13 14:04:55,041  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 79.0 (TID 141) in 9 ms on localhost (1/2)
2016-06-13 14:04:55,042  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 79.0 (TID 142). 45217 bytes result sent to driver
2016-06-13 14:04:55,043  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 79.0 (TID 142) in 11 ms on localhost (2/2)
2016-06-13 14:04:55,043  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 79.0, whose tasks have all completed, from pool 
2016-06-13 14:04:55,043  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 79 (treeAggregate at RowMatrix.scala:93) finished in 0.012 s
2016-06-13 14:04:55,044  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 69 finished: treeAggregate at RowMatrix.scala:93, took 0.018400 s
2016-06-13 14:04:55,047  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_142 stored as values in memory (estimated size 124.9 KB, free 99.2 MB)
2016-06-13 14:04:55,049  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_142_piece0 stored as bytes in memory (estimated size 124.9 KB, free 99.3 MB)
2016-06-13 14:04:55,049  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_142_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:55,050  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 142 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:55,057  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:55,057  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 70 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:55,057  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 80 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,057  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:55,057  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:55,058  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 80 (MapPartitionsRDD[113] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:55,059  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_143 stored as values in memory (estimated size 55.2 KB, free 99.4 MB)
2016-06-13 14:04:55,060  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_143_piece0 stored as bytes in memory (estimated size 8.1 KB, free 99.4 MB)
2016-06-13 14:04:55,061  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_143_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:55,061  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 143 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:55,061  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 80 (MapPartitionsRDD[113] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,061  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 80.0 with 2 tasks
2016-06-13 14:04:55,062  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 80.0 (TID 143, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,062  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 80.0 (TID 144, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,062  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 80.0 (TID 143)
2016-06-13 14:04:55,062  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 80.0 (TID 144)
2016-06-13 14:04:55,065  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:55,067  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 80.0 (TID 144). 45217 bytes result sent to driver
2016-06-13 14:04:55,067  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 80.0 (TID 144) in 5 ms on localhost (1/2)
2016-06-13 14:04:55,068  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:55,070  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 80.0 (TID 143). 45217 bytes result sent to driver
2016-06-13 14:04:55,071  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 80.0 (TID 143) in 10 ms on localhost (2/2)
2016-06-13 14:04:55,071  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 80.0, whose tasks have all completed, from pool 
2016-06-13 14:04:55,071  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 80 (treeAggregate at RowMatrix.scala:93) finished in 0.001 s
2016-06-13 14:04:55,071  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 70 finished: treeAggregate at RowMatrix.scala:93, took 0.014603 s
2016-06-13 14:04:55,074  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_144 stored as values in memory (estimated size 124.9 KB, free 99.5 MB)
2016-06-13 14:04:55,075  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_144_piece0 stored as bytes in memory (estimated size 124.9 KB, free 99.6 MB)
2016-06-13 14:04:55,075  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_144_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:55,076  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 144 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:55,081  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:55,081  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 71 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:55,081  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 81 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,081  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:55,081  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:55,082  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 81 (MapPartitionsRDD[114] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:55,083  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_145 stored as values in memory (estimated size 55.2 KB, free 99.7 MB)
2016-06-13 14:04:55,084  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_145_piece0 stored as bytes in memory (estimated size 8.1 KB, free 99.7 MB)
2016-06-13 14:04:55,084  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_145_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:55,085  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 145 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:55,085  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 81 (MapPartitionsRDD[114] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,085  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 81.0 with 2 tasks
2016-06-13 14:04:55,085  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 81.0 (TID 145, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,085  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 81.0 (TID 146, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,086  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 81.0 (TID 145)
2016-06-13 14:04:55,088  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:55,090  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 81.0 (TID 145). 45217 bytes result sent to driver
2016-06-13 14:04:55,090  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 81.0 (TID 146)
2016-06-13 14:04:55,090  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 81.0 (TID 145) in 5 ms on localhost (1/2)
2016-06-13 14:04:55,093  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:55,095  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 81.0 (TID 146). 45217 bytes result sent to driver
2016-06-13 14:04:55,096  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 81.0 (TID 146) in 11 ms on localhost (2/2)
2016-06-13 14:04:55,096  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 81 (treeAggregate at RowMatrix.scala:93) finished in 0.011 s
2016-06-13 14:04:55,096  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 71 finished: treeAggregate at RowMatrix.scala:93, took 0.015656 s
2016-06-13 14:04:55,096  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 81.0, whose tasks have all completed, from pool 
2016-06-13 14:04:55,100  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_146 stored as values in memory (estimated size 124.9 KB, free 99.8 MB)
2016-06-13 14:04:55,101  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_146_piece0 stored as bytes in memory (estimated size 124.9 KB, free 99.9 MB)
2016-06-13 14:04:55,102  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_146_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:55,102  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 146 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:55,110  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:55,110  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 72 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:55,110  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 82 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,110  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:55,111  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:55,111  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 82 (MapPartitionsRDD[115] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:55,112  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_147 stored as values in memory (estimated size 55.2 KB, free 100.0 MB)
2016-06-13 14:04:55,113  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_147_piece0 stored as bytes in memory (estimated size 8.1 KB, free 100.0 MB)
2016-06-13 14:04:55,114  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_147_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:55,114  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 147 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:55,114  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 82 (MapPartitionsRDD[115] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,114  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 82.0 with 2 tasks
2016-06-13 14:04:55,114  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 82.0 (TID 147, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,115  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 82.0 (TID 148, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,115  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 82.0 (TID 147)
2016-06-13 14:04:55,117  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:55,118  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 82.0 (TID 148)
2016-06-13 14:04:55,119  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 82.0 (TID 147). 45217 bytes result sent to driver
2016-06-13 14:04:55,121  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:55,123  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 82.0 (TID 147) in 9 ms on localhost (1/2)
2016-06-13 14:04:55,124  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 82.0 (TID 148). 45217 bytes result sent to driver
2016-06-13 14:04:55,125  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 82.0 (TID 148) in 10 ms on localhost (2/2)
2016-06-13 14:04:55,125  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 82.0, whose tasks have all completed, from pool 
2016-06-13 14:04:55,126  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 82 (treeAggregate at RowMatrix.scala:93) finished in 0.011 s
2016-06-13 14:04:55,131  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 72 finished: treeAggregate at RowMatrix.scala:93, took 0.021023 s
2016-06-13 14:04:55,134  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_148 stored as values in memory (estimated size 124.9 KB, free 100.1 MB)
2016-06-13 14:04:55,136  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_148_piece0 stored as bytes in memory (estimated size 124.8 KB, free 100.2 MB)
2016-06-13 14:04:55,136  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_148_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:55,137  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 148 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:55,145  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:55,146  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 73 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:55,146  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 83 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,146  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:55,146  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:55,146  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 83 (MapPartitionsRDD[116] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:55,147  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_149 stored as values in memory (estimated size 55.2 KB, free 100.3 MB)
2016-06-13 14:04:55,148  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_149_piece0 stored as bytes in memory (estimated size 8.1 KB, free 100.3 MB)
2016-06-13 14:04:55,149  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_149_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:55,149  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 149 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:55,149  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 83 (MapPartitionsRDD[116] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,149  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 83.0 with 2 tasks
2016-06-13 14:04:55,150  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 83.0 (TID 149, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,150  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 83.0 (TID 150, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,150  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 83.0 (TID 149)
2016-06-13 14:04:55,153  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:55,154  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 83.0 (TID 150)
2016-06-13 14:04:55,155  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 83.0 (TID 149). 45217 bytes result sent to driver
2016-06-13 14:04:55,156  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:55,159  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 83.0 (TID 149) in 10 ms on localhost (1/2)
2016-06-13 14:04:55,160  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 83.0 (TID 150). 45217 bytes result sent to driver
2016-06-13 14:04:55,163  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 83.0 (TID 150) in 13 ms on localhost (2/2)
2016-06-13 14:04:55,163  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 83.0, whose tasks have all completed, from pool 
2016-06-13 14:04:55,163  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 83 (treeAggregate at RowMatrix.scala:93) finished in 0.014 s
2016-06-13 14:04:55,164  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 73 finished: treeAggregate at RowMatrix.scala:93, took 0.018001 s
2016-06-13 14:04:55,168  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_150 stored as values in memory (estimated size 124.9 KB, free 100.4 MB)
2016-06-13 14:04:55,169  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_150_piece0 stored as bytes in memory (estimated size 125.0 KB, free 100.5 MB)
2016-06-13 14:04:55,171  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_150_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:55,173  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 150 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:55,183  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:55,184  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 74 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:55,184  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 84 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,184  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:55,191  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:55,191  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 84 (MapPartitionsRDD[117] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:55,192  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_151 stored as values in memory (estimated size 55.2 KB, free 100.6 MB)
2016-06-13 14:04:55,194  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_151_piece0 stored as bytes in memory (estimated size 8.1 KB, free 100.6 MB)
2016-06-13 14:04:55,196  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_151_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:55,196  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 151 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:55,197  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 84 (MapPartitionsRDD[117] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,197  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 84.0 with 2 tasks
2016-06-13 14:04:55,197  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 84.0 (TID 151, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,198  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 84.0 (TID 152, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,198  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 84.0 (TID 151)
2016-06-13 14:04:55,198  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 84.0 (TID 152)
2016-06-13 14:04:55,202  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:55,203  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:55,205  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 84.0 (TID 151). 45217 bytes result sent to driver
2016-06-13 14:04:55,206  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 84.0 (TID 152). 45217 bytes result sent to driver
2016-06-13 14:04:55,207  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 84.0 (TID 151) in 9 ms on localhost (1/2)
2016-06-13 14:04:55,207  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 84.0 (TID 152) in 9 ms on localhost (2/2)
2016-06-13 14:04:55,207  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 84.0, whose tasks have all completed, from pool 
2016-06-13 14:04:55,208  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 84 (treeAggregate at RowMatrix.scala:93) finished in 0.001 s
2016-06-13 14:04:55,208  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 74 finished: treeAggregate at RowMatrix.scala:93, took 0.024478 s
2016-06-13 14:04:55,211  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_152 stored as values in memory (estimated size 124.9 KB, free 100.7 MB)
2016-06-13 14:04:55,213  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_152_piece0 stored as bytes in memory (estimated size 124.9 KB, free 100.8 MB)
2016-06-13 14:04:55,213  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_152_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:55,214  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 152 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:55,221  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:55,222  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 75 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:55,222  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 85 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,222  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:55,223  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:55,223  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 85 (MapPartitionsRDD[118] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:55,224  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_153 stored as values in memory (estimated size 55.2 KB, free 100.9 MB)
2016-06-13 14:04:55,225  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_153_piece0 stored as bytes in memory (estimated size 8.1 KB, free 100.9 MB)
2016-06-13 14:04:55,226  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_153_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:55,226  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 153 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:55,226  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 85 (MapPartitionsRDD[118] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,226  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 85.0 with 2 tasks
2016-06-13 14:04:55,227  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 85.0 (TID 153, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,228  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 85.0 (TID 154, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,228  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 85.0 (TID 153)
2016-06-13 14:04:55,230  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:55,233  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 85.0 (TID 153). 45217 bytes result sent to driver
2016-06-13 14:04:55,239  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 85.0 (TID 153) in 12 ms on localhost (1/2)
2016-06-13 14:04:55,239  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 85.0 (TID 154)
2016-06-13 14:04:55,242  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:55,244  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 85.0 (TID 154). 45217 bytes result sent to driver
2016-06-13 14:04:55,245  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 85.0 (TID 154) in 18 ms on localhost (2/2)
2016-06-13 14:04:55,245  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 85.0, whose tasks have all completed, from pool 
2016-06-13 14:04:55,245  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 85 (treeAggregate at RowMatrix.scala:93) finished in 0.018 s
2016-06-13 14:04:55,245  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 75 finished: treeAggregate at RowMatrix.scala:93, took 0.023833 s
2016-06-13 14:04:55,248  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_154 stored as values in memory (estimated size 124.9 KB, free 101.0 MB)
2016-06-13 14:04:55,250  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_154_piece0 stored as bytes in memory (estimated size 125.0 KB, free 101.2 MB)
2016-06-13 14:04:55,251  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_154_piece0 in memory on localhost:44356 (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:55,251  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 154 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:55,271  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:55,272  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 76 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:55,272  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 86 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,272  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:55,273  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:55,273  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 86 (MapPartitionsRDD[119] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:55,275  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_155 stored as values in memory (estimated size 55.2 KB, free 101.2 MB)
2016-06-13 14:04:55,276  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_155_piece0 stored as bytes in memory (estimated size 8.1 KB, free 101.2 MB)
2016-06-13 14:04:55,276  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_155_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:55,276  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 155 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:55,277  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 86 (MapPartitionsRDD[119] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,277  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 86.0 with 2 tasks
2016-06-13 14:04:55,277  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 86.0 (TID 155, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,278  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 86.0 (TID 156, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,278  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 86.0 (TID 156)
2016-06-13 14:04:55,278  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 86.0 (TID 155)
2016-06-13 14:04:55,282  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:55,285  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 86.0 (TID 156). 45217 bytes result sent to driver
2016-06-13 14:04:55,286  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 86.0 (TID 156) in 9 ms on localhost (1/2)
2016-06-13 14:04:55,287  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:55,290  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 86.0 (TID 155). 45217 bytes result sent to driver
2016-06-13 14:04:55,291  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 86.0 (TID 155) in 14 ms on localhost (2/2)
2016-06-13 14:04:55,291  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 86 (treeAggregate at RowMatrix.scala:93) finished in 0.003 s
2016-06-13 14:04:55,291  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 86.0, whose tasks have all completed, from pool 
2016-06-13 14:04:55,292  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 76 finished: treeAggregate at RowMatrix.scala:93, took 0.020862 s
2016-06-13 14:04:55,296  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_156 stored as values in memory (estimated size 124.9 KB, free 101.3 MB)
2016-06-13 14:04:55,298  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_156_piece0 stored as bytes in memory (estimated size 124.9 KB, free 101.5 MB)
2016-06-13 14:04:55,299  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_156_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:55,302  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 156 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:55,308  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:55,309  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 77 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:55,309  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 87 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,309  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:55,309  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:55,310  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 87 (MapPartitionsRDD[120] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:55,311  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_157 stored as values in memory (estimated size 55.2 KB, free 101.5 MB)
2016-06-13 14:04:55,312  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_157_piece0 stored as bytes in memory (estimated size 8.1 KB, free 101.5 MB)
2016-06-13 14:04:55,313  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_157_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:55,314  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 157 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:55,314  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 87 (MapPartitionsRDD[120] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,315  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 87.0 with 2 tasks
2016-06-13 14:04:55,316  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 87.0 (TID 157, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,317  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 87.0 (TID 158, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,317  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 87.0 (TID 157)
2016-06-13 14:04:55,317  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 87.0 (TID 158)
2016-06-13 14:04:55,320  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:55,321  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:55,323  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 87.0 (TID 157). 45217 bytes result sent to driver
2016-06-13 14:04:55,324  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 87.0 (TID 157) in 8 ms on localhost (1/2)
2016-06-13 14:04:55,326  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 87.0 (TID 158). 45217 bytes result sent to driver
2016-06-13 14:04:55,327  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 87.0 (TID 158) in 10 ms on localhost (2/2)
2016-06-13 14:04:55,327  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 87.0, whose tasks have all completed, from pool 
2016-06-13 14:04:55,327  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 87 (treeAggregate at RowMatrix.scala:93) finished in 0.010 s
2016-06-13 14:04:55,327  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 77 finished: treeAggregate at RowMatrix.scala:93, took 0.018852 s
2016-06-13 14:04:55,334  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_158 stored as values in memory (estimated size 124.9 KB, free 101.6 MB)
2016-06-13 14:04:55,336  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_158_piece0 stored as bytes in memory (estimated size 124.9 KB, free 101.8 MB)
2016-06-13 14:04:55,336  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_158_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:55,337  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 158 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:55,343  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:55,343  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 78 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:55,344  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 88 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,344  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:55,344  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:55,344  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 88 (MapPartitionsRDD[121] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:55,345  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_159 stored as values in memory (estimated size 55.2 KB, free 101.8 MB)
2016-06-13 14:04:55,346  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_159_piece0 stored as bytes in memory (estimated size 8.1 KB, free 101.8 MB)
2016-06-13 14:04:55,346  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_159_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:55,347  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 159 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:55,347  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 88 (MapPartitionsRDD[121] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,347  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 88.0 with 2 tasks
2016-06-13 14:04:55,348  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 88.0 (TID 159, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,348  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 88.0 (TID 160, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,348  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 88.0 (TID 160)
2016-06-13 14:04:55,350  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 88.0 (TID 159)
2016-06-13 14:04:55,352  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:55,353  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:55,354  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 88.0 (TID 160). 45217 bytes result sent to driver
2016-06-13 14:04:55,355  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 88.0 (TID 160) in 7 ms on localhost (1/2)
2016-06-13 14:04:55,359  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 88.0 (TID 159). 45217 bytes result sent to driver
2016-06-13 14:04:55,360  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 88.0 (TID 159) in 12 ms on localhost (2/2)
2016-06-13 14:04:55,360  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 88.0, whose tasks have all completed, from pool 
2016-06-13 14:04:55,361  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 88 (treeAggregate at RowMatrix.scala:93) finished in 0.013 s
2016-06-13 14:04:55,361  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 78 finished: treeAggregate at RowMatrix.scala:93, took 0.017755 s
2016-06-13 14:04:55,365  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_160 stored as values in memory (estimated size 124.9 KB, free 101.9 MB)
2016-06-13 14:04:55,366  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_160_piece0 stored as bytes in memory (estimated size 124.9 KB, free 102.1 MB)
2016-06-13 14:04:55,367  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_160_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:55,368  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 160 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:55,376  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:55,376  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 79 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:55,376  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 89 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,376  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:55,377  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:55,377  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 89 (MapPartitionsRDD[122] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:55,378  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_161 stored as values in memory (estimated size 55.2 KB, free 102.1 MB)
2016-06-13 14:04:55,379  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_161_piece0 stored as bytes in memory (estimated size 8.1 KB, free 102.1 MB)
2016-06-13 14:04:55,379  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_161_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:55,379  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 161 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:55,379  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 89 (MapPartitionsRDD[122] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,379  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 89.0 with 2 tasks
2016-06-13 14:04:55,380  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 89.0 (TID 161, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,380  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 89.0 (TID 162, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,381  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 89.0 (TID 161)
2016-06-13 14:04:55,381  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 89.0 (TID 162)
2016-06-13 14:04:55,383  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:55,386  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 89.0 (TID 161). 45217 bytes result sent to driver
2016-06-13 14:04:55,388  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:55,391  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 89.0 (TID 162). 45217 bytes result sent to driver
2016-06-13 14:04:55,395  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 89.0 (TID 161) in 14 ms on localhost (1/2)
2016-06-13 14:04:55,395  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 89.0 (TID 162) in 15 ms on localhost (2/2)
2016-06-13 14:04:55,395  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 89.0, whose tasks have all completed, from pool 
2016-06-13 14:04:55,395  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 89 (treeAggregate at RowMatrix.scala:93) finished in 0.015 s
2016-06-13 14:04:55,395  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 79 finished: treeAggregate at RowMatrix.scala:93, took 0.019338 s
2016-06-13 14:04:55,398  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_162 stored as values in memory (estimated size 124.9 KB, free 102.3 MB)
2016-06-13 14:04:55,399  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_162_piece0 stored as bytes in memory (estimated size 124.9 KB, free 102.4 MB)
2016-06-13 14:04:55,400  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_162_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:55,400  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 162 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:55,406  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:55,406  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 80 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:55,406  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 90 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,406  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:55,406  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:55,407  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 90 (MapPartitionsRDD[123] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:55,408  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_163 stored as values in memory (estimated size 55.2 KB, free 102.4 MB)
2016-06-13 14:04:55,409  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_163_piece0 stored as bytes in memory (estimated size 8.1 KB, free 102.4 MB)
2016-06-13 14:04:55,409  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_163_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:55,412  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 163 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:55,412  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 90 (MapPartitionsRDD[123] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,412  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 90.0 with 2 tasks
2016-06-13 14:04:55,413  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 90.0 (TID 163, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,413  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 90.0 (TID 164, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,413  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 90.0 (TID 163)
2016-06-13 14:04:55,413  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 90.0 (TID 164)
2016-06-13 14:04:55,417  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:55,419  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 90.0 (TID 163). 45217 bytes result sent to driver
2016-06-13 14:04:55,420  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 90.0 (TID 163) in 7 ms on localhost (1/2)
2016-06-13 14:04:55,417  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:55,423  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 90.0 (TID 164). 45217 bytes result sent to driver
2016-06-13 14:04:55,424  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 90.0 (TID 164) in 11 ms on localhost (2/2)
2016-06-13 14:04:55,424  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 90.0, whose tasks have all completed, from pool 
2016-06-13 14:04:55,424  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 90 (treeAggregate at RowMatrix.scala:93) finished in 0.010 s
2016-06-13 14:04:55,424  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 80 finished: treeAggregate at RowMatrix.scala:93, took 0.018735 s
2016-06-13 14:04:55,427  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_164 stored as values in memory (estimated size 124.9 KB, free 102.6 MB)
2016-06-13 14:04:55,430  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_164_piece0 stored as bytes in memory (estimated size 124.9 KB, free 102.7 MB)
2016-06-13 14:04:55,430  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_164_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:55,431  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 164 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:55,437  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:55,438  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 81 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:55,438  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 91 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,438  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:55,438  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:55,438  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 91 (MapPartitionsRDD[124] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:55,439  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_165 stored as values in memory (estimated size 55.2 KB, free 102.7 MB)
2016-06-13 14:04:55,440  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_165_piece0 stored as bytes in memory (estimated size 8.1 KB, free 102.7 MB)
2016-06-13 14:04:55,441  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_165_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:55,441  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 165 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:55,441  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 91 (MapPartitionsRDD[124] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,441  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 91.0 with 2 tasks
2016-06-13 14:04:55,442  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 91.0 (TID 165, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,442  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 91.0 (TID 166, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,442  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 91.0 (TID 165)
2016-06-13 14:04:55,442  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 91.0 (TID 166)
2016-06-13 14:04:55,444  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:55,446  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 91.0 (TID 166). 45217 bytes result sent to driver
2016-06-13 14:04:55,446  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 91.0 (TID 166) in 4 ms on localhost (1/2)
2016-06-13 14:04:55,448  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:55,451  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 91.0 (TID 165). 45217 bytes result sent to driver
2016-06-13 14:04:55,452  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 91.0 (TID 165) in 11 ms on localhost (2/2)
2016-06-13 14:04:55,453  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 91.0, whose tasks have all completed, from pool 
2016-06-13 14:04:55,453  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 91 (treeAggregate at RowMatrix.scala:93) finished in 0.012 s
2016-06-13 14:04:55,453  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 81 finished: treeAggregate at RowMatrix.scala:93, took 0.015556 s
2016-06-13 14:04:55,456  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_166 stored as values in memory (estimated size 124.9 KB, free 102.9 MB)
2016-06-13 14:04:55,458  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_166_piece0 stored as bytes in memory (estimated size 124.9 KB, free 103.0 MB)
2016-06-13 14:04:55,462  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_166_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:55,464  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 166 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:55,469  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:55,470  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 82 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:55,470  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 92 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,470  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:55,470  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:55,470  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 92 (MapPartitionsRDD[125] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:55,471  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_167 stored as values in memory (estimated size 55.2 KB, free 103.0 MB)
2016-06-13 14:04:55,472  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_167_piece0 stored as bytes in memory (estimated size 8.1 KB, free 103.0 MB)
2016-06-13 14:04:55,473  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_167_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:55,473  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 167 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:55,473  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 92 (MapPartitionsRDD[125] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,473  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 92.0 with 2 tasks
2016-06-13 14:04:55,474  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 92.0 (TID 167, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,474  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 92.0 (TID 168, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,474  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 92.0 (TID 168)
2016-06-13 14:04:55,476  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:55,474  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 92.0 (TID 167)
2016-06-13 14:04:55,478  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 92.0 (TID 168). 45217 bytes result sent to driver
2016-06-13 14:04:55,478  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 92.0 (TID 168) in 4 ms on localhost (1/2)
2016-06-13 14:04:55,480  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:55,483  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 92.0 (TID 167). 45217 bytes result sent to driver
2016-06-13 14:04:55,484  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 92.0 (TID 167) in 10 ms on localhost (2/2)
2016-06-13 14:04:55,484  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 92 (treeAggregate at RowMatrix.scala:93) finished in 0.011 s
2016-06-13 14:04:55,484  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 92.0, whose tasks have all completed, from pool 
2016-06-13 14:04:55,484  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 82 finished: treeAggregate at RowMatrix.scala:93, took 0.014377 s
2016-06-13 14:04:55,487  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_168 stored as values in memory (estimated size 124.9 KB, free 103.2 MB)
2016-06-13 14:04:55,488  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_168_piece0 stored as bytes in memory (estimated size 124.8 KB, free 103.3 MB)
2016-06-13 14:04:55,489  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_168_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:55,489  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 168 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:55,497  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:55,497  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 83 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:55,497  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 93 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,497  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:55,498  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:55,498  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 93 (MapPartitionsRDD[126] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:55,500  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_169 stored as values in memory (estimated size 55.2 KB, free 103.3 MB)
2016-06-13 14:04:55,501  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_169_piece0 stored as bytes in memory (estimated size 8.1 KB, free 103.4 MB)
2016-06-13 14:04:55,501  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_169_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:55,501  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 169 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:55,502  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 93 (MapPartitionsRDD[126] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,502  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 93.0 with 2 tasks
2016-06-13 14:04:55,503  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 93.0 (TID 169, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,503  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 93.0 (TID 170, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,503  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 93.0 (TID 170)
2016-06-13 14:04:55,503  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 93.0 (TID 169)
2016-06-13 14:04:55,506  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:55,508  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 93.0 (TID 170). 45217 bytes result sent to driver
2016-06-13 14:04:55,506  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:55,509  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 93.0 (TID 170) in 6 ms on localhost (1/2)
2016-06-13 14:04:55,512  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 93.0 (TID 169). 45217 bytes result sent to driver
2016-06-13 14:04:55,515  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 93.0 (TID 169) in 12 ms on localhost (2/2)
2016-06-13 14:04:55,515  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 93.0, whose tasks have all completed, from pool 
2016-06-13 14:04:55,515  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 93 (treeAggregate at RowMatrix.scala:93) finished in 0.012 s
2016-06-13 14:04:55,515  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 83 finished: treeAggregate at RowMatrix.scala:93, took 0.018190 s
2016-06-13 14:04:55,518  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_170 stored as values in memory (estimated size 124.9 KB, free 103.5 MB)
2016-06-13 14:04:55,520  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_170_piece0 stored as bytes in memory (estimated size 124.9 KB, free 103.6 MB)
2016-06-13 14:04:55,521  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_170_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:55,521  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 170 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:55,537  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:55,552  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 84 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:55,552  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 94 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,552  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:55,566  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:55,566  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 94 (MapPartitionsRDD[127] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:55,568  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_171 stored as values in memory (estimated size 55.2 KB, free 103.7 MB)
2016-06-13 14:04:55,569  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_171_piece0 stored as bytes in memory (estimated size 8.1 KB, free 103.7 MB)
2016-06-13 14:04:55,570  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_171_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:55,570  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 171 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:55,571  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 94 (MapPartitionsRDD[127] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,571  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 94.0 with 2 tasks
2016-06-13 14:04:55,572  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 94.0 (TID 171, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,572  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 94.0 (TID 172, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,572  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 94.0 (TID 171)
2016-06-13 14:04:55,572  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 94.0 (TID 172)
2016-06-13 14:04:55,588  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:55,593  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:55,595  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 94.0 (TID 172). 45217 bytes result sent to driver
2016-06-13 14:04:55,596  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 94.0 (TID 172) in 24 ms on localhost (1/2)
2016-06-13 14:04:55,596  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 94.0 (TID 171). 45217 bytes result sent to driver
2016-06-13 14:04:55,597  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 94.0 (TID 171) in 26 ms on localhost (2/2)
2016-06-13 14:04:55,597  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 94.0, whose tasks have all completed, from pool 
2016-06-13 14:04:55,598  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 94 (treeAggregate at RowMatrix.scala:93) finished in 0.006 s
2016-06-13 14:04:55,598  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 84 finished: treeAggregate at RowMatrix.scala:93, took 0.047644 s
2016-06-13 14:04:55,607  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_172 stored as values in memory (estimated size 124.9 KB, free 103.8 MB)
2016-06-13 14:04:55,608  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_172_piece0 stored as bytes in memory (estimated size 124.9 KB, free 103.9 MB)
2016-06-13 14:04:55,608  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_172_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:55,609  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 172 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:55,616  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:55,616  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 85 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:55,616  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 95 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,616  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:55,617  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:55,617  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 95 (MapPartitionsRDD[128] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:55,618  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_173 stored as values in memory (estimated size 55.2 KB, free 104.0 MB)
2016-06-13 14:04:55,619  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_173_piece0 stored as bytes in memory (estimated size 8.1 KB, free 104.0 MB)
2016-06-13 14:04:55,620  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_173_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:55,621  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 173 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:55,621  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 95 (MapPartitionsRDD[128] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,621  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 95.0 with 2 tasks
2016-06-13 14:04:55,622  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 95.0 (TID 173, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,622  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 95.0 (TID 174, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,622  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 95.0 (TID 173)
2016-06-13 14:04:55,622  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 95.0 (TID 174)
2016-06-13 14:04:55,625  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:55,629  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 95.0 (TID 174). 45217 bytes result sent to driver
2016-06-13 14:04:55,632  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:55,633  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 95.0 (TID 174) in 11 ms on localhost (1/2)
2016-06-13 14:04:55,639  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 95.0 (TID 173). 45217 bytes result sent to driver
2016-06-13 14:04:55,640  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 95.0 (TID 173) in 18 ms on localhost (2/2)
2016-06-13 14:04:55,640  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 95.0, whose tasks have all completed, from pool 
2016-06-13 14:04:55,641  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 95 (treeAggregate at RowMatrix.scala:93) finished in 0.009 s
2016-06-13 14:04:55,641  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 85 finished: treeAggregate at RowMatrix.scala:93, took 0.025541 s
2016-06-13 14:04:55,648  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_174 stored as values in memory (estimated size 124.9 KB, free 104.1 MB)
2016-06-13 14:04:55,649  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_174_piece0 stored as bytes in memory (estimated size 124.9 KB, free 104.2 MB)
2016-06-13 14:04:55,650  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_174_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:55,650  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 174 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:55,659  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:55,660  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 86 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:55,660  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 96 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,660  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:55,661  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:55,661  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 96 (MapPartitionsRDD[129] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:55,662  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_175 stored as values in memory (estimated size 55.2 KB, free 104.3 MB)
2016-06-13 14:04:55,664  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_175_piece0 stored as bytes in memory (estimated size 8.1 KB, free 104.3 MB)
2016-06-13 14:04:55,665  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_175_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:55,665  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 175 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:55,665  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 96 (MapPartitionsRDD[129] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,665  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 96.0 with 2 tasks
2016-06-13 14:04:55,666  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 96.0 (TID 175, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,666  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 96.0 (TID 176, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,666  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 96.0 (TID 175)
2016-06-13 14:04:55,667  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 96.0 (TID 176)
2016-06-13 14:04:55,669  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:55,669  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:55,671  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 96.0 (TID 175). 45217 bytes result sent to driver
2016-06-13 14:04:55,672  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 96.0 (TID 176). 45217 bytes result sent to driver
2016-06-13 14:04:55,672  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 96.0 (TID 175) in 6 ms on localhost (1/2)
2016-06-13 14:04:55,673  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 96.0 (TID 176) in 7 ms on localhost (2/2)
2016-06-13 14:04:55,673  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 96.0, whose tasks have all completed, from pool 
2016-06-13 14:04:55,673  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 96 (treeAggregate at RowMatrix.scala:93) finished in 0.007 s
2016-06-13 14:04:55,674  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 86 finished: treeAggregate at RowMatrix.scala:93, took 0.014672 s
2016-06-13 14:04:55,678  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_176 stored as values in memory (estimated size 124.9 KB, free 104.4 MB)
2016-06-13 14:04:55,680  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_176_piece0 stored as bytes in memory (estimated size 124.9 KB, free 104.5 MB)
2016-06-13 14:04:55,680  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_176_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:55,680  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 176 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:55,688  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:55,695  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 87 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:55,695  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 97 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,695  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:55,696  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:55,696  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 97 (MapPartitionsRDD[130] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:55,698  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_177 stored as values in memory (estimated size 55.2 KB, free 104.6 MB)
2016-06-13 14:04:55,699  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_177_piece0 stored as bytes in memory (estimated size 8.1 KB, free 104.6 MB)
2016-06-13 14:04:55,700  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_177_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:55,701  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 177 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:55,701  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 97 (MapPartitionsRDD[130] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,701  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 97.0 with 2 tasks
2016-06-13 14:04:55,702  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 97.0 (TID 177, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,702  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 97.0 (TID 178, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,702  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 97.0 (TID 177)
2016-06-13 14:04:55,702  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 97.0 (TID 178)
2016-06-13 14:04:55,705  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:55,707  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:55,711  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 97.0 (TID 178). 45217 bytes result sent to driver
2016-06-13 14:04:55,712  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 97.0 (TID 177). 45217 bytes result sent to driver
2016-06-13 14:04:55,716  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 97.0 (TID 178) in 13 ms on localhost (1/2)
2016-06-13 14:04:55,716  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 97.0 (TID 177) in 15 ms on localhost (2/2)
2016-06-13 14:04:55,716  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 97.0, whose tasks have all completed, from pool 
2016-06-13 14:04:55,717  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 97 (treeAggregate at RowMatrix.scala:93) finished in 0.016 s
2016-06-13 14:04:55,717  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 87 finished: treeAggregate at RowMatrix.scala:93, took 0.026949 s
2016-06-13 14:04:55,721  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_178 stored as values in memory (estimated size 124.9 KB, free 104.7 MB)
2016-06-13 14:04:55,723  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_178_piece0 stored as bytes in memory (estimated size 124.9 KB, free 104.8 MB)
2016-06-13 14:04:55,723  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_178_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:55,726  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 178 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:55,735  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:55,736  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 88 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:55,736  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 98 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,736  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:55,736  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:55,737  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 98 (MapPartitionsRDD[131] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:55,739  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_179 stored as values in memory (estimated size 55.2 KB, free 104.9 MB)
2016-06-13 14:04:55,740  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_179_piece0 stored as bytes in memory (estimated size 8.1 KB, free 104.9 MB)
2016-06-13 14:04:55,741  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_179_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:55,741  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 179 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:55,742  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 98 (MapPartitionsRDD[131] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,742  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 98.0 with 2 tasks
2016-06-13 14:04:55,743  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 98.0 (TID 179, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,743  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 98.0 (TID 180, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,744  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 98.0 (TID 179)
2016-06-13 14:04:55,747  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:55,749  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 98.0 (TID 179). 45217 bytes result sent to driver
2016-06-13 14:04:55,750  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 98.0 (TID 179) in 7 ms on localhost (1/2)
2016-06-13 14:04:55,752  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 98.0 (TID 180)
2016-06-13 14:04:55,755  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:55,758  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 98.0 (TID 180). 45217 bytes result sent to driver
2016-06-13 14:04:55,759  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 98.0 (TID 180) in 16 ms on localhost (2/2)
2016-06-13 14:04:55,760  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 98.0, whose tasks have all completed, from pool 
2016-06-13 14:04:55,761  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 98 (treeAggregate at RowMatrix.scala:93) finished in 0.018 s
2016-06-13 14:04:55,761  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 88 finished: treeAggregate at RowMatrix.scala:93, took 0.025930 s
2016-06-13 14:04:55,765  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_180 stored as values in memory (estimated size 124.9 KB, free 105.0 MB)
2016-06-13 14:04:55,767  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_180_piece0 stored as bytes in memory (estimated size 124.9 KB, free 105.1 MB)
2016-06-13 14:04:55,768  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_180_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:55,769  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 180 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:55,777  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:55,778  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 89 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:55,778  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 99 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,778  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:55,778  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:55,778  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 99 (MapPartitionsRDD[132] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:55,780  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_181 stored as values in memory (estimated size 55.2 KB, free 105.2 MB)
2016-06-13 14:04:55,782  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_181_piece0 stored as bytes in memory (estimated size 8.1 KB, free 105.2 MB)
2016-06-13 14:04:55,782  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_181_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:55,783  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 181 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:55,783  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 99 (MapPartitionsRDD[132] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,783  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 99.0 with 2 tasks
2016-06-13 14:04:55,784  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 99.0 (TID 181, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,784  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 99.0 (TID 182, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,785  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 99.0 (TID 182)
2016-06-13 14:04:55,785  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 99.0 (TID 181)
2016-06-13 14:04:55,789  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:55,789  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:55,792  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 99.0 (TID 181). 45217 bytes result sent to driver
2016-06-13 14:04:55,792  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 99.0 (TID 182). 45217 bytes result sent to driver
2016-06-13 14:04:55,793  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 99.0 (TID 181) in 8 ms on localhost (1/2)
2016-06-13 14:04:55,793  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 99.0 (TID 182) in 9 ms on localhost (2/2)
2016-06-13 14:04:55,793  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 99.0, whose tasks have all completed, from pool 
2016-06-13 14:04:55,793  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 99 (treeAggregate at RowMatrix.scala:93) finished in 0.008 s
2016-06-13 14:04:55,793  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 89 finished: treeAggregate at RowMatrix.scala:93, took 0.016274 s
2016-06-13 14:04:55,797  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_182 stored as values in memory (estimated size 124.9 KB, free 105.3 MB)
2016-06-13 14:04:55,798  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_182_piece0 stored as bytes in memory (estimated size 124.9 KB, free 105.4 MB)
2016-06-13 14:04:55,798  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_182_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:55,799  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 182 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:55,805  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:55,805  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 90 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:55,805  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 100 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,805  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:55,805  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:55,806  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 100 (MapPartitionsRDD[133] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:55,807  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_183 stored as values in memory (estimated size 55.2 KB, free 105.5 MB)
2016-06-13 14:04:55,808  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_183_piece0 stored as bytes in memory (estimated size 8.1 KB, free 105.5 MB)
2016-06-13 14:04:55,808  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_183_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:55,809  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 183 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:55,809  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 100 (MapPartitionsRDD[133] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,809  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 100.0 with 2 tasks
2016-06-13 14:04:55,810  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 100.0 (TID 183, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,810  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 100.0 (TID 184, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,810  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 100.0 (TID 183)
2016-06-13 14:04:55,810  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 100.0 (TID 184)
2016-06-13 14:04:55,813  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:55,814  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:55,816  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 100.0 (TID 183). 45217 bytes result sent to driver
2016-06-13 14:04:55,817  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 100.0 (TID 183) in 8 ms on localhost (1/2)
2016-06-13 14:04:55,818  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 100.0 (TID 184). 45217 bytes result sent to driver
2016-06-13 14:04:55,819  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 100.0 (TID 184) in 9 ms on localhost (2/2)
2016-06-13 14:04:55,819  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 100.0, whose tasks have all completed, from pool 
2016-06-13 14:04:55,820  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 100 (treeAggregate at RowMatrix.scala:93) finished in 0.010 s
2016-06-13 14:04:55,820  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 90 finished: treeAggregate at RowMatrix.scala:93, took 0.015498 s
2016-06-13 14:04:55,824  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_184 stored as values in memory (estimated size 124.9 KB, free 105.6 MB)
2016-06-13 14:04:55,846  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_184_piece0 stored as bytes in memory (estimated size 124.9 KB, free 105.7 MB)
2016-06-13 14:04:55,846  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_184_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:55,849  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 184 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:55,861  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:55,862  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 91 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:55,862  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 101 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,862  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:55,863  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:55,863  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 101 (MapPartitionsRDD[134] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:55,865  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_185 stored as values in memory (estimated size 55.2 KB, free 105.8 MB)
2016-06-13 14:04:55,867  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_185_piece0 stored as bytes in memory (estimated size 8.1 KB, free 105.8 MB)
2016-06-13 14:04:55,867  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_185_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:55,867  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 185 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:55,868  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 101 (MapPartitionsRDD[134] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,868  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 101.0 with 2 tasks
2016-06-13 14:04:55,868  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 101.0 (TID 185, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,869  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 101.0 (TID 186, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,869  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 101.0 (TID 185)
2016-06-13 14:04:55,869  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 101.0 (TID 186)
2016-06-13 14:04:55,871  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:55,874  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 101.0 (TID 186). 45217 bytes result sent to driver
2016-06-13 14:04:55,874  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 101.0 (TID 186) in 6 ms on localhost (1/2)
2016-06-13 14:04:55,876  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:55,880  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 101.0 (TID 185). 45217 bytes result sent to driver
2016-06-13 14:04:55,881  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 101.0 (TID 185) in 13 ms on localhost (2/2)
2016-06-13 14:04:55,881  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 101.0, whose tasks have all completed, from pool 
2016-06-13 14:04:55,881  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 101 (treeAggregate at RowMatrix.scala:93) finished in 0.002 s
2016-06-13 14:04:55,889  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 91 finished: treeAggregate at RowMatrix.scala:93, took 0.027280 s
2016-06-13 14:04:55,893  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_186 stored as values in memory (estimated size 124.9 KB, free 105.9 MB)
2016-06-13 14:04:55,894  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_186_piece0 stored as bytes in memory (estimated size 124.8 KB, free 106.0 MB)
2016-06-13 14:04:55,895  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_186_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:55,895  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 186 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:55,905  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:55,906  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 92 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:55,906  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 102 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,906  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:55,906  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:55,906  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 102 (MapPartitionsRDD[135] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:55,908  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_187 stored as values in memory (estimated size 55.2 KB, free 106.1 MB)
2016-06-13 14:04:55,909  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_187_piece0 stored as bytes in memory (estimated size 8.1 KB, free 106.1 MB)
2016-06-13 14:04:55,909  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_187_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:55,910  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 187 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:55,912  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 102 (MapPartitionsRDD[135] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,912  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 102.0 with 2 tasks
2016-06-13 14:04:55,913  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 102.0 (TID 187, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,913  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 102.0 (TID 188, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,914  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 102.0 (TID 187)
2016-06-13 14:04:55,914  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 102.0 (TID 188)
2016-06-13 14:04:55,918  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:55,923  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:55,927  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 102.0 (TID 188). 45217 bytes result sent to driver
2016-06-13 14:04:55,927  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 102.0 (TID 187). 45217 bytes result sent to driver
2016-06-13 14:04:55,929  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 102.0 (TID 188) in 16 ms on localhost (1/2)
2016-06-13 14:04:55,929  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 102.0 (TID 187) in 16 ms on localhost (2/2)
2016-06-13 14:04:55,929  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 102.0, whose tasks have all completed, from pool 
2016-06-13 14:04:55,930  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 102 (treeAggregate at RowMatrix.scala:93) finished in 0.004 s
2016-06-13 14:04:55,931  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 92 finished: treeAggregate at RowMatrix.scala:93, took 0.025298 s
2016-06-13 14:04:55,934  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_188 stored as values in memory (estimated size 124.9 KB, free 106.2 MB)
2016-06-13 14:04:55,936  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_188_piece0 stored as bytes in memory (estimated size 124.9 KB, free 106.3 MB)
2016-06-13 14:04:55,936  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_188_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:55,937  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 188 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:55,943  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:55,943  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 93 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:55,943  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 103 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,943  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:55,944  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:55,944  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 103 (MapPartitionsRDD[136] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:55,946  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_189 stored as values in memory (estimated size 55.2 KB, free 106.4 MB)
2016-06-13 14:04:55,948  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_189_piece0 stored as bytes in memory (estimated size 8.1 KB, free 106.4 MB)
2016-06-13 14:04:55,948  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_189_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:55,949  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 189 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:55,949  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 103 (MapPartitionsRDD[136] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,949  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 103.0 with 2 tasks
2016-06-13 14:04:55,950  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 103.0 (TID 189, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,950  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 103.0 (TID 190, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,950  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 103.0 (TID 189)
2016-06-13 14:04:55,950  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 103.0 (TID 190)
2016-06-13 14:04:55,953  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:55,956  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:55,959  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 103.0 (TID 189). 45217 bytes result sent to driver
2016-06-13 14:04:55,959  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 103.0 (TID 190). 45217 bytes result sent to driver
2016-06-13 14:04:55,960  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 103.0 (TID 189) in 11 ms on localhost (1/2)
2016-06-13 14:04:55,961  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 103.0 (TID 190) in 11 ms on localhost (2/2)
2016-06-13 14:04:55,961  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 103.0, whose tasks have all completed, from pool 
2016-06-13 14:04:55,961  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 103 (treeAggregate at RowMatrix.scala:93) finished in 0.001 s
2016-06-13 14:04:55,962  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 93 finished: treeAggregate at RowMatrix.scala:93, took 0.018560 s
2016-06-13 14:04:55,965  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_190 stored as values in memory (estimated size 124.9 KB, free 106.5 MB)
2016-06-13 14:04:55,967  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_190_piece0 stored as bytes in memory (estimated size 124.9 KB, free 106.7 MB)
2016-06-13 14:04:55,967  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_190_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:55,968  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 190 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:55,979  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:55,980  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 94 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:55,980  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 104 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,980  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:55,980  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:55,981  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 104 (MapPartitionsRDD[137] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:55,983  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_191 stored as values in memory (estimated size 55.2 KB, free 106.7 MB)
2016-06-13 14:04:55,984  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_191_piece0 stored as bytes in memory (estimated size 8.1 KB, free 106.7 MB)
2016-06-13 14:04:55,984  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_191_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:55,985  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 191 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:55,985  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 104 (MapPartitionsRDD[137] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:55,985  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 104.0 with 2 tasks
2016-06-13 14:04:55,986  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 104.0 (TID 191, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,986  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 104.0 (TID 192, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:55,987  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 104.0 (TID 191)
2016-06-13 14:04:55,989  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:55,990  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 104.0 (TID 192)
2016-06-13 14:04:55,992  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:55,997  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 104.0 (TID 191). 45217 bytes result sent to driver
2016-06-13 14:04:55,998  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 104.0 (TID 191) in 12 ms on localhost (1/2)
2016-06-13 14:04:55,998  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 104.0 (TID 192). 45217 bytes result sent to driver
2016-06-13 14:04:56,000  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 104.0 (TID 192) in 14 ms on localhost (2/2)
2016-06-13 14:04:56,000  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 104 (treeAggregate at RowMatrix.scala:93) finished in 0.014 s
2016-06-13 14:04:56,000  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 104.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,000  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 94 finished: treeAggregate at RowMatrix.scala:93, took 0.021019 s
2016-06-13 14:04:56,004  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_192 stored as values in memory (estimated size 124.9 KB, free 106.8 MB)
2016-06-13 14:04:56,006  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_192_piece0 stored as bytes in memory (estimated size 124.8 KB, free 107.0 MB)
2016-06-13 14:04:56,006  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_192_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:56,007  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 192 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:56,017  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:56,022  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 95 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:56,022  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 105 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,022  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:56,023  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:56,023  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 105 (MapPartitionsRDD[138] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:56,024  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_193 stored as values in memory (estimated size 55.2 KB, free 107.0 MB)
2016-06-13 14:04:56,025  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_193_piece0 stored as bytes in memory (estimated size 8.1 KB, free 107.0 MB)
2016-06-13 14:04:56,026  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_193_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:56,026  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 193 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:56,026  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 105 (MapPartitionsRDD[138] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,026  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 105.0 with 2 tasks
2016-06-13 14:04:56,027  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 105.0 (TID 193, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,027  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 105.0 (TID 194, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,027  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 105.0 (TID 193)
2016-06-13 14:04:56,030  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:56,030  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 105.0 (TID 194)
2016-06-13 14:04:56,035  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:56,037  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 105.0 (TID 193). 45217 bytes result sent to driver
2016-06-13 14:04:56,038  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 105.0 (TID 194). 45217 bytes result sent to driver
2016-06-13 14:04:56,038  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 105.0 (TID 193) in 11 ms on localhost (1/2)
2016-06-13 14:04:56,039  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 105.0 (TID 194) in 12 ms on localhost (2/2)
2016-06-13 14:04:56,039  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 105.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,042  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 105 (treeAggregate at RowMatrix.scala:93) finished in 0.013 s
2016-06-13 14:04:56,043  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 95 finished: treeAggregate at RowMatrix.scala:93, took 0.021590 s
2016-06-13 14:04:56,047  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_194 stored as values in memory (estimated size 124.9 KB, free 107.1 MB)
2016-06-13 14:04:56,048  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_194_piece0 stored as bytes in memory (estimated size 124.8 KB, free 107.3 MB)
2016-06-13 14:04:56,049  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_194_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:56,049  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 194 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:56,057  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:56,057  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 96 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:56,058  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 106 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,058  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:56,058  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:56,059  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 106 (MapPartitionsRDD[139] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:56,061  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_195 stored as values in memory (estimated size 55.2 KB, free 107.3 MB)
2016-06-13 14:04:56,062  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_195_piece0 stored as bytes in memory (estimated size 8.1 KB, free 107.3 MB)
2016-06-13 14:04:56,062  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_195_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:56,063  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 195 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:56,064  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 106 (MapPartitionsRDD[139] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,065  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 106.0 with 2 tasks
2016-06-13 14:04:56,067  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 106.0 (TID 195, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,069  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 106.0 (TID 196, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,070  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 106.0 (TID 195)
2016-06-13 14:04:56,072  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 106.0 (TID 196)
2016-06-13 14:04:56,073  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:56,077  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:56,078  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 106.0 (TID 195). 45217 bytes result sent to driver
2016-06-13 14:04:56,079  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 106.0 (TID 195) in 13 ms on localhost (1/2)
2016-06-13 14:04:56,082  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 106.0 (TID 196). 45217 bytes result sent to driver
2016-06-13 14:04:56,083  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 106.0 (TID 196) in 14 ms on localhost (2/2)
2016-06-13 14:04:56,083  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 106.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,084  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 106 (treeAggregate at RowMatrix.scala:93) finished in 0.017 s
2016-06-13 14:04:56,084  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 96 finished: treeAggregate at RowMatrix.scala:93, took 0.027368 s
2016-06-13 14:04:56,088  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_196 stored as values in memory (estimated size 124.9 KB, free 107.4 MB)
2016-06-13 14:04:56,090  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_196_piece0 stored as bytes in memory (estimated size 124.9 KB, free 107.6 MB)
2016-06-13 14:04:56,090  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_196_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:56,091  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 196 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:56,109  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:56,110  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 97 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:56,110  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 107 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,110  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:56,110  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:56,110  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 107 (MapPartitionsRDD[140] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:56,112  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_197 stored as values in memory (estimated size 55.2 KB, free 107.6 MB)
2016-06-13 14:04:56,113  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_197_piece0 stored as bytes in memory (estimated size 8.1 KB, free 107.6 MB)
2016-06-13 14:04:56,113  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_197_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:56,116  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 197 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:56,117  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 107 (MapPartitionsRDD[140] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,118  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 107.0 with 2 tasks
2016-06-13 14:04:56,120  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 107.0 (TID 197, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,120  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 107.0 (TID 198, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,121  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 107.0 (TID 198)
2016-06-13 14:04:56,121  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 107.0 (TID 197)
2016-06-13 14:04:56,127  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:56,128  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:56,130  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 107.0 (TID 197). 45217 bytes result sent to driver
2016-06-13 14:04:56,131  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 107.0 (TID 198). 45217 bytes result sent to driver
2016-06-13 14:04:56,132  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 107.0 (TID 197) in 12 ms on localhost (1/2)
2016-06-13 14:04:56,133  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 107.0 (TID 198) in 13 ms on localhost (2/2)
2016-06-13 14:04:56,133  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 107.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,135  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 107 (treeAggregate at RowMatrix.scala:93) finished in 0.011 s
2016-06-13 14:04:56,135  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 97 finished: treeAggregate at RowMatrix.scala:93, took 0.026066 s
2016-06-13 14:04:56,139  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_198 stored as values in memory (estimated size 124.9 KB, free 107.8 MB)
2016-06-13 14:04:56,140  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_198_piece0 stored as bytes in memory (estimated size 124.9 KB, free 107.9 MB)
2016-06-13 14:04:56,142  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_198_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:56,145  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 198 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:56,152  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:56,152  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 98 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:56,152  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 108 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,152  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:56,153  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:56,153  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 108 (MapPartitionsRDD[141] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:56,154  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_199 stored as values in memory (estimated size 55.2 KB, free 107.9 MB)
2016-06-13 14:04:56,156  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_199_piece0 stored as bytes in memory (estimated size 8.1 KB, free 107.9 MB)
2016-06-13 14:04:56,156  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_199_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:56,157  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 199 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:56,157  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 108 (MapPartitionsRDD[141] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,157  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 108.0 with 2 tasks
2016-06-13 14:04:56,158  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 108.0 (TID 199, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,158  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 108.0 (TID 200, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,159  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 108.0 (TID 199)
2016-06-13 14:04:56,159  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 108.0 (TID 200)
2016-06-13 14:04:56,162  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:56,162  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:56,164  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 108.0 (TID 200). 45217 bytes result sent to driver
2016-06-13 14:04:56,165  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 108.0 (TID 199). 45217 bytes result sent to driver
2016-06-13 14:04:56,166  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 108.0 (TID 200) in 8 ms on localhost (1/2)
2016-06-13 14:04:56,167  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 108.0 (TID 199) in 9 ms on localhost (2/2)
2016-06-13 14:04:56,167  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 108 (treeAggregate at RowMatrix.scala:93) finished in 0.007 s
2016-06-13 14:04:56,167  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 98 finished: treeAggregate at RowMatrix.scala:93, took 0.015205 s
2016-06-13 14:04:56,167  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 108.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,171  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_200 stored as values in memory (estimated size 124.9 KB, free 108.1 MB)
2016-06-13 14:04:56,172  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_200_piece0 stored as bytes in memory (estimated size 124.8 KB, free 108.2 MB)
2016-06-13 14:04:56,172  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_200_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:56,173  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 200 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:56,178  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:56,178  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 99 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:56,178  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 109 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,178  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:56,179  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:56,179  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 109 (MapPartitionsRDD[142] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:56,180  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_201 stored as values in memory (estimated size 55.2 KB, free 108.2 MB)
2016-06-13 14:04:56,181  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_201_piece0 stored as bytes in memory (estimated size 8.1 KB, free 108.2 MB)
2016-06-13 14:04:56,181  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_201_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:56,181  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 201 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:56,181  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 109 (MapPartitionsRDD[142] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,181  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 109.0 with 2 tasks
2016-06-13 14:04:56,182  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 109.0 (TID 201, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,182  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 109.0 (TID 202, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,182  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 109.0 (TID 201)
2016-06-13 14:04:56,182  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 109.0 (TID 202)
2016-06-13 14:04:56,185  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:56,185  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:56,187  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 109.0 (TID 201). 45217 bytes result sent to driver
2016-06-13 14:04:56,187  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 109.0 (TID 202). 45217 bytes result sent to driver
2016-06-13 14:04:56,188  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 109.0 (TID 201) in 6 ms on localhost (1/2)
2016-06-13 14:04:56,188  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 109.0 (TID 202) in 6 ms on localhost (2/2)
2016-06-13 14:04:56,188  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 109.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,188  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 109 (treeAggregate at RowMatrix.scala:93) finished in 0.007 s
2016-06-13 14:04:56,189  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 99 finished: treeAggregate at RowMatrix.scala:93, took 0.010977 s
2016-06-13 14:04:56,192  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_202 stored as values in memory (estimated size 124.9 KB, free 108.4 MB)
2016-06-13 14:04:56,193  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_202_piece0 stored as bytes in memory (estimated size 124.8 KB, free 108.5 MB)
2016-06-13 14:04:56,193  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_202_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:56,193  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 202 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:56,197  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:56,197  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 100 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:56,197  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 110 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,197  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:56,198  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:56,198  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 110 (MapPartitionsRDD[143] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:56,199  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_203 stored as values in memory (estimated size 55.2 KB, free 108.5 MB)
2016-06-13 14:04:56,200  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_203_piece0 stored as bytes in memory (estimated size 8.1 KB, free 108.5 MB)
2016-06-13 14:04:56,200  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_203_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:56,200  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 203 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:56,200  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 110 (MapPartitionsRDD[143] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,200  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 110.0 with 2 tasks
2016-06-13 14:04:56,202  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 110.0 (TID 203, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,202  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 110.0 (TID 204, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,203  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 110.0 (TID 204)
2016-06-13 14:04:56,203  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 110.0 (TID 203)
2016-06-13 14:04:56,205  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:56,206  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:56,208  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 110.0 (TID 204). 45217 bytes result sent to driver
2016-06-13 14:04:56,208  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 110.0 (TID 203). 45217 bytes result sent to driver
2016-06-13 14:04:56,209  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 110.0 (TID 204) in 7 ms on localhost (1/2)
2016-06-13 14:04:56,210  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 110.0 (TID 203) in 9 ms on localhost (2/2)
2016-06-13 14:04:56,210  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 110.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,210  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 110 (treeAggregate at RowMatrix.scala:93) finished in 0.009 s
2016-06-13 14:04:56,211  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 100 finished: treeAggregate at RowMatrix.scala:93, took 0.013895 s
2016-06-13 14:04:56,215  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_204 stored as values in memory (estimated size 124.9 KB, free 108.7 MB)
2016-06-13 14:04:56,217  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_204_piece0 stored as bytes in memory (estimated size 124.9 KB, free 108.8 MB)
2016-06-13 14:04:56,217  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_204_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:56,217  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 204 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:56,221  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:56,222  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 101 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:56,222  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 111 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,222  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:56,222  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:56,222  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 111 (MapPartitionsRDD[144] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:56,223  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_205 stored as values in memory (estimated size 55.2 KB, free 108.8 MB)
2016-06-13 14:04:56,224  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_205_piece0 stored as bytes in memory (estimated size 8.1 KB, free 108.9 MB)
2016-06-13 14:04:56,224  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_205_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:56,225  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 205 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:56,226  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 111 (MapPartitionsRDD[144] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,226  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 111.0 with 2 tasks
2016-06-13 14:04:56,226  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 111.0 (TID 205, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,226  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 111.0 (TID 206, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,226  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 111.0 (TID 205)
2016-06-13 14:04:56,226  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 111.0 (TID 206)
2016-06-13 14:04:56,228  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:56,229  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:56,230  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 111.0 (TID 206). 45217 bytes result sent to driver
2016-06-13 14:04:56,230  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 111.0 (TID 206) in 4 ms on localhost (1/2)
2016-06-13 14:04:56,231  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 111.0 (TID 205). 45217 bytes result sent to driver
2016-06-13 14:04:56,232  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 111.0 (TID 205) in 6 ms on localhost (2/2)
2016-06-13 14:04:56,232  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 111 (treeAggregate at RowMatrix.scala:93) finished in 0.006 s
2016-06-13 14:04:56,232  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 111.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,232  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 101 finished: treeAggregate at RowMatrix.scala:93, took 0.010862 s
2016-06-13 14:04:56,235  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_206 stored as values in memory (estimated size 124.9 KB, free 109.0 MB)
2016-06-13 14:04:56,236  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_206_piece0 stored as bytes in memory (estimated size 124.8 KB, free 109.1 MB)
2016-06-13 14:04:56,236  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_206_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:56,237  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 206 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:56,245  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:56,250  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 102 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:56,250  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 112 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,250  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:56,251  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:56,251  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 112 (MapPartitionsRDD[145] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:56,252  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_207 stored as values in memory (estimated size 55.2 KB, free 109.2 MB)
2016-06-13 14:04:56,254  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_207_piece0 stored as bytes in memory (estimated size 8.1 KB, free 109.2 MB)
2016-06-13 14:04:56,254  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_207_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:56,258  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 207 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:56,258  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 112 (MapPartitionsRDD[145] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,258  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 112.0 with 2 tasks
2016-06-13 14:04:56,259  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 112.0 (TID 207, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,259  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 112.0 (TID 208, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,259  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 112.0 (TID 208)
2016-06-13 14:04:56,259  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 112.0 (TID 207)
2016-06-13 14:04:56,262  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:56,267  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:56,270  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 112.0 (TID 208). 45217 bytes result sent to driver
2016-06-13 14:04:56,270  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 112.0 (TID 207). 45217 bytes result sent to driver
2016-06-13 14:04:56,271  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 112.0 (TID 207) in 12 ms on localhost (1/2)
2016-06-13 14:04:56,271  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 112.0 (TID 208) in 12 ms on localhost (2/2)
2016-06-13 14:04:56,271  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 112.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,272  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 112 (treeAggregate at RowMatrix.scala:93) finished in 0.010 s
2016-06-13 14:04:56,272  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 102 finished: treeAggregate at RowMatrix.scala:93, took 0.026472 s
2016-06-13 14:04:56,276  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_208 stored as values in memory (estimated size 124.9 KB, free 109.3 MB)
2016-06-13 14:04:56,278  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_208_piece0 stored as bytes in memory (estimated size 124.8 KB, free 109.4 MB)
2016-06-13 14:04:56,284  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_208_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:56,285  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 208 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:56,292  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:56,292  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 103 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:56,293  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 113 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,293  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:56,293  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:56,294  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 113 (MapPartitionsRDD[146] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:56,296  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_209 stored as values in memory (estimated size 55.2 KB, free 109.5 MB)
2016-06-13 14:04:56,297  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_209_piece0 stored as bytes in memory (estimated size 8.1 KB, free 109.5 MB)
2016-06-13 14:04:56,299  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_209_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:56,299  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 209 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:56,301  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 113 (MapPartitionsRDD[146] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,301  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 113.0 with 2 tasks
2016-06-13 14:04:56,302  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 113.0 (TID 209, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,302  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 113.0 (TID 210, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,302  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 113.0 (TID 209)
2016-06-13 14:04:56,304  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 113.0 (TID 210)
2016-06-13 14:04:56,306  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:56,307  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:56,309  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 113.0 (TID 210). 45217 bytes result sent to driver
2016-06-13 14:04:56,310  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 113.0 (TID 210) in 8 ms on localhost (1/2)
2016-06-13 14:04:56,311  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 113.0 (TID 209). 45217 bytes result sent to driver
2016-06-13 14:04:56,311  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 113.0 (TID 209) in 10 ms on localhost (2/2)
2016-06-13 14:04:56,312  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 113.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,312  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 113 (treeAggregate at RowMatrix.scala:93) finished in 0.011 s
2016-06-13 14:04:56,312  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 103 finished: treeAggregate at RowMatrix.scala:93, took 0.019732 s
2016-06-13 14:04:56,316  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_210 stored as values in memory (estimated size 124.9 KB, free 109.6 MB)
2016-06-13 14:04:56,318  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_210_piece0 stored as bytes in memory (estimated size 124.9 KB, free 109.7 MB)
2016-06-13 14:04:56,318  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_210_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:56,319  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 210 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:56,324  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:56,325  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 104 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:56,325  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 114 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,325  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:56,325  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:56,325  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 114 (MapPartitionsRDD[147] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:56,326  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_211 stored as values in memory (estimated size 55.2 KB, free 109.8 MB)
2016-06-13 14:04:56,327  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_211_piece0 stored as bytes in memory (estimated size 8.1 KB, free 109.8 MB)
2016-06-13 14:04:56,328  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_211_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:56,328  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 211 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:56,328  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 114 (MapPartitionsRDD[147] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,328  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 114.0 with 2 tasks
2016-06-13 14:04:56,328  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 114.0 (TID 211, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,329  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 114.0 (TID 212, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,329  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 114.0 (TID 211)
2016-06-13 14:04:56,329  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 114.0 (TID 212)
2016-06-13 14:04:56,330  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:56,331  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:56,332  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 114.0 (TID 211). 45217 bytes result sent to driver
2016-06-13 14:04:56,333  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 114.0 (TID 211) in 5 ms on localhost (1/2)
2016-06-13 14:04:56,333  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 114.0 (TID 212). 45217 bytes result sent to driver
2016-06-13 14:04:56,333  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 114.0 (TID 212) in 5 ms on localhost (2/2)
2016-06-13 14:04:56,334  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 114.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,334  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 114 (treeAggregate at RowMatrix.scala:93) finished in 0.006 s
2016-06-13 14:04:56,334  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 104 finished: treeAggregate at RowMatrix.scala:93, took 0.009759 s
2016-06-13 14:04:56,338  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_212 stored as values in memory (estimated size 124.9 KB, free 109.9 MB)
2016-06-13 14:04:56,339  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_212_piece0 stored as bytes in memory (estimated size 124.8 KB, free 110.0 MB)
2016-06-13 14:04:56,340  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_212_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:56,340  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 212 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:56,344  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:56,344  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 105 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:56,344  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 115 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,344  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:56,344  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:56,344  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 115 (MapPartitionsRDD[148] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:56,345  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_213 stored as values in memory (estimated size 55.2 KB, free 110.1 MB)
2016-06-13 14:04:56,346  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_213_piece0 stored as bytes in memory (estimated size 8.1 KB, free 110.1 MB)
2016-06-13 14:04:56,347  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_213_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:56,347  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 213 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:56,347  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 115 (MapPartitionsRDD[148] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,347  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 115.0 with 2 tasks
2016-06-13 14:04:56,351  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 115.0 (TID 213, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,351  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 115.0 (TID 214, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,352  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 115.0 (TID 214)
2016-06-13 14:04:56,352  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 115.0 (TID 213)
2016-06-13 14:04:56,354  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:56,354  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:56,357  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 115.0 (TID 213). 45217 bytes result sent to driver
2016-06-13 14:04:56,357  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 115.0 (TID 214). 45217 bytes result sent to driver
2016-06-13 14:04:56,358  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 115.0 (TID 213) in 10 ms on localhost (1/2)
2016-06-13 14:04:56,359  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 115.0 (TID 214) in 8 ms on localhost (2/2)
2016-06-13 14:04:56,359  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 115.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,359  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 115 (treeAggregate at RowMatrix.scala:93) finished in 0.012 s
2016-06-13 14:04:56,360  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 105 finished: treeAggregate at RowMatrix.scala:93, took 0.015935 s
2016-06-13 14:04:56,363  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_214 stored as values in memory (estimated size 124.9 KB, free 110.2 MB)
2016-06-13 14:04:56,365  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_214_piece0 stored as bytes in memory (estimated size 124.8 KB, free 110.3 MB)
2016-06-13 14:04:56,365  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_214_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:56,366  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 214 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:56,372  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:56,373  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 106 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:56,373  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 116 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,373  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:56,373  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:56,373  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 116 (MapPartitionsRDD[149] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:56,374  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_215 stored as values in memory (estimated size 55.2 KB, free 110.4 MB)
2016-06-13 14:04:56,375  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_215_piece0 stored as bytes in memory (estimated size 8.1 KB, free 110.4 MB)
2016-06-13 14:04:56,376  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_215_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:56,376  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 215 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:56,376  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 116 (MapPartitionsRDD[149] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,376  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 116.0 with 2 tasks
2016-06-13 14:04:56,376  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 116.0 (TID 215, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,377  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 116.0 (TID 216, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,377  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 116.0 (TID 215)
2016-06-13 14:04:56,378  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 116.0 (TID 216)
2016-06-13 14:04:56,379  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:56,380  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:56,381  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 116.0 (TID 215). 45217 bytes result sent to driver
2016-06-13 14:04:56,383  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 116.0 (TID 216). 45217 bytes result sent to driver
2016-06-13 14:04:56,383  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 116.0 (TID 215) in 7 ms on localhost (1/2)
2016-06-13 14:04:56,383  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 116.0 (TID 216) in 7 ms on localhost (2/2)
2016-06-13 14:04:56,383  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 116.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,384  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 116 (treeAggregate at RowMatrix.scala:93) finished in 0.008 s
2016-06-13 14:04:56,385  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 106 finished: treeAggregate at RowMatrix.scala:93, took 0.012112 s
2016-06-13 14:04:56,388  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_216 stored as values in memory (estimated size 124.9 KB, free 110.5 MB)
2016-06-13 14:04:56,390  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_216_piece0 stored as bytes in memory (estimated size 124.8 KB, free 110.6 MB)
2016-06-13 14:04:56,390  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_216_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:56,391  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 216 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:56,402  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:56,402  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 107 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:56,402  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 117 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,403  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:56,403  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:56,403  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 117 (MapPartitionsRDD[150] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:56,406  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_217 stored as values in memory (estimated size 55.2 KB, free 110.7 MB)
2016-06-13 14:04:56,407  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_217_piece0 stored as bytes in memory (estimated size 8.1 KB, free 110.7 MB)
2016-06-13 14:04:56,408  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_217_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:56,408  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 217 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:56,409  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 117 (MapPartitionsRDD[150] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,409  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 117.0 with 2 tasks
2016-06-13 14:04:56,410  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 117.0 (TID 217, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,410  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 117.0 (TID 218, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,410  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 117.0 (TID 218)
2016-06-13 14:04:56,410  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 117.0 (TID 217)
2016-06-13 14:04:56,412  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:56,414  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:56,417  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 117.0 (TID 217). 45217 bytes result sent to driver
2016-06-13 14:04:56,418  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 117.0 (TID 217) in 9 ms on localhost (1/2)
2016-06-13 14:04:56,420  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 117.0 (TID 218). 45217 bytes result sent to driver
2016-06-13 14:04:56,421  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 117.0 (TID 218) in 11 ms on localhost (2/2)
2016-06-13 14:04:56,421  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 117.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,422  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 117 (treeAggregate at RowMatrix.scala:93) finished in 0.013 s
2016-06-13 14:04:56,423  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 107 finished: treeAggregate at RowMatrix.scala:93, took 0.021187 s
2016-06-13 14:04:56,427  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_218 stored as values in memory (estimated size 124.9 KB, free 110.8 MB)
2016-06-13 14:04:56,429  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_218_piece0 stored as bytes in memory (estimated size 124.8 KB, free 110.9 MB)
2016-06-13 14:04:56,430  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_218_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:56,431  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 218 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:56,438  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:56,439  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 108 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:56,439  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 118 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,439  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:56,440  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:56,441  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 118 (MapPartitionsRDD[151] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:56,442  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_219 stored as values in memory (estimated size 55.2 KB, free 111.0 MB)
2016-06-13 14:04:56,443  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_219_piece0 stored as bytes in memory (estimated size 8.1 KB, free 111.0 MB)
2016-06-13 14:04:56,445  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_219_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:56,446  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 219 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:56,447  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 118 (MapPartitionsRDD[151] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,447  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 118.0 with 2 tasks
2016-06-13 14:04:56,448  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 118.0 (TID 219, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,448  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 118.0 (TID 220, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,448  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 118.0 (TID 219)
2016-06-13 14:04:56,448  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 118.0 (TID 220)
2016-06-13 14:04:56,451  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:56,454  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 118.0 (TID 220). 45217 bytes result sent to driver
2016-06-13 14:04:56,455  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 118.0 (TID 220) in 6 ms on localhost (1/2)
2016-06-13 14:04:56,456  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:56,461  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 118.0 (TID 219). 45217 bytes result sent to driver
2016-06-13 14:04:56,463  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 118.0 (TID 219) in 15 ms on localhost (2/2)
2016-06-13 14:04:56,463  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 118.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,463  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 118 (treeAggregate at RowMatrix.scala:93) finished in 0.002 s
2016-06-13 14:04:56,463  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 108 finished: treeAggregate at RowMatrix.scala:93, took 0.024483 s
2016-06-13 14:04:56,471  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_220 stored as values in memory (estimated size 124.9 KB, free 111.1 MB)
2016-06-13 14:04:56,475  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_220_piece0 stored as bytes in memory (estimated size 124.8 KB, free 111.2 MB)
2016-06-13 14:04:56,476  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_220_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:56,476  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 220 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:56,489  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:56,493  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 109 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:56,493  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 119 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,493  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:56,495  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:56,496  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 119 (MapPartitionsRDD[152] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:56,497  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_221 stored as values in memory (estimated size 55.2 KB, free 111.3 MB)
2016-06-13 14:04:56,498  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_221_piece0 stored as bytes in memory (estimated size 8.1 KB, free 111.3 MB)
2016-06-13 14:04:56,500  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_221_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:56,500  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 221 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:56,500  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 119 (MapPartitionsRDD[152] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,500  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 119.0 with 2 tasks
2016-06-13 14:04:56,501  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 119.0 (TID 221, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,501  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 119.0 (TID 222, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,501  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 119.0 (TID 221)
2016-06-13 14:04:56,502  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 119.0 (TID 222)
2016-06-13 14:04:56,504  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:56,508  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:56,511  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 119.0 (TID 221). 45217 bytes result sent to driver
2016-06-13 14:04:56,513  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 119.0 (TID 222). 45217 bytes result sent to driver
2016-06-13 14:04:56,515  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 119.0 (TID 221) in 13 ms on localhost (1/2)
2016-06-13 14:04:56,515  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 119.0 (TID 222) in 14 ms on localhost (2/2)
2016-06-13 14:04:56,515  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 119.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,515  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 119 (treeAggregate at RowMatrix.scala:93) finished in 0.002 s
2016-06-13 14:04:56,516  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 109 finished: treeAggregate at RowMatrix.scala:93, took 0.022947 s
2016-06-13 14:04:56,520  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_222 stored as values in memory (estimated size 124.9 KB, free 111.4 MB)
2016-06-13 14:04:56,532  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_222_piece0 stored as bytes in memory (estimated size 124.9 KB, free 111.5 MB)
2016-06-13 14:04:56,532  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_222_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:56,533  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 222 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:56,540  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:56,542  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 110 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:56,542  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 120 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,542  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:56,542  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:56,543  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 120 (MapPartitionsRDD[153] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:56,544  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_223 stored as values in memory (estimated size 55.2 KB, free 111.6 MB)
2016-06-13 14:04:56,545  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_223_piece0 stored as bytes in memory (estimated size 8.1 KB, free 111.6 MB)
2016-06-13 14:04:56,546  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_223_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:56,546  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 223 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:56,546  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 120 (MapPartitionsRDD[153] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,547  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 120.0 with 2 tasks
2016-06-13 14:04:56,547  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 120.0 (TID 223, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,547  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 120.0 (TID 224, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,548  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 120.0 (TID 223)
2016-06-13 14:04:56,548  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 120.0 (TID 224)
2016-06-13 14:04:56,550  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:56,554  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:56,556  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 120.0 (TID 223). 45217 bytes result sent to driver
2016-06-13 14:04:56,558  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 120.0 (TID 224). 45217 bytes result sent to driver
2016-06-13 14:04:56,559  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 120.0 (TID 223) in 12 ms on localhost (1/2)
2016-06-13 14:04:56,560  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 120.0 (TID 224) in 13 ms on localhost (2/2)
2016-06-13 14:04:56,560  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 120.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,561  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 120 (treeAggregate at RowMatrix.scala:93) finished in 0.002 s
2016-06-13 14:04:56,561  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 110 finished: treeAggregate at RowMatrix.scala:93, took 0.019517 s
2016-06-13 14:04:56,579  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_224 stored as values in memory (estimated size 124.9 KB, free 111.7 MB)
2016-06-13 14:04:56,580  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_224_piece0 stored as bytes in memory (estimated size 124.8 KB, free 111.8 MB)
2016-06-13 14:04:56,581  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_224_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:56,582  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 224 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:56,588  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:56,588  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 111 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:56,588  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 121 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,588  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:56,589  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:56,589  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 121 (MapPartitionsRDD[154] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:56,590  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_225 stored as values in memory (estimated size 55.2 KB, free 111.9 MB)
2016-06-13 14:04:56,592  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_225_piece0 stored as bytes in memory (estimated size 8.1 KB, free 111.9 MB)
2016-06-13 14:04:56,594  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_225_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:56,599  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 225 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:56,599  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 121 (MapPartitionsRDD[154] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,599  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 121.0 with 2 tasks
2016-06-13 14:04:56,600  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 121.0 (TID 225, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,600  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 121.0 (TID 226, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,600  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 121.0 (TID 225)
2016-06-13 14:04:56,600  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 121.0 (TID 226)
2016-06-13 14:04:56,603  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:56,605  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 121.0 (TID 226). 45217 bytes result sent to driver
2016-06-13 14:04:56,606  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 121.0 (TID 226) in 6 ms on localhost (1/2)
2016-06-13 14:04:56,609  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:56,611  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 121.0 (TID 225). 45217 bytes result sent to driver
2016-06-13 14:04:56,612  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 121.0 (TID 225) in 12 ms on localhost (2/2)
2016-06-13 14:04:56,612  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 121.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,613  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 121 (treeAggregate at RowMatrix.scala:93) finished in 0.002 s
2016-06-13 14:04:56,613  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 111 finished: treeAggregate at RowMatrix.scala:93, took 0.025211 s
2016-06-13 14:04:56,617  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_226 stored as values in memory (estimated size 124.9 KB, free 112.0 MB)
2016-06-13 14:04:56,621  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_226_piece0 stored as bytes in memory (estimated size 124.7 KB, free 112.2 MB)
2016-06-13 14:04:56,621  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_226_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:56,622  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 226 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:56,630  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:56,630  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 112 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:56,630  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 122 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,630  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:56,631  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:56,631  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 122 (MapPartitionsRDD[155] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:56,633  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_227 stored as values in memory (estimated size 55.2 KB, free 112.2 MB)
2016-06-13 14:04:56,634  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_227_piece0 stored as bytes in memory (estimated size 8.1 KB, free 112.2 MB)
2016-06-13 14:04:56,635  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_227_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:56,635  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 227 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:56,635  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 122 (MapPartitionsRDD[155] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,635  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 122.0 with 2 tasks
2016-06-13 14:04:56,636  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 122.0 (TID 227, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,636  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 122.0 (TID 228, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,636  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 122.0 (TID 227)
2016-06-13 14:04:56,636  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 122.0 (TID 228)
2016-06-13 14:04:56,639  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:56,642  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 122.0 (TID 228). 45217 bytes result sent to driver
2016-06-13 14:04:56,642  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 122.0 (TID 228) in 6 ms on localhost (1/2)
2016-06-13 14:04:56,645  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:56,648  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 122.0 (TID 227). 45217 bytes result sent to driver
2016-06-13 14:04:56,649  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 122.0 (TID 227) in 13 ms on localhost (2/2)
2016-06-13 14:04:56,649  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 122.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,649  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 122 (treeAggregate at RowMatrix.scala:93) finished in 0.001 s
2016-06-13 14:04:56,650  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 112 finished: treeAggregate at RowMatrix.scala:93, took 0.019598 s
2016-06-13 14:04:56,656  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_228 stored as values in memory (estimated size 124.9 KB, free 112.3 MB)
2016-06-13 14:04:56,658  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_228_piece0 stored as bytes in memory (estimated size 124.8 KB, free 112.5 MB)
2016-06-13 14:04:56,658  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_228_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:56,659  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 228 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:56,667  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:56,668  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 113 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:56,668  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 123 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,668  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:56,669  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:56,669  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 123 (MapPartitionsRDD[156] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:56,674  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_229 stored as values in memory (estimated size 55.2 KB, free 112.5 MB)
2016-06-13 14:04:56,675  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_229_piece0 stored as bytes in memory (estimated size 8.1 KB, free 112.5 MB)
2016-06-13 14:04:56,675  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_229_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:56,676  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 229 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:56,676  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 123 (MapPartitionsRDD[156] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,676  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 123.0 with 2 tasks
2016-06-13 14:04:56,679  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 123.0 (TID 229, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,679  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 123.0 (TID 230, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,680  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 123.0 (TID 229)
2016-06-13 14:04:56,682  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:56,684  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 123.0 (TID 229). 45217 bytes result sent to driver
2016-06-13 14:04:56,684  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 123.0 (TID 230)
2016-06-13 14:04:56,685  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:56,687  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 123.0 (TID 230). 45217 bytes result sent to driver
2016-06-13 14:04:56,688  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 123.0 (TID 230) in 9 ms on localhost (1/2)
2016-06-13 14:04:56,688  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 123.0 (TID 229) in 9 ms on localhost (2/2)
2016-06-13 14:04:56,688  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 123.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,689  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 123 (treeAggregate at RowMatrix.scala:93) finished in 0.010 s
2016-06-13 14:04:56,690  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 113 finished: treeAggregate at RowMatrix.scala:93, took 0.022764 s
2016-06-13 14:04:56,697  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_230 stored as values in memory (estimated size 124.9 KB, free 112.6 MB)
2016-06-13 14:04:56,700  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_230_piece0 stored as bytes in memory (estimated size 124.8 KB, free 112.8 MB)
2016-06-13 14:04:56,700  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_230_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:56,702  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 230 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:56,709  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:56,709  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 114 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:56,709  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 124 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,709  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:56,710  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:56,711  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 124 (MapPartitionsRDD[157] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:56,712  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_231 stored as values in memory (estimated size 55.2 KB, free 112.8 MB)
2016-06-13 14:04:56,713  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_231_piece0 stored as bytes in memory (estimated size 8.1 KB, free 112.8 MB)
2016-06-13 14:04:56,714  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_231_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:56,715  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 231 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:56,718  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 124 (MapPartitionsRDD[157] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,718  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 124.0 with 2 tasks
2016-06-13 14:04:56,719  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 124.0 (TID 231, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,719  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 124.0 (TID 232, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,719  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 124.0 (TID 231)
2016-06-13 14:04:56,719  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 124.0 (TID 232)
2016-06-13 14:04:56,722  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:56,722  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:56,725  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 124.0 (TID 232). 45217 bytes result sent to driver
2016-06-13 14:04:56,725  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 124.0 (TID 231). 45217 bytes result sent to driver
2016-06-13 14:04:56,726  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 124.0 (TID 232) in 7 ms on localhost (1/2)
2016-06-13 14:04:56,727  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 124.0 (TID 231) in 8 ms on localhost (2/2)
2016-06-13 14:04:56,727  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 124.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,727  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 124 (treeAggregate at RowMatrix.scala:93) finished in 0.007 s
2016-06-13 14:04:56,728  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 114 finished: treeAggregate at RowMatrix.scala:93, took 0.018641 s
2016-06-13 14:04:56,731  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_232 stored as values in memory (estimated size 124.9 KB, free 113.0 MB)
2016-06-13 14:04:56,732  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_232_piece0 stored as bytes in memory (estimated size 124.8 KB, free 113.1 MB)
2016-06-13 14:04:56,733  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_232_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:56,733  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 232 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:56,739  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:56,740  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 115 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:56,740  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 125 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,740  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:56,740  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:56,740  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 125 (MapPartitionsRDD[158] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:56,742  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_233 stored as values in memory (estimated size 55.2 KB, free 113.1 MB)
2016-06-13 14:04:56,743  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_233_piece0 stored as bytes in memory (estimated size 8.1 KB, free 113.1 MB)
2016-06-13 14:04:56,743  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_233_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:56,743  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 233 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:56,743  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 125 (MapPartitionsRDD[158] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,743  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 125.0 with 2 tasks
2016-06-13 14:04:56,744  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 125.0 (TID 233, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,744  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 125.0 (TID 234, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,744  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 125.0 (TID 233)
2016-06-13 14:04:56,746  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:56,746  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 125.0 (TID 234)
2016-06-13 14:04:56,748  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:56,748  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 125.0 (TID 233). 45217 bytes result sent to driver
2016-06-13 14:04:56,750  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 125.0 (TID 234). 45217 bytes result sent to driver
2016-06-13 14:04:56,751  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 125.0 (TID 234) in 7 ms on localhost (1/2)
2016-06-13 14:04:56,751  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 125.0 (TID 233) in 7 ms on localhost (2/2)
2016-06-13 14:04:56,751  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 125.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,751  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 125 (treeAggregate at RowMatrix.scala:93) finished in 0.008 s
2016-06-13 14:04:56,752  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 115 finished: treeAggregate at RowMatrix.scala:93, took 0.012168 s
2016-06-13 14:04:56,756  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_234 stored as values in memory (estimated size 124.9 KB, free 113.3 MB)
2016-06-13 14:04:56,757  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_234_piece0 stored as bytes in memory (estimated size 124.8 KB, free 113.4 MB)
2016-06-13 14:04:56,757  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_234_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:56,758  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 234 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:56,761  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:56,762  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 116 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:56,762  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 126 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,762  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:56,762  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:56,762  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 126 (MapPartitionsRDD[159] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:56,763  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_235 stored as values in memory (estimated size 55.2 KB, free 113.4 MB)
2016-06-13 14:04:56,764  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_235_piece0 stored as bytes in memory (estimated size 8.1 KB, free 113.4 MB)
2016-06-13 14:04:56,764  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_235_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:56,765  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 235 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:56,765  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 126 (MapPartitionsRDD[159] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,765  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 126.0 with 2 tasks
2016-06-13 14:04:56,765  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 126.0 (TID 235, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,765  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 126.0 (TID 236, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,765  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 126.0 (TID 236)
2016-06-13 14:04:56,765  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 126.0 (TID 235)
2016-06-13 14:04:56,768  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:56,768  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:56,769  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 126.0 (TID 235). 45217 bytes result sent to driver
2016-06-13 14:04:56,770  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 126.0 (TID 235) in 5 ms on localhost (1/2)
2016-06-13 14:04:56,771  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 126.0 (TID 236). 45217 bytes result sent to driver
2016-06-13 14:04:56,771  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 126.0 (TID 236) in 6 ms on localhost (2/2)
2016-06-13 14:04:56,771  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 126.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,771  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 126 (treeAggregate at RowMatrix.scala:93) finished in 0.006 s
2016-06-13 14:04:56,772  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 116 finished: treeAggregate at RowMatrix.scala:93, took 0.010329 s
2016-06-13 14:04:56,776  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_236 stored as values in memory (estimated size 124.9 KB, free 113.6 MB)
2016-06-13 14:04:56,777  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_236_piece0 stored as bytes in memory (estimated size 124.8 KB, free 113.7 MB)
2016-06-13 14:04:56,777  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_236_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:56,777  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 236 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:56,781  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:56,781  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 117 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:56,781  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 127 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,781  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:56,782  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:56,782  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 127 (MapPartitionsRDD[160] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:56,783  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_237 stored as values in memory (estimated size 55.2 KB, free 113.7 MB)
2016-06-13 14:04:56,785  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_237_piece0 stored as bytes in memory (estimated size 8.1 KB, free 113.7 MB)
2016-06-13 14:04:56,785  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_237_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:56,786  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 237 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:56,786  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 127 (MapPartitionsRDD[160] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,786  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 127.0 with 2 tasks
2016-06-13 14:04:56,787  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 127.0 (TID 237, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,787  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 127.0 (TID 238, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,787  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 127.0 (TID 237)
2016-06-13 14:04:56,787  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 127.0 (TID 238)
2016-06-13 14:04:56,789  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:56,790  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:56,791  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 127.0 (TID 237). 45217 bytes result sent to driver
2016-06-13 14:04:56,792  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 127.0 (TID 238). 45217 bytes result sent to driver
2016-06-13 14:04:56,793  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 127.0 (TID 237) in 6 ms on localhost (1/2)
2016-06-13 14:04:56,793  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 127.0 (TID 238) in 6 ms on localhost (2/2)
2016-06-13 14:04:56,793  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 127.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,794  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 127 (treeAggregate at RowMatrix.scala:93) finished in 0.006 s
2016-06-13 14:04:56,794  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 117 finished: treeAggregate at RowMatrix.scala:93, took 0.013020 s
2016-06-13 14:04:56,798  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_238 stored as values in memory (estimated size 124.9 KB, free 113.9 MB)
2016-06-13 14:04:56,800  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_238_piece0 stored as bytes in memory (estimated size 124.8 KB, free 114.0 MB)
2016-06-13 14:04:56,800  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_238_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:56,800  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 238 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:56,804  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:56,804  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 118 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:56,804  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 128 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,804  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:56,804  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:56,805  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 128 (MapPartitionsRDD[161] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:56,805  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_239 stored as values in memory (estimated size 55.2 KB, free 114.0 MB)
2016-06-13 14:04:56,807  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_239_piece0 stored as bytes in memory (estimated size 8.1 KB, free 114.1 MB)
2016-06-13 14:04:56,807  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_239_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:56,807  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 239 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:56,807  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 128 (MapPartitionsRDD[161] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,807  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 128.0 with 2 tasks
2016-06-13 14:04:56,807  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 128.0 (TID 239, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,808  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 128.0 (TID 240, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,808  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 128.0 (TID 240)
2016-06-13 14:04:56,808  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 128.0 (TID 239)
2016-06-13 14:04:56,810  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:56,810  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:56,812  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 128.0 (TID 240). 45217 bytes result sent to driver
2016-06-13 14:04:56,812  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 128.0 (TID 239). 45217 bytes result sent to driver
2016-06-13 14:04:56,813  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 128.0 (TID 240) in 5 ms on localhost (1/2)
2016-06-13 14:04:56,813  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 128.0 (TID 239) in 6 ms on localhost (2/2)
2016-06-13 14:04:56,813  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 128.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,813  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 128 (treeAggregate at RowMatrix.scala:93) finished in 0.006 s
2016-06-13 14:04:56,813  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 118 finished: treeAggregate at RowMatrix.scala:93, took 0.009227 s
2016-06-13 14:04:56,816  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_240 stored as values in memory (estimated size 124.9 KB, free 114.2 MB)
2016-06-13 14:04:56,817  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_240_piece0 stored as bytes in memory (estimated size 124.8 KB, free 114.3 MB)
2016-06-13 14:04:56,817  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_240_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:56,818  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 240 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:56,822  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:56,822  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 119 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:56,822  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 129 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,822  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:56,825  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:56,825  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 129 (MapPartitionsRDD[162] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:56,827  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_241 stored as values in memory (estimated size 55.2 KB, free 114.3 MB)
2016-06-13 14:04:56,828  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_241_piece0 stored as bytes in memory (estimated size 8.1 KB, free 114.4 MB)
2016-06-13 14:04:56,828  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_241_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:56,828  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 241 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:56,829  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 129 (MapPartitionsRDD[162] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,829  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 129.0 with 2 tasks
2016-06-13 14:04:56,829  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 129.0 (TID 241, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,829  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 129.0 (TID 242, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,830  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 129.0 (TID 241)
2016-06-13 14:04:56,831  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 129.0 (TID 242)
2016-06-13 14:04:56,832  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:56,833  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:56,835  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 129.0 (TID 241). 45217 bytes result sent to driver
2016-06-13 14:04:56,836  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 129.0 (TID 242). 45217 bytes result sent to driver
2016-06-13 14:04:56,839  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 129.0 (TID 241) in 10 ms on localhost (1/2)
2016-06-13 14:04:56,839  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 129.0 (TID 242) in 10 ms on localhost (2/2)
2016-06-13 14:04:56,839  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 129 (treeAggregate at RowMatrix.scala:93) finished in 0.010 s
2016-06-13 14:04:56,839  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 129.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,840  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 119 finished: treeAggregate at RowMatrix.scala:93, took 0.017816 s
2016-06-13 14:04:56,844  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_242 stored as values in memory (estimated size 124.9 KB, free 114.5 MB)
2016-06-13 14:04:56,845  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_242_piece0 stored as bytes in memory (estimated size 124.9 KB, free 114.6 MB)
2016-06-13 14:04:56,846  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_242_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:56,847  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 242 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:56,853  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:56,853  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 120 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:56,853  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 130 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,853  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:56,853  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:56,853  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 130 (MapPartitionsRDD[163] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:56,854  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_243 stored as values in memory (estimated size 55.2 KB, free 114.7 MB)
2016-06-13 14:04:56,855  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_243_piece0 stored as bytes in memory (estimated size 8.1 KB, free 114.7 MB)
2016-06-13 14:04:56,856  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_243_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:56,856  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 243 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:56,856  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 130 (MapPartitionsRDD[163] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,856  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 130.0 with 2 tasks
2016-06-13 14:04:56,857  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 130.0 (TID 243, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,857  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 130.0 (TID 244, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,857  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 130.0 (TID 243)
2016-06-13 14:04:56,858  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 130.0 (TID 244)
2016-06-13 14:04:56,860  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:56,863  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:56,865  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 130.0 (TID 243). 45217 bytes result sent to driver
2016-06-13 14:04:56,865  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 130.0 (TID 244). 45217 bytes result sent to driver
2016-06-13 14:04:56,866  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 130.0 (TID 243) in 10 ms on localhost (1/2)
2016-06-13 14:04:56,866  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 130.0 (TID 244) in 9 ms on localhost (2/2)
2016-06-13 14:04:56,866  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 130.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,866  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 130 (treeAggregate at RowMatrix.scala:93) finished in 0.010 s
2016-06-13 14:04:56,867  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 120 finished: treeAggregate at RowMatrix.scala:93, took 0.013814 s
2016-06-13 14:04:56,870  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_244 stored as values in memory (estimated size 124.9 KB, free 114.8 MB)
2016-06-13 14:04:56,872  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_244_piece0 stored as bytes in memory (estimated size 124.7 KB, free 114.9 MB)
2016-06-13 14:04:56,872  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_244_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:56,872  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 244 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:56,877  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:56,878  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 121 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:56,878  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 131 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,878  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:56,878  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:56,878  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 131 (MapPartitionsRDD[164] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:56,879  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_245 stored as values in memory (estimated size 55.2 KB, free 115.0 MB)
2016-06-13 14:04:56,880  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_245_piece0 stored as bytes in memory (estimated size 8.1 KB, free 115.0 MB)
2016-06-13 14:04:56,881  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_245_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:56,881  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 245 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:56,881  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 131 (MapPartitionsRDD[164] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,881  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 131.0 with 2 tasks
2016-06-13 14:04:56,881  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 131.0 (TID 245, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,882  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 131.0 (TID 246, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,882  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 131.0 (TID 245)
2016-06-13 14:04:56,882  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 131.0 (TID 246)
2016-06-13 14:04:56,884  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:56,884  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:56,886  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 131.0 (TID 245). 45217 bytes result sent to driver
2016-06-13 14:04:56,887  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 131.0 (TID 245) in 6 ms on localhost (1/2)
2016-06-13 14:04:56,888  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 131.0 (TID 246). 45217 bytes result sent to driver
2016-06-13 14:04:56,889  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 131.0 (TID 246) in 6 ms on localhost (2/2)
2016-06-13 14:04:56,889  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 131.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,889  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 131 (treeAggregate at RowMatrix.scala:93) finished in 0.008 s
2016-06-13 14:04:56,889  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 121 finished: treeAggregate at RowMatrix.scala:93, took 0.011578 s
2016-06-13 14:04:56,892  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_246 stored as values in memory (estimated size 124.9 KB, free 115.1 MB)
2016-06-13 14:04:56,893  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_246_piece0 stored as bytes in memory (estimated size 124.8 KB, free 115.2 MB)
2016-06-13 14:04:56,894  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_246_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:56,894  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 246 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:56,902  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:56,902  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 122 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:56,903  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 132 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,903  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:56,903  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:56,904  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 132 (MapPartitionsRDD[165] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:56,915  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_247 stored as values in memory (estimated size 55.2 KB, free 115.3 MB)
2016-06-13 14:04:56,918  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_247_piece0 stored as bytes in memory (estimated size 8.1 KB, free 115.3 MB)
2016-06-13 14:04:56,918  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_247_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:56,920  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 247 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:56,920  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 132 (MapPartitionsRDD[165] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,921  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 132.0 with 2 tasks
2016-06-13 14:04:56,922  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 132.0 (TID 247, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,922  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 132.0 (TID 248, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,922  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 132.0 (TID 247)
2016-06-13 14:04:56,923  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 132.0 (TID 248)
2016-06-13 14:04:56,926  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:56,930  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:56,936  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 132.0 (TID 248). 45217 bytes result sent to driver
2016-06-13 14:04:56,936  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 132.0 (TID 247). 45217 bytes result sent to driver
2016-06-13 14:04:56,937  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 132.0 (TID 248) in 15 ms on localhost (1/2)
2016-06-13 14:04:56,937  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 132.0 (TID 247) in 15 ms on localhost (2/2)
2016-06-13 14:04:56,937  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 132.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,939  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 132 (treeAggregate at RowMatrix.scala:93) finished in 0.000 s
2016-06-13 14:04:56,939  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 122 finished: treeAggregate at RowMatrix.scala:93, took 0.037578 s
2016-06-13 14:04:56,944  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_248 stored as values in memory (estimated size 124.9 KB, free 115.4 MB)
2016-06-13 14:04:56,946  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_248_piece0 stored as bytes in memory (estimated size 124.7 KB, free 115.5 MB)
2016-06-13 14:04:56,947  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_248_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:56,947  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 248 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:56,955  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:56,955  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 123 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:56,955  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 133 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,955  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:56,956  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:56,956  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 133 (MapPartitionsRDD[166] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:56,957  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_249 stored as values in memory (estimated size 55.2 KB, free 115.6 MB)
2016-06-13 14:04:56,959  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_249_piece0 stored as bytes in memory (estimated size 8.1 KB, free 115.6 MB)
2016-06-13 14:04:56,959  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_249_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:56,959  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 249 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:56,959  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 133 (MapPartitionsRDD[166] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,960  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 133.0 with 2 tasks
2016-06-13 14:04:56,960  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 133.0 (TID 249, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,960  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 133.0 (TID 250, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,960  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 133.0 (TID 249)
2016-06-13 14:04:56,962  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 133.0 (TID 250)
2016-06-13 14:04:56,962  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:56,964  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:56,965  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 133.0 (TID 249). 45217 bytes result sent to driver
2016-06-13 14:04:56,967  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 133.0 (TID 250). 45217 bytes result sent to driver
2016-06-13 14:04:56,968  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 133.0 (TID 249) in 7 ms on localhost (1/2)
2016-06-13 14:04:56,969  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 133.0 (TID 250) in 9 ms on localhost (2/2)
2016-06-13 14:04:56,969  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 133.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,969  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 133 (treeAggregate at RowMatrix.scala:93) finished in 0.009 s
2016-06-13 14:04:56,970  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 123 finished: treeAggregate at RowMatrix.scala:93, took 0.015035 s
2016-06-13 14:04:56,974  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_250 stored as values in memory (estimated size 124.9 KB, free 115.7 MB)
2016-06-13 14:04:56,976  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_250_piece0 stored as bytes in memory (estimated size 124.8 KB, free 115.8 MB)
2016-06-13 14:04:56,976  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_250_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:56,977  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 250 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:56,987  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:56,987  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 124 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:56,987  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 134 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,987  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:56,987  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:56,988  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 134 (MapPartitionsRDD[167] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:56,989  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_251 stored as values in memory (estimated size 55.2 KB, free 115.9 MB)
2016-06-13 14:04:56,990  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_251_piece0 stored as bytes in memory (estimated size 8.1 KB, free 115.9 MB)
2016-06-13 14:04:56,990  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_251_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:56,990  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 251 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:56,990  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 134 (MapPartitionsRDD[167] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:56,990  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 134.0 with 2 tasks
2016-06-13 14:04:56,991  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 134.0 (TID 251, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,991  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 134.0 (TID 252, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:56,991  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 134.0 (TID 251)
2016-06-13 14:04:56,993  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:56,994  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 134.0 (TID 251). 45217 bytes result sent to driver
2016-06-13 14:04:56,991  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 134.0 (TID 252)
2016-06-13 14:04:56,995  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 134.0 (TID 251) in 4 ms on localhost (1/2)
2016-06-13 14:04:56,996  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:56,998  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 134.0 (TID 252). 45217 bytes result sent to driver
2016-06-13 14:04:56,999  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 134.0 (TID 252) in 8 ms on localhost (2/2)
2016-06-13 14:04:56,999  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 134.0, whose tasks have all completed, from pool 
2016-06-13 14:04:56,999  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 134 (treeAggregate at RowMatrix.scala:93) finished in 0.009 s
2016-06-13 14:04:56,999  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 124 finished: treeAggregate at RowMatrix.scala:93, took 0.012006 s
2016-06-13 14:04:57,002  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_252 stored as values in memory (estimated size 124.9 KB, free 116.0 MB)
2016-06-13 14:04:57,003  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_252_piece0 stored as bytes in memory (estimated size 124.7 KB, free 116.1 MB)
2016-06-13 14:04:57,003  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_252_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:57,004  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 252 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,007  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,008  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 125 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,008  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 135 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,008  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,008  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,008  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 135 (MapPartitionsRDD[168] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,009  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_253 stored as values in memory (estimated size 55.2 KB, free 116.2 MB)
2016-06-13 14:04:57,010  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_253_piece0 stored as bytes in memory (estimated size 8.1 KB, free 116.2 MB)
2016-06-13 14:04:57,010  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_253_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,014  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 253 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,014  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 135 (MapPartitionsRDD[168] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,014  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 135.0 with 2 tasks
2016-06-13 14:04:57,015  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 135.0 (TID 253, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,015  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 135.0 (TID 254, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,015  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 135.0 (TID 254)
2016-06-13 14:04:57,017  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:57,018  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 135.0 (TID 253)
2016-06-13 14:04:57,018  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 135.0 (TID 254). 45217 bytes result sent to driver
2016-06-13 14:04:57,020  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 135.0 (TID 254) in 5 ms on localhost (1/2)
2016-06-13 14:04:57,020  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,022  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 135.0 (TID 253). 45217 bytes result sent to driver
2016-06-13 14:04:57,023  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 135.0 (TID 253) in 7 ms on localhost (2/2)
2016-06-13 14:04:57,023  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 135.0, whose tasks have all completed, from pool 
2016-06-13 14:04:57,023  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 135 (treeAggregate at RowMatrix.scala:93) finished in 0.009 s
2016-06-13 14:04:57,023  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 125 finished: treeAggregate at RowMatrix.scala:93, took 0.015185 s
2016-06-13 14:04:57,027  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_254 stored as values in memory (estimated size 124.9 KB, free 116.3 MB)
2016-06-13 14:04:57,029  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_254_piece0 stored as bytes in memory (estimated size 124.8 KB, free 116.4 MB)
2016-06-13 14:04:57,029  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_254_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:57,029  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 254 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,033  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,034  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 126 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,034  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 136 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,034  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,034  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,034  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 136 (MapPartitionsRDD[169] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,035  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_255 stored as values in memory (estimated size 55.2 KB, free 116.5 MB)
2016-06-13 14:04:57,036  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_255_piece0 stored as bytes in memory (estimated size 8.1 KB, free 116.5 MB)
2016-06-13 14:04:57,036  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_255_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,037  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 255 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,037  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 136 (MapPartitionsRDD[169] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,037  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 136.0 with 2 tasks
2016-06-13 14:04:57,037  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 136.0 (TID 255, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,037  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 136.0 (TID 256, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,038  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 136.0 (TID 255)
2016-06-13 14:04:57,038  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 136.0 (TID 256)
2016-06-13 14:04:57,040  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:57,040  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,042  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 136.0 (TID 256). 45217 bytes result sent to driver
2016-06-13 14:04:57,043  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 136.0 (TID 255). 45217 bytes result sent to driver
2016-06-13 14:04:57,043  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 136.0 (TID 256) in 6 ms on localhost (1/2)
2016-06-13 14:04:57,043  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 136.0 (TID 255) in 6 ms on localhost (2/2)
2016-06-13 14:04:57,043  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 136.0, whose tasks have all completed, from pool 
2016-06-13 14:04:57,043  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 136 (treeAggregate at RowMatrix.scala:93) finished in 0.006 s
2016-06-13 14:04:57,044  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 126 finished: treeAggregate at RowMatrix.scala:93, took 0.010227 s
2016-06-13 14:04:57,047  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_256 stored as values in memory (estimated size 124.9 KB, free 116.6 MB)
2016-06-13 14:04:57,049  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_256_piece0 stored as bytes in memory (estimated size 124.8 KB, free 116.7 MB)
2016-06-13 14:04:57,049  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_256_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:57,049  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 256 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,057  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,058  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 127 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,058  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 137 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,058  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,059  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,059  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 137 (MapPartitionsRDD[170] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,060  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_257 stored as values in memory (estimated size 55.2 KB, free 116.8 MB)
2016-06-13 14:04:57,061  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_257_piece0 stored as bytes in memory (estimated size 8.1 KB, free 116.8 MB)
2016-06-13 14:04:57,061  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_257_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,061  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 257 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,061  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 137 (MapPartitionsRDD[170] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,062  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 137.0 with 2 tasks
2016-06-13 14:04:57,062  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 137.0 (TID 257, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,062  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 137.0 (TID 258, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,063  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 137.0 (TID 257)
2016-06-13 14:04:57,063  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 137.0 (TID 258)
2016-06-13 14:04:57,065  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:57,068  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 137.0 (TID 258). 45217 bytes result sent to driver
2016-06-13 14:04:57,068  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,068  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 137.0 (TID 258) in 6 ms on localhost (1/2)
2016-06-13 14:04:57,070  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 137.0 (TID 257). 45217 bytes result sent to driver
2016-06-13 14:04:57,072  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 137.0 (TID 257) in 9 ms on localhost (2/2)
2016-06-13 14:04:57,072  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 137.0, whose tasks have all completed, from pool 
2016-06-13 14:04:57,072  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 137 (treeAggregate at RowMatrix.scala:93) finished in 0.009 s
2016-06-13 14:04:57,072  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 127 finished: treeAggregate at RowMatrix.scala:93, took 0.014444 s
2016-06-13 14:04:57,076  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_258 stored as values in memory (estimated size 124.9 KB, free 116.9 MB)
2016-06-13 14:04:57,078  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_258_piece0 stored as bytes in memory (estimated size 124.8 KB, free 117.0 MB)
2016-06-13 14:04:57,078  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_258_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:57,078  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 258 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,085  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,085  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 128 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,085  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 138 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,085  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,086  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,086  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 138 (MapPartitionsRDD[171] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,087  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_259 stored as values in memory (estimated size 55.2 KB, free 117.1 MB)
2016-06-13 14:04:57,088  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_259_piece0 stored as bytes in memory (estimated size 8.1 KB, free 117.1 MB)
2016-06-13 14:04:57,088  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_259_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,088  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 259 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,088  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 138 (MapPartitionsRDD[171] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,088  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 138.0 with 2 tasks
2016-06-13 14:04:57,089  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 138.0 (TID 259, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,089  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 138.0 (TID 260, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,089  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 138.0 (TID 259)
2016-06-13 14:04:57,089  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 138.0 (TID 260)
2016-06-13 14:04:57,091  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,091  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:57,096  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 138.0 (TID 259). 45217 bytes result sent to driver
2016-06-13 14:04:57,097  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 138.0 (TID 260). 45217 bytes result sent to driver
2016-06-13 14:04:57,099  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 138.0 (TID 260) in 9 ms on localhost (1/2)
2016-06-13 14:04:57,099  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 138.0 (TID 259) in 10 ms on localhost (2/2)
2016-06-13 14:04:57,099  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 138.0, whose tasks have all completed, from pool 
2016-06-13 14:04:57,099  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 138 (treeAggregate at RowMatrix.scala:93) finished in 0.010 s
2016-06-13 14:04:57,103  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 128 finished: treeAggregate at RowMatrix.scala:93, took 0.018201 s
2016-06-13 14:04:57,108  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_260 stored as values in memory (estimated size 124.9 KB, free 117.2 MB)
2016-06-13 14:04:57,109  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_260_piece0 stored as bytes in memory (estimated size 124.7 KB, free 117.4 MB)
2016-06-13 14:04:57,109  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_260_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:57,110  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 260 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,115  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,116  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 129 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,116  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 139 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,116  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,116  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,116  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 139 (MapPartitionsRDD[172] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,117  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_261 stored as values in memory (estimated size 55.2 KB, free 117.4 MB)
2016-06-13 14:04:57,118  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_261_piece0 stored as bytes in memory (estimated size 8.1 KB, free 117.4 MB)
2016-06-13 14:04:57,118  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_261_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,119  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 261 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,119  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 139 (MapPartitionsRDD[172] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,119  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 139.0 with 2 tasks
2016-06-13 14:04:57,119  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 139.0 (TID 261, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,119  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 139.0 (TID 262, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,120  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 139.0 (TID 262)
2016-06-13 14:04:57,120  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 139.0 (TID 261)
2016-06-13 14:04:57,122  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,122  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:57,125  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 139.0 (TID 262). 45217 bytes result sent to driver
2016-06-13 14:04:57,127  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 139.0 (TID 261). 45217 bytes result sent to driver
2016-06-13 14:04:57,128  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 139.0 (TID 262) in 8 ms on localhost (1/2)
2016-06-13 14:04:57,128  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 139.0 (TID 261) in 9 ms on localhost (2/2)
2016-06-13 14:04:57,128  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 139.0, whose tasks have all completed, from pool 
2016-06-13 14:04:57,128  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 139 (treeAggregate at RowMatrix.scala:93) finished in 0.008 s
2016-06-13 14:04:57,128  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 129 finished: treeAggregate at RowMatrix.scala:93, took 0.012561 s
2016-06-13 14:04:57,132  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_262 stored as values in memory (estimated size 124.9 KB, free 117.5 MB)
2016-06-13 14:04:57,133  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_262_piece0 stored as bytes in memory (estimated size 124.8 KB, free 117.7 MB)
2016-06-13 14:04:57,133  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_262_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:57,133  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 262 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,142  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,143  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 130 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,143  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 140 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,143  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,143  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,144  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 140 (MapPartitionsRDD[173] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,146  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_263 stored as values in memory (estimated size 55.2 KB, free 117.7 MB)
2016-06-13 14:04:57,147  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_263_piece0 stored as bytes in memory (estimated size 8.1 KB, free 117.7 MB)
2016-06-13 14:04:57,147  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_263_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,148  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 263 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,148  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 140 (MapPartitionsRDD[173] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,148  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 140.0 with 2 tasks
2016-06-13 14:04:57,149  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 140.0 (TID 263, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,149  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 140.0 (TID 264, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,150  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 140.0 (TID 263)
2016-06-13 14:04:57,150  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 140.0 (TID 264)
2016-06-13 14:04:57,154  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,156  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 140.0 (TID 263). 45217 bytes result sent to driver
2016-06-13 14:04:57,156  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 140.0 (TID 263) in 7 ms on localhost (1/2)
2016-06-13 14:04:57,154  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:57,158  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 140.0 (TID 264). 45217 bytes result sent to driver
2016-06-13 14:04:57,159  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 140.0 (TID 264) in 10 ms on localhost (2/2)
2016-06-13 14:04:57,159  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 140.0, whose tasks have all completed, from pool 
2016-06-13 14:04:57,159  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 140 (treeAggregate at RowMatrix.scala:93) finished in 0.001 s
2016-06-13 14:04:57,160  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 130 finished: treeAggregate at RowMatrix.scala:93, took 0.017760 s
2016-06-13 14:04:57,163  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_264 stored as values in memory (estimated size 124.9 KB, free 117.8 MB)
2016-06-13 14:04:57,164  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_264_piece0 stored as bytes in memory (estimated size 124.9 KB, free 118.0 MB)
2016-06-13 14:04:57,165  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_264_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:57,165  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 264 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,169  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,170  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 131 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,170  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 141 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,170  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,170  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,170  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 141 (MapPartitionsRDD[174] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,171  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_265 stored as values in memory (estimated size 55.2 KB, free 118.0 MB)
2016-06-13 14:04:57,172  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_265_piece0 stored as bytes in memory (estimated size 8.1 KB, free 118.0 MB)
2016-06-13 14:04:57,172  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_265_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,173  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 265 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,173  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 141 (MapPartitionsRDD[174] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,173  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 141.0 with 2 tasks
2016-06-13 14:04:57,173  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 141.0 (TID 265, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,174  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 141.0 (TID 266, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,174  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 141.0 (TID 265)
2016-06-13 14:04:57,174  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 141.0 (TID 266)
2016-06-13 14:04:57,176  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,181  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:57,185  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 141.0 (TID 266). 45217 bytes result sent to driver
2016-06-13 14:04:57,186  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 141.0 (TID 266) in 13 ms on localhost (1/2)
2016-06-13 14:04:57,187  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 141.0 (TID 265). 45217 bytes result sent to driver
2016-06-13 14:04:57,188  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 141.0 (TID 265) in 15 ms on localhost (2/2)
2016-06-13 14:04:57,189  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 141.0, whose tasks have all completed, from pool 
2016-06-13 14:04:57,189  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 141 (treeAggregate at RowMatrix.scala:93) finished in 0.016 s
2016-06-13 14:04:57,189  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 131 finished: treeAggregate at RowMatrix.scala:93, took 0.019221 s
2016-06-13 14:04:57,193  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_266 stored as values in memory (estimated size 124.9 KB, free 118.1 MB)
2016-06-13 14:04:57,194  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_266_piece0 stored as bytes in memory (estimated size 124.9 KB, free 118.3 MB)
2016-06-13 14:04:57,194  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_266_piece0 in memory on localhost:44356 (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:57,195  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 266 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,202  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,202  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 132 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,202  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 142 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,202  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,203  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,203  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 142 (MapPartitionsRDD[175] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,204  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_267 stored as values in memory (estimated size 55.2 KB, free 118.3 MB)
2016-06-13 14:04:57,206  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_267_piece0 stored as bytes in memory (estimated size 8.1 KB, free 118.3 MB)
2016-06-13 14:04:57,206  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_267_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,206  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 267 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,206  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 142 (MapPartitionsRDD[175] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,206  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 142.0 with 2 tasks
2016-06-13 14:04:57,207  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 142.0 (TID 267, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,207  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 142.0 (TID 268, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,207  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 142.0 (TID 267)
2016-06-13 14:04:57,210  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,210  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 142.0 (TID 268)
2016-06-13 14:04:57,212  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 142.0 (TID 267). 45217 bytes result sent to driver
2016-06-13 14:04:57,212  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:57,214  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 142.0 (TID 267) in 7 ms on localhost (1/2)
2016-06-13 14:04:57,215  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 142.0 (TID 268). 45217 bytes result sent to driver
2016-06-13 14:04:57,216  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 142.0 (TID 268) in 9 ms on localhost (2/2)
2016-06-13 14:04:57,216  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 142.0, whose tasks have all completed, from pool 
2016-06-13 14:04:57,217  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 142 (treeAggregate at RowMatrix.scala:93) finished in 0.010 s
2016-06-13 14:04:57,218  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 132 finished: treeAggregate at RowMatrix.scala:93, took 0.016138 s
2016-06-13 14:04:57,223  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_268 stored as values in memory (estimated size 124.9 KB, free 118.5 MB)
2016-06-13 14:04:57,225  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_268_piece0 stored as bytes in memory (estimated size 124.7 KB, free 118.6 MB)
2016-06-13 14:04:57,226  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_268_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:57,227  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 268 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,234  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,235  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 133 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,235  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 143 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,235  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,236  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,236  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 143 (MapPartitionsRDD[176] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,237  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_269 stored as values in memory (estimated size 55.2 KB, free 118.6 MB)
2016-06-13 14:04:57,238  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_269_piece0 stored as bytes in memory (estimated size 8.1 KB, free 118.6 MB)
2016-06-13 14:04:57,239  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_269_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,240  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 269 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,240  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 143 (MapPartitionsRDD[176] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,241  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 143.0 with 2 tasks
2016-06-13 14:04:57,241  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 143.0 (TID 269, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,242  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 143.0 (TID 270, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,242  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 143.0 (TID 269)
2016-06-13 14:04:57,242  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 143.0 (TID 270)
2016-06-13 14:04:57,244  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,245  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:57,246  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 143.0 (TID 269). 45217 bytes result sent to driver
2016-06-13 14:04:57,247  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 143.0 (TID 269) in 6 ms on localhost (1/2)
2016-06-13 14:04:57,248  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 143.0 (TID 270). 45217 bytes result sent to driver
2016-06-13 14:04:57,249  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 143.0 (TID 270) in 8 ms on localhost (2/2)
2016-06-13 14:04:57,249  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 143.0, whose tasks have all completed, from pool 
2016-06-13 14:04:57,252  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 143 (treeAggregate at RowMatrix.scala:93) finished in 0.011 s
2016-06-13 14:04:57,253  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 133 finished: treeAggregate at RowMatrix.scala:93, took 0.018507 s
2016-06-13 14:04:57,257  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_270 stored as values in memory (estimated size 124.9 KB, free 118.8 MB)
2016-06-13 14:04:57,258  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_270_piece0 stored as bytes in memory (estimated size 124.8 KB, free 118.9 MB)
2016-06-13 14:04:57,258  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_270_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:57,259  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 270 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,264  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,264  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 134 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,264  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 144 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,264  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,264  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,265  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 144 (MapPartitionsRDD[177] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,266  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_271 stored as values in memory (estimated size 55.2 KB, free 118.9 MB)
2016-06-13 14:04:57,268  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_271_piece0 stored as bytes in memory (estimated size 8.1 KB, free 118.9 MB)
2016-06-13 14:04:57,268  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_271_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,268  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 271 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,268  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 144 (MapPartitionsRDD[177] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,269  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 144.0 with 2 tasks
2016-06-13 14:04:57,269  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 144.0 (TID 271, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,270  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 144.0 (TID 272, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,270  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 144.0 (TID 271)
2016-06-13 14:04:57,271  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 144.0 (TID 272)
2016-06-13 14:04:57,272  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,274  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:57,276  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 144.0 (TID 272). 45217 bytes result sent to driver
2016-06-13 14:04:57,279  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 144.0 (TID 271). 45217 bytes result sent to driver
2016-06-13 14:04:57,279  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 144.0 (TID 272) in 10 ms on localhost (1/2)
2016-06-13 14:04:57,282  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 144.0 (TID 271) in 13 ms on localhost (2/2)
2016-06-13 14:04:57,282  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 144.0, whose tasks have all completed, from pool 
2016-06-13 14:04:57,283  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 144 (treeAggregate at RowMatrix.scala:93) finished in 0.014 s
2016-06-13 14:04:57,284  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 134 finished: treeAggregate at RowMatrix.scala:93, took 0.020367 s
2016-06-13 14:04:57,288  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_272 stored as values in memory (estimated size 124.9 KB, free 119.1 MB)
2016-06-13 14:04:57,289  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_272_piece0 stored as bytes in memory (estimated size 124.7 KB, free 119.2 MB)
2016-06-13 14:04:57,289  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_272_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:57,290  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 272 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,296  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,297  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 135 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,297  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 145 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,297  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,298  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,298  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 145 (MapPartitionsRDD[178] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,300  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_273 stored as values in memory (estimated size 55.2 KB, free 119.2 MB)
2016-06-13 14:04:57,301  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_273_piece0 stored as bytes in memory (estimated size 8.1 KB, free 119.2 MB)
2016-06-13 14:04:57,301  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_273_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,302  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 273 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,302  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 145 (MapPartitionsRDD[178] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,302  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 145.0 with 2 tasks
2016-06-13 14:04:57,303  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 145.0 (TID 273, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,303  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 145.0 (TID 274, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,303  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 145.0 (TID 274)
2016-06-13 14:04:57,304  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 145.0 (TID 273)
2016-06-13 14:04:57,305  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:57,306  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,308  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 145.0 (TID 273). 45217 bytes result sent to driver
2016-06-13 14:04:57,309  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 145.0 (TID 273) in 6 ms on localhost (1/2)
2016-06-13 14:04:57,311  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 145.0 (TID 274). 45217 bytes result sent to driver
2016-06-13 14:04:57,312  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 145.0 (TID 274) in 9 ms on localhost (2/2)
2016-06-13 14:04:57,312  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 145.0, whose tasks have all completed, from pool 
2016-06-13 14:04:57,312  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 145 (treeAggregate at RowMatrix.scala:93) finished in 0.009 s
2016-06-13 14:04:57,314  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 135 finished: treeAggregate at RowMatrix.scala:93, took 0.017332 s
2016-06-13 14:04:57,318  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_274 stored as values in memory (estimated size 124.9 KB, free 119.4 MB)
2016-06-13 14:04:57,320  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_274_piece0 stored as bytes in memory (estimated size 124.8 KB, free 119.5 MB)
2016-06-13 14:04:57,320  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_274_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:57,321  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 274 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,326  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,327  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 136 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,327  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 146 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,327  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,327  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,327  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 146 (MapPartitionsRDD[179] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,329  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_275 stored as values in memory (estimated size 55.2 KB, free 119.5 MB)
2016-06-13 14:04:57,330  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_275_piece0 stored as bytes in memory (estimated size 8.1 KB, free 119.6 MB)
2016-06-13 14:04:57,331  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_275_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,332  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 275 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,332  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 146 (MapPartitionsRDD[179] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,332  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 146.0 with 2 tasks
2016-06-13 14:04:57,333  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 146.0 (TID 275, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,333  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 146.0 (TID 276, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,333  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 146.0 (TID 275)
2016-06-13 14:04:57,333  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 146.0 (TID 276)
2016-06-13 14:04:57,337  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,340  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 146.0 (TID 275). 45217 bytes result sent to driver
2016-06-13 14:04:57,341  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 146.0 (TID 275) in 9 ms on localhost (1/2)
2016-06-13 14:04:57,349  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:57,351  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 146.0 (TID 276). 45217 bytes result sent to driver
2016-06-13 14:04:57,352  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 146.0 (TID 276) in 19 ms on localhost (2/2)
2016-06-13 14:04:57,352  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 146.0, whose tasks have all completed, from pool 
2016-06-13 14:04:57,353  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 146 (treeAggregate at RowMatrix.scala:93) finished in 0.019 s
2016-06-13 14:04:57,358  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 136 finished: treeAggregate at RowMatrix.scala:93, took 0.031742 s
2016-06-13 14:04:57,364  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_276 stored as values in memory (estimated size 124.9 KB, free 119.7 MB)
2016-06-13 14:04:57,370  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_276_piece0 stored as bytes in memory (estimated size 124.8 KB, free 119.8 MB)
2016-06-13 14:04:57,370  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_276_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:57,370  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 276 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,380  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,381  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 137 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,381  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 147 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,381  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,381  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,381  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 147 (MapPartitionsRDD[180] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,383  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_277 stored as values in memory (estimated size 55.2 KB, free 119.8 MB)
2016-06-13 14:04:57,384  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_277_piece0 stored as bytes in memory (estimated size 8.1 KB, free 119.9 MB)
2016-06-13 14:04:57,384  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_277_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,385  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 277 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,385  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 147 (MapPartitionsRDD[180] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,385  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 147.0 with 2 tasks
2016-06-13 14:04:57,386  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 147.0 (TID 277, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,386  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 147.0 (TID 278, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,386  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 147.0 (TID 277)
2016-06-13 14:04:57,387  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 147.0 (TID 278)
2016-06-13 14:04:57,389  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,389  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:57,391  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 147.0 (TID 277). 45217 bytes result sent to driver
2016-06-13 14:04:57,392  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 147.0 (TID 277) in 7 ms on localhost (1/2)
2016-06-13 14:04:57,392  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 147.0 (TID 278). 45217 bytes result sent to driver
2016-06-13 14:04:57,393  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 147.0 (TID 278) in 7 ms on localhost (2/2)
2016-06-13 14:04:57,393  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 147.0, whose tasks have all completed, from pool 
2016-06-13 14:04:57,393  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 147 (treeAggregate at RowMatrix.scala:93) finished in 0.008 s
2016-06-13 14:04:57,394  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 137 finished: treeAggregate at RowMatrix.scala:93, took 0.013585 s
2016-06-13 14:04:57,400  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_278 stored as values in memory (estimated size 124.9 KB, free 120.0 MB)
2016-06-13 14:04:57,402  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_278_piece0 stored as bytes in memory (estimated size 124.8 KB, free 120.1 MB)
2016-06-13 14:04:57,402  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_278_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:57,403  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 278 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,412  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,413  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 138 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,413  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 148 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,413  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,413  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,413  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 148 (MapPartitionsRDD[181] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,415  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_279 stored as values in memory (estimated size 55.2 KB, free 120.2 MB)
2016-06-13 14:04:57,416  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_279_piece0 stored as bytes in memory (estimated size 8.1 KB, free 120.2 MB)
2016-06-13 14:04:57,416  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_279_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,417  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 279 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,417  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 148 (MapPartitionsRDD[181] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,417  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 148.0 with 2 tasks
2016-06-13 14:04:57,417  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 148.0 (TID 279, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,417  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 148.0 (TID 280, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,418  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 148.0 (TID 279)
2016-06-13 14:04:57,418  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 148.0 (TID 280)
2016-06-13 14:04:57,420  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,423  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 148.0 (TID 279). 45217 bytes result sent to driver
2016-06-13 14:04:57,423  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 148.0 (TID 279) in 6 ms on localhost (1/2)
2016-06-13 14:04:57,425  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:57,427  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 148.0 (TID 280). 45217 bytes result sent to driver
2016-06-13 14:04:57,434  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 148.0 (TID 280) in 17 ms on localhost (2/2)
2016-06-13 14:04:57,434  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 148.0, whose tasks have all completed, from pool 
2016-06-13 14:04:57,435  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 148 (treeAggregate at RowMatrix.scala:93) finished in 0.018 s
2016-06-13 14:04:57,435  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 138 finished: treeAggregate at RowMatrix.scala:93, took 0.022502 s
2016-06-13 14:04:57,440  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_280 stored as values in memory (estimated size 124.9 KB, free 120.3 MB)
2016-06-13 14:04:57,441  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_280_piece0 stored as bytes in memory (estimated size 124.7 KB, free 120.4 MB)
2016-06-13 14:04:57,442  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_280_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:57,442  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 280 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,450  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,450  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 139 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,451  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 149 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,451  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,451  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,451  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 149 (MapPartitionsRDD[182] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,452  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_281 stored as values in memory (estimated size 55.2 KB, free 120.5 MB)
2016-06-13 14:04:57,454  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_281_piece0 stored as bytes in memory (estimated size 8.1 KB, free 120.5 MB)
2016-06-13 14:04:57,454  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_281_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,454  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 281 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,455  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 149 (MapPartitionsRDD[182] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,455  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 149.0 with 2 tasks
2016-06-13 14:04:57,455  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 149.0 (TID 281, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,455  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 149.0 (TID 282, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,456  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 149.0 (TID 281)
2016-06-13 14:04:57,458  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 149.0 (TID 282)
2016-06-13 14:04:57,459  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,460  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:57,461  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 149.0 (TID 281). 45217 bytes result sent to driver
2016-06-13 14:04:57,462  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 149.0 (TID 281) in 7 ms on localhost (1/2)
2016-06-13 14:04:57,464  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 149.0 (TID 282). 45217 bytes result sent to driver
2016-06-13 14:04:57,465  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 149.0 (TID 282) in 10 ms on localhost (2/2)
2016-06-13 14:04:57,465  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 149.0, whose tasks have all completed, from pool 
2016-06-13 14:04:57,465  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 149 (treeAggregate at RowMatrix.scala:93) finished in 0.010 s
2016-06-13 14:04:57,465  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 139 finished: treeAggregate at RowMatrix.scala:93, took 0.015199 s
2016-06-13 14:04:57,471  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_282 stored as values in memory (estimated size 124.9 KB, free 120.6 MB)
2016-06-13 14:04:57,473  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_282_piece0 stored as bytes in memory (estimated size 124.8 KB, free 120.7 MB)
2016-06-13 14:04:57,473  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_282_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:57,474  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 282 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,482  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,482  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 140 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,482  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 150 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,482  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,483  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,483  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 150 (MapPartitionsRDD[183] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,485  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_283 stored as values in memory (estimated size 55.2 KB, free 120.8 MB)
2016-06-13 14:04:57,486  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_283_piece0 stored as bytes in memory (estimated size 8.1 KB, free 120.8 MB)
2016-06-13 14:04:57,486  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_283_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,486  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 283 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,487  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 150 (MapPartitionsRDD[183] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,487  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 150.0 with 2 tasks
2016-06-13 14:04:57,487  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 150.0 (TID 283, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,487  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 150.0 (TID 284, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,488  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 150.0 (TID 283)
2016-06-13 14:04:57,488  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 150.0 (TID 284)
2016-06-13 14:04:57,490  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:57,493  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 150.0 (TID 284). 45217 bytes result sent to driver
2016-06-13 14:04:57,494  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 150.0 (TID 284) in 7 ms on localhost (1/2)
2016-06-13 14:04:57,496  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,501  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 150.0 (TID 283). 45217 bytes result sent to driver
2016-06-13 14:04:57,503  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 150.0 (TID 283) in 15 ms on localhost (2/2)
2016-06-13 14:04:57,503  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 150.0, whose tasks have all completed, from pool 
2016-06-13 14:04:57,503  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 150 (treeAggregate at RowMatrix.scala:93) finished in 0.003 s
2016-06-13 14:04:57,503  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 140 finished: treeAggregate at RowMatrix.scala:93, took 0.021464 s
2016-06-13 14:04:57,509  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_284 stored as values in memory (estimated size 124.9 KB, free 120.9 MB)
2016-06-13 14:04:57,511  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_284_piece0 stored as bytes in memory (estimated size 124.7 KB, free 121.0 MB)
2016-06-13 14:04:57,511  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_284_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:57,511  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 284 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,521  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,521  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 141 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,521  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 151 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,521  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,521  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,522  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 151 (MapPartitionsRDD[184] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,523  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_285 stored as values in memory (estimated size 55.2 KB, free 121.1 MB)
2016-06-13 14:04:57,524  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_285_piece0 stored as bytes in memory (estimated size 8.1 KB, free 121.1 MB)
2016-06-13 14:04:57,525  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_285_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,525  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 285 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,525  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 151 (MapPartitionsRDD[184] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,525  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 151.0 with 2 tasks
2016-06-13 14:04:57,526  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 151.0 (TID 285, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,526  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 151.0 (TID 286, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,526  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 151.0 (TID 285)
2016-06-13 14:04:57,526  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 151.0 (TID 286)
2016-06-13 14:04:57,529  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:57,533  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,536  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 151.0 (TID 286). 45217 bytes result sent to driver
2016-06-13 14:04:57,537  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 151.0 (TID 285). 45217 bytes result sent to driver
2016-06-13 14:04:57,538  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 151.0 (TID 286) in 12 ms on localhost (1/2)
2016-06-13 14:04:57,539  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 151.0 (TID 285) in 12 ms on localhost (2/2)
2016-06-13 14:04:57,539  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 151.0, whose tasks have all completed, from pool 
2016-06-13 14:04:57,539  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 151 (treeAggregate at RowMatrix.scala:93) finished in 0.003 s
2016-06-13 14:04:57,540  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 141 finished: treeAggregate at RowMatrix.scala:93, took 0.018947 s
2016-06-13 14:04:57,545  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_286 stored as values in memory (estimated size 124.9 KB, free 121.2 MB)
2016-06-13 14:04:57,546  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_286_piece0 stored as bytes in memory (estimated size 124.7 KB, free 121.3 MB)
2016-06-13 14:04:57,546  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_286_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:57,547  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 286 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,558  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,558  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 142 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,558  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 152 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,558  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,559  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,559  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 152 (MapPartitionsRDD[185] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,560  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_287 stored as values in memory (estimated size 55.2 KB, free 121.4 MB)
2016-06-13 14:04:57,562  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_287_piece0 stored as bytes in memory (estimated size 8.1 KB, free 121.4 MB)
2016-06-13 14:04:57,562  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_287_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,562  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 287 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,563  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 152 (MapPartitionsRDD[185] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,563  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 152.0 with 2 tasks
2016-06-13 14:04:57,563  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 152.0 (TID 287, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,564  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 152.0 (TID 288, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,564  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 152.0 (TID 287)
2016-06-13 14:04:57,564  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 152.0 (TID 288)
2016-06-13 14:04:57,571  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,573  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:57,575  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 152.0 (TID 288). 45217 bytes result sent to driver
2016-06-13 14:04:57,577  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 152.0 (TID 287). 45217 bytes result sent to driver
2016-06-13 14:04:57,578  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 152.0 (TID 288) in 14 ms on localhost (1/2)
2016-06-13 14:04:57,579  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 152.0 (TID 287) in 16 ms on localhost (2/2)
2016-06-13 14:04:57,579  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 152.0, whose tasks have all completed, from pool 
2016-06-13 14:04:57,579  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 152 (treeAggregate at RowMatrix.scala:93) finished in 0.002 s
2016-06-13 14:04:57,580  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 142 finished: treeAggregate at RowMatrix.scala:93, took 0.021739 s
2016-06-13 14:04:57,586  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_288 stored as values in memory (estimated size 124.9 KB, free 121.5 MB)
2016-06-13 14:04:57,587  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_288_piece0 stored as bytes in memory (estimated size 124.7 KB, free 121.6 MB)
2016-06-13 14:04:57,588  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_288_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:57,588  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 288 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,596  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,597  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 143 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,597  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 153 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,597  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,597  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,597  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 153 (MapPartitionsRDD[186] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,599  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_289 stored as values in memory (estimated size 55.2 KB, free 121.7 MB)
2016-06-13 14:04:57,602  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_289_piece0 stored as bytes in memory (estimated size 8.1 KB, free 121.7 MB)
2016-06-13 14:04:57,603  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_289_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,603  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 289 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,603  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 153 (MapPartitionsRDD[186] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,603  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 153.0 with 2 tasks
2016-06-13 14:04:57,604  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 153.0 (TID 289, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,604  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 153.0 (TID 290, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,604  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 153.0 (TID 289)
2016-06-13 14:04:57,604  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 153.0 (TID 290)
2016-06-13 14:04:57,607  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:57,609  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 153.0 (TID 290). 45217 bytes result sent to driver
2016-06-13 14:04:57,610  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 153.0 (TID 290) in 6 ms on localhost (1/2)
2016-06-13 14:04:57,614  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,623  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 153.0 (TID 289). 45217 bytes result sent to driver
2016-06-13 14:04:57,624  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 153.0 (TID 289) in 20 ms on localhost (2/2)
2016-06-13 14:04:57,624  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 153.0, whose tasks have all completed, from pool 
2016-06-13 14:04:57,624  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 153 (treeAggregate at RowMatrix.scala:93) finished in 0.002 s
2016-06-13 14:04:57,626  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 143 finished: treeAggregate at RowMatrix.scala:93, took 0.029292 s
2016-06-13 14:04:57,631  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_290 stored as values in memory (estimated size 124.9 KB, free 121.8 MB)
2016-06-13 14:04:57,636  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_290_piece0 stored as bytes in memory (estimated size 124.7 KB, free 121.9 MB)
2016-06-13 14:04:57,636  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_290_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:57,637  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 290 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,644  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,645  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 144 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,645  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 154 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,645  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,645  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,645  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 154 (MapPartitionsRDD[187] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,647  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_291 stored as values in memory (estimated size 55.2 KB, free 122.0 MB)
2016-06-13 14:04:57,648  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_291_piece0 stored as bytes in memory (estimated size 8.1 KB, free 122.0 MB)
2016-06-13 14:04:57,649  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_291_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,649  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 291 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,649  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 154 (MapPartitionsRDD[187] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,649  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 154.0 with 2 tasks
2016-06-13 14:04:57,650  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 154.0 (TID 291, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,650  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 154.0 (TID 292, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,650  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 154.0 (TID 291)
2016-06-13 14:04:57,650  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 154.0 (TID 292)
2016-06-13 14:04:57,653  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:57,657  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,663  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 154.0 (TID 292). 45217 bytes result sent to driver
2016-06-13 14:04:57,664  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 154.0 (TID 292) in 14 ms on localhost (1/2)
2016-06-13 14:04:57,665  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 154.0 (TID 291). 45217 bytes result sent to driver
2016-06-13 14:04:57,668  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 154.0 (TID 291) in 18 ms on localhost (2/2)
2016-06-13 14:04:57,668  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 154.0, whose tasks have all completed, from pool 
2016-06-13 14:04:57,668  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 154 (treeAggregate at RowMatrix.scala:93) finished in 0.007 s
2016-06-13 14:04:57,669  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 144 finished: treeAggregate at RowMatrix.scala:93, took 0.024497 s
2016-06-13 14:04:57,674  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_292 stored as values in memory (estimated size 124.9 KB, free 122.1 MB)
2016-06-13 14:04:57,676  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_292_piece0 stored as bytes in memory (estimated size 124.7 KB, free 122.2 MB)
2016-06-13 14:04:57,676  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_292_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:57,676  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 292 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,685  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,686  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 145 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,686  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 155 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,686  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,687  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,688  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 155 (MapPartitionsRDD[188] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,689  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_293 stored as values in memory (estimated size 55.2 KB, free 122.3 MB)
2016-06-13 14:04:57,690  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_293_piece0 stored as bytes in memory (estimated size 8.1 KB, free 122.3 MB)
2016-06-13 14:04:57,690  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_293_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,690  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 293 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,690  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 155 (MapPartitionsRDD[188] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,690  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 155.0 with 2 tasks
2016-06-13 14:04:57,691  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 155.0 (TID 293, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,691  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 155.0 (TID 294, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,691  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 155.0 (TID 293)
2016-06-13 14:04:57,691  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 155.0 (TID 294)
2016-06-13 14:04:57,693  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,694  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:57,695  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 155.0 (TID 293). 45217 bytes result sent to driver
2016-06-13 14:04:57,697  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 155.0 (TID 294). 45217 bytes result sent to driver
2016-06-13 14:04:57,697  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 155.0 (TID 293) in 6 ms on localhost (1/2)
2016-06-13 14:04:57,697  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 155.0 (TID 294) in 6 ms on localhost (2/2)
2016-06-13 14:04:57,697  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 155.0, whose tasks have all completed, from pool 
2016-06-13 14:04:57,697  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 155 (treeAggregate at RowMatrix.scala:93) finished in 0.006 s
2016-06-13 14:04:57,698  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 145 finished: treeAggregate at RowMatrix.scala:93, took 0.012010 s
2016-06-13 14:04:57,703  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_294 stored as values in memory (estimated size 124.9 KB, free 122.4 MB)
2016-06-13 14:04:57,704  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_294_piece0 stored as bytes in memory (estimated size 124.8 KB, free 122.5 MB)
2016-06-13 14:04:57,704  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_294_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:57,705  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 294 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,711  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,712  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 146 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,712  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 156 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,712  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,712  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,712  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 156 (MapPartitionsRDD[189] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,714  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_295 stored as values in memory (estimated size 55.2 KB, free 122.6 MB)
2016-06-13 14:04:57,715  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_295_piece0 stored as bytes in memory (estimated size 8.1 KB, free 122.6 MB)
2016-06-13 14:04:57,716  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_295_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,716  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 295 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,716  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 156 (MapPartitionsRDD[189] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,716  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 156.0 with 2 tasks
2016-06-13 14:04:57,717  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 156.0 (TID 295, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,717  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 156.0 (TID 296, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,717  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 156.0 (TID 296)
2016-06-13 14:04:57,717  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 156.0 (TID 295)
2016-06-13 14:04:57,720  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:57,724  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,727  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 156.0 (TID 295). 45217 bytes result sent to driver
2016-06-13 14:04:57,728  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 156.0 (TID 296). 45217 bytes result sent to driver
2016-06-13 14:04:57,729  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 156.0 (TID 295) in 12 ms on localhost (1/2)
2016-06-13 14:04:57,730  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 156.0 (TID 296) in 13 ms on localhost (2/2)
2016-06-13 14:04:57,730  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 156.0, whose tasks have all completed, from pool 
2016-06-13 14:04:57,730  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 156 (treeAggregate at RowMatrix.scala:93) finished in 0.013 s
2016-06-13 14:04:57,730  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 146 finished: treeAggregate at RowMatrix.scala:93, took 0.018588 s
2016-06-13 14:04:57,737  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_296 stored as values in memory (estimated size 124.9 KB, free 122.7 MB)
2016-06-13 14:04:57,739  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_296_piece0 stored as bytes in memory (estimated size 124.8 KB, free 122.9 MB)
2016-06-13 14:04:57,739  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_296_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:57,740  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 296 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,747  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,747  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 147 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,747  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 157 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,747  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,748  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,748  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 157 (MapPartitionsRDD[190] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,750  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_297 stored as values in memory (estimated size 55.2 KB, free 122.9 MB)
2016-06-13 14:04:57,751  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_297_piece0 stored as bytes in memory (estimated size 8.1 KB, free 122.9 MB)
2016-06-13 14:04:57,753  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_297_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,753  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 297 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,754  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 157 (MapPartitionsRDD[190] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,754  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 157.0 with 2 tasks
2016-06-13 14:04:57,754  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 157.0 (TID 297, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,754  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 157.0 (TID 298, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,755  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 157.0 (TID 297)
2016-06-13 14:04:57,755  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 157.0 (TID 298)
2016-06-13 14:04:57,757  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,760  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:57,760  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 157.0 (TID 297). 45217 bytes result sent to driver
2016-06-13 14:04:57,761  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 157.0 (TID 297) in 6 ms on localhost (1/2)
2016-06-13 14:04:57,761  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 157.0 (TID 298). 45217 bytes result sent to driver
2016-06-13 14:04:57,762  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 157.0 (TID 298) in 8 ms on localhost (2/2)
2016-06-13 14:04:57,762  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 157.0, whose tasks have all completed, from pool 
2016-06-13 14:04:57,762  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 157 (treeAggregate at RowMatrix.scala:93) finished in 0.001 s
2016-06-13 14:04:57,762  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 147 finished: treeAggregate at RowMatrix.scala:93, took 0.015218 s
2016-06-13 14:04:57,767  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_298 stored as values in memory (estimated size 124.9 KB, free 123.0 MB)
2016-06-13 14:04:57,769  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_298_piece0 stored as bytes in memory (estimated size 124.8 KB, free 123.2 MB)
2016-06-13 14:04:57,769  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_298_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:57,769  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 298 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,775  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,776  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 148 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,776  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 158 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,776  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,776  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,776  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 158 (MapPartitionsRDD[191] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,777  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_299 stored as values in memory (estimated size 55.2 KB, free 123.2 MB)
2016-06-13 14:04:57,778  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_299_piece0 stored as bytes in memory (estimated size 8.1 KB, free 123.2 MB)
2016-06-13 14:04:57,778  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_299_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,779  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 299 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,779  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 158 (MapPartitionsRDD[191] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,779  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 158.0 with 2 tasks
2016-06-13 14:04:57,779  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 158.0 (TID 299, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,779  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 158.0 (TID 300, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,779  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 158.0 (TID 299)
2016-06-13 14:04:57,779  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 158.0 (TID 300)
2016-06-13 14:04:57,781  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:57,783  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 158.0 (TID 300). 45217 bytes result sent to driver
2016-06-13 14:04:57,784  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 158.0 (TID 300) in 5 ms on localhost (1/2)
2016-06-13 14:04:57,784  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,786  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 158.0 (TID 299). 45217 bytes result sent to driver
2016-06-13 14:04:57,789  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 158.0 (TID 299) in 10 ms on localhost (2/2)
2016-06-13 14:04:57,789  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 158 (treeAggregate at RowMatrix.scala:93) finished in 0.010 s
2016-06-13 14:04:57,789  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 158.0, whose tasks have all completed, from pool 
2016-06-13 14:04:57,790  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 148 finished: treeAggregate at RowMatrix.scala:93, took 0.014322 s
2016-06-13 14:04:57,794  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_300 stored as values in memory (estimated size 124.9 KB, free 123.3 MB)
2016-06-13 14:04:57,795  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_300_piece0 stored as bytes in memory (estimated size 124.7 KB, free 123.5 MB)
2016-06-13 14:04:57,795  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_300_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:57,796  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 300 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,804  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,804  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 149 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,804  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 159 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,804  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,804  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,804  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 159 (MapPartitionsRDD[192] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,806  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_301 stored as values in memory (estimated size 55.2 KB, free 123.5 MB)
2016-06-13 14:04:57,807  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_301_piece0 stored as bytes in memory (estimated size 8.1 KB, free 123.5 MB)
2016-06-13 14:04:57,807  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_301_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,808  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 301 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,808  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 159 (MapPartitionsRDD[192] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,808  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 159.0 with 2 tasks
2016-06-13 14:04:57,808  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 159.0 (TID 301, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,808  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 159.0 (TID 302, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,809  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 159.0 (TID 302)
2016-06-13 14:04:57,810  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 159.0 (TID 301)
2016-06-13 14:04:57,810  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:57,812  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,813  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 159.0 (TID 302). 45217 bytes result sent to driver
2016-06-13 14:04:57,813  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 159.0 (TID 302) in 5 ms on localhost (1/2)
2016-06-13 14:04:57,814  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 159.0 (TID 301). 45217 bytes result sent to driver
2016-06-13 14:04:57,815  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 159.0 (TID 301) in 7 ms on localhost (2/2)
2016-06-13 14:04:57,815  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 159 (treeAggregate at RowMatrix.scala:93) finished in 0.007 s
2016-06-13 14:04:57,815  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 149 finished: treeAggregate at RowMatrix.scala:93, took 0.011528 s
2016-06-13 14:04:57,815  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 159.0, whose tasks have all completed, from pool 
2016-06-13 14:04:57,820  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_302 stored as values in memory (estimated size 124.9 KB, free 123.6 MB)
2016-06-13 14:04:57,822  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_302_piece0 stored as bytes in memory (estimated size 124.7 KB, free 123.8 MB)
2016-06-13 14:04:57,822  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_302_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:57,822  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 302 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,828  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,829  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 150 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,829  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 160 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,829  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,829  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,829  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 160 (MapPartitionsRDD[193] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,830  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_303 stored as values in memory (estimated size 55.2 KB, free 123.8 MB)
2016-06-13 14:04:57,831  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_303_piece0 stored as bytes in memory (estimated size 8.1 KB, free 123.8 MB)
2016-06-13 14:04:57,831  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_303_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,831  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 303 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,832  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 160 (MapPartitionsRDD[193] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,832  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 160.0 with 2 tasks
2016-06-13 14:04:57,832  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 160.0 (TID 303, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,832  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 160.0 (TID 304, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,832  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 160.0 (TID 304)
2016-06-13 14:04:57,832  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 160.0 (TID 303)
2016-06-13 14:04:57,836  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:57,842  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,844  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 160.0 (TID 304). 45217 bytes result sent to driver
2016-06-13 14:04:57,844  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 160.0 (TID 303). 45217 bytes result sent to driver
2016-06-13 14:04:57,845  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 160.0 (TID 303) in 13 ms on localhost (1/2)
2016-06-13 14:04:57,846  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 160.0 (TID 304) in 14 ms on localhost (2/2)
2016-06-13 14:04:57,846  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 160.0, whose tasks have all completed, from pool 
2016-06-13 14:04:57,846  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 160 (treeAggregate at RowMatrix.scala:93) finished in 0.014 s
2016-06-13 14:04:57,847  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 150 finished: treeAggregate at RowMatrix.scala:93, took 0.018572 s
2016-06-13 14:04:57,854  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_304 stored as values in memory (estimated size 124.9 KB, free 124.0 MB)
2016-06-13 14:04:57,856  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_304_piece0 stored as bytes in memory (estimated size 124.7 KB, free 124.1 MB)
2016-06-13 14:04:57,856  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_304_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:57,856  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 304 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,863  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,863  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 151 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,864  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 161 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,864  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,864  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,864  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 161 (MapPartitionsRDD[194] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,865  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_305 stored as values in memory (estimated size 55.2 KB, free 124.1 MB)
2016-06-13 14:04:57,866  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_305_piece0 stored as bytes in memory (estimated size 8.1 KB, free 124.1 MB)
2016-06-13 14:04:57,866  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_305_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,866  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 305 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,866  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 161 (MapPartitionsRDD[194] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,866  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 161.0 with 2 tasks
2016-06-13 14:04:57,867  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 161.0 (TID 305, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,867  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 161.0 (TID 306, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,867  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 161.0 (TID 305)
2016-06-13 14:04:57,869  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,872  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 161.0 (TID 305). 45217 bytes result sent to driver
2016-06-13 14:04:57,872  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 161.0 (TID 306)
2016-06-13 14:04:57,875  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:57,877  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 161.0 (TID 306). 45217 bytes result sent to driver
2016-06-13 14:04:57,879  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 161.0 (TID 305) in 11 ms on localhost (1/2)
2016-06-13 14:04:57,879  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 161.0 (TID 306) in 12 ms on localhost (2/2)
2016-06-13 14:04:57,879  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 161.0, whose tasks have all completed, from pool 
2016-06-13 14:04:57,880  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 161 (treeAggregate at RowMatrix.scala:93) finished in 0.013 s
2016-06-13 14:04:57,881  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 151 finished: treeAggregate at RowMatrix.scala:93, took 0.017527 s
2016-06-13 14:04:57,887  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_306 stored as values in memory (estimated size 124.9 KB, free 124.3 MB)
2016-06-13 14:04:57,889  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_306_piece0 stored as bytes in memory (estimated size 124.7 KB, free 124.4 MB)
2016-06-13 14:04:57,889  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_306_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:57,890  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 306 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,896  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,897  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 152 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,897  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 162 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,897  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,897  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,898  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 162 (MapPartitionsRDD[195] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,900  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_307 stored as values in memory (estimated size 55.2 KB, free 124.4 MB)
2016-06-13 14:04:57,901  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_307_piece0 stored as bytes in memory (estimated size 8.1 KB, free 124.4 MB)
2016-06-13 14:04:57,901  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_307_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,901  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 307 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,902  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 162 (MapPartitionsRDD[195] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,902  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 162.0 with 2 tasks
2016-06-13 14:04:57,902  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 162.0 (TID 307, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,903  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 162.0 (TID 308, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,903  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 162.0 (TID 307)
2016-06-13 14:04:57,905  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,905  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 162.0 (TID 308)
2016-06-13 14:04:57,908  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 162.0 (TID 307). 45217 bytes result sent to driver
2016-06-13 14:04:57,908  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:57,908  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 162.0 (TID 307) in 6 ms on localhost (1/2)
2016-06-13 14:04:57,910  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 162.0 (TID 308). 45217 bytes result sent to driver
2016-06-13 14:04:57,911  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 162.0 (TID 308) in 9 ms on localhost (2/2)
2016-06-13 14:04:57,911  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 162.0, whose tasks have all completed, from pool 
2016-06-13 14:04:57,911  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 162 (treeAggregate at RowMatrix.scala:93) finished in 0.009 s
2016-06-13 14:04:57,911  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 152 finished: treeAggregate at RowMatrix.scala:93, took 0.014758 s
2016-06-13 14:04:57,915  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_308 stored as values in memory (estimated size 124.9 KB, free 124.6 MB)
2016-06-13 14:04:57,916  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_308_piece0 stored as bytes in memory (estimated size 124.7 KB, free 124.7 MB)
2016-06-13 14:04:57,917  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_308_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:57,917  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 308 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,922  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,922  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 153 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,922  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 163 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,922  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,922  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,923  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 163 (MapPartitionsRDD[196] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,924  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_309 stored as values in memory (estimated size 55.2 KB, free 124.7 MB)
2016-06-13 14:04:57,924  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_309_piece0 stored as bytes in memory (estimated size 8.1 KB, free 124.7 MB)
2016-06-13 14:04:57,925  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_309_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,925  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 309 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,925  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 163 (MapPartitionsRDD[196] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,925  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 163.0 with 2 tasks
2016-06-13 14:04:57,925  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 163.0 (TID 309, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,926  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 163.0 (TID 310, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,926  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 163.0 (TID 309)
2016-06-13 14:04:57,926  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 163.0 (TID 310)
2016-06-13 14:04:57,927  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,928  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:57,929  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 163.0 (TID 309). 45217 bytes result sent to driver
2016-06-13 14:04:57,929  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 163.0 (TID 309) in 4 ms on localhost (1/2)
2016-06-13 14:04:57,930  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 163.0 (TID 310). 45217 bytes result sent to driver
2016-06-13 14:04:57,931  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 163.0 (TID 310) in 6 ms on localhost (2/2)
2016-06-13 14:04:57,931  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 163 (treeAggregate at RowMatrix.scala:93) finished in 0.006 s
2016-06-13 14:04:57,931  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 163.0, whose tasks have all completed, from pool 
2016-06-13 14:04:57,931  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 153 finished: treeAggregate at RowMatrix.scala:93, took 0.009595 s
2016-06-13 14:04:57,937  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_310 stored as values in memory (estimated size 124.9 KB, free 124.9 MB)
2016-06-13 14:04:57,940  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_310_piece0 stored as bytes in memory (estimated size 124.7 KB, free 125.0 MB)
2016-06-13 14:04:57,941  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_310_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:57,941  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 310 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,950  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,950  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 154 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,950  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 164 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,950  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,952  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,952  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 164 (MapPartitionsRDD[197] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,953  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_311 stored as values in memory (estimated size 55.2 KB, free 125.0 MB)
2016-06-13 14:04:57,954  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_311_piece0 stored as bytes in memory (estimated size 8.1 KB, free 125.1 MB)
2016-06-13 14:04:57,955  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_311_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,955  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 311 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,955  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 164 (MapPartitionsRDD[197] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,955  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 164.0 with 2 tasks
2016-06-13 14:04:57,955  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 164.0 (TID 311, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,955  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 164.0 (TID 312, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,956  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 164.0 (TID 312)
2016-06-13 14:04:57,956  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 164.0 (TID 311)
2016-06-13 14:04:57,957  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,958  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:57,959  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 164.0 (TID 311). 45217 bytes result sent to driver
2016-06-13 14:04:57,959  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 164.0 (TID 311) in 4 ms on localhost (1/2)
2016-06-13 14:04:57,960  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 164.0 (TID 312). 45217 bytes result sent to driver
2016-06-13 14:04:57,960  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 164.0 (TID 312) in 5 ms on localhost (2/2)
2016-06-13 14:04:57,960  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 164.0, whose tasks have all completed, from pool 
2016-06-13 14:04:57,960  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 164 (treeAggregate at RowMatrix.scala:93) finished in 0.005 s
2016-06-13 14:04:57,960  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 154 finished: treeAggregate at RowMatrix.scala:93, took 0.010591 s
2016-06-13 14:04:57,964  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_312 stored as values in memory (estimated size 124.9 KB, free 125.2 MB)
2016-06-13 14:04:57,965  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_312_piece0 stored as bytes in memory (estimated size 124.8 KB, free 125.3 MB)
2016-06-13 14:04:57,965  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_312_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:57,966  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 312 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:57,978  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:57,979  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 155 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:57,979  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 165 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,979  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:57,979  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:57,980  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 165 (MapPartitionsRDD[198] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:57,983  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_313 stored as values in memory (estimated size 55.2 KB, free 125.3 MB)
2016-06-13 14:04:57,984  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_313_piece0 stored as bytes in memory (estimated size 8.1 KB, free 125.4 MB)
2016-06-13 14:04:57,985  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_313_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:57,986  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 313 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:57,986  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 165 (MapPartitionsRDD[198] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:57,986  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 165.0 with 2 tasks
2016-06-13 14:04:57,987  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 165.0 (TID 313, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,987  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 165.0 (TID 314, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:57,988  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 165.0 (TID 313)
2016-06-13 14:04:57,990  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:57,993  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 165.0 (TID 313). 45217 bytes result sent to driver
2016-06-13 14:04:57,994  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 165.0 (TID 314)
2016-06-13 14:04:57,994  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 165.0 (TID 313) in 7 ms on localhost (1/2)
2016-06-13 14:04:57,999  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:58,001  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 165.0 (TID 314). 45217 bytes result sent to driver
2016-06-13 14:04:58,001  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 165.0 (TID 314) in 14 ms on localhost (2/2)
2016-06-13 14:04:58,001  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 165 (treeAggregate at RowMatrix.scala:93) finished in 0.015 s
2016-06-13 14:04:58,001  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 165.0, whose tasks have all completed, from pool 
2016-06-13 14:04:58,002  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 155 finished: treeAggregate at RowMatrix.scala:93, took 0.023288 s
2016-06-13 14:04:58,006  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_314 stored as values in memory (estimated size 124.9 KB, free 125.5 MB)
2016-06-13 14:04:58,007  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_314_piece0 stored as bytes in memory (estimated size 124.8 KB, free 125.6 MB)
2016-06-13 14:04:58,007  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_314_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,009  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 314 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:58,016  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:58,016  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 156 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:58,017  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 166 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,017  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:58,018  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:58,019  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 166 (MapPartitionsRDD[199] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:58,020  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_315 stored as values in memory (estimated size 55.2 KB, free 125.7 MB)
2016-06-13 14:04:58,023  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_315_piece0 stored as bytes in memory (estimated size 8.1 KB, free 125.7 MB)
2016-06-13 14:04:58,023  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_315_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,023  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 315 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:58,024  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 166 (MapPartitionsRDD[199] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,025  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 166.0 with 2 tasks
2016-06-13 14:04:58,025  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 166.0 (TID 315, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,026  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 166.0 (TID 316, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,026  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 166.0 (TID 315)
2016-06-13 14:04:58,026  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 166.0 (TID 316)
2016-06-13 14:04:58,029  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:58,030  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:58,033  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 166.0 (TID 315). 45217 bytes result sent to driver
2016-06-13 14:04:58,033  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 166.0 (TID 316). 45217 bytes result sent to driver
2016-06-13 14:04:58,034  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 166.0 (TID 315) in 9 ms on localhost (1/2)
2016-06-13 14:04:58,034  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 166.0 (TID 316) in 9 ms on localhost (2/2)
2016-06-13 14:04:58,034  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 166.0, whose tasks have all completed, from pool 
2016-06-13 14:04:58,034  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 166 (treeAggregate at RowMatrix.scala:93) finished in 0.008 s
2016-06-13 14:04:58,036  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 156 finished: treeAggregate at RowMatrix.scala:93, took 0.019793 s
2016-06-13 14:04:58,040  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_316 stored as values in memory (estimated size 124.9 KB, free 125.8 MB)
2016-06-13 14:04:58,042  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_316_piece0 stored as bytes in memory (estimated size 124.7 KB, free 125.9 MB)
2016-06-13 14:04:58,042  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_316_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,043  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 316 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:58,048  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:58,049  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 157 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:58,049  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 167 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,049  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:58,049  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:58,049  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 167 (MapPartitionsRDD[200] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:58,051  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_317 stored as values in memory (estimated size 55.2 KB, free 126.0 MB)
2016-06-13 14:04:58,052  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_317_piece0 stored as bytes in memory (estimated size 8.1 KB, free 126.0 MB)
2016-06-13 14:04:58,052  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_317_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,052  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 317 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:58,052  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 167 (MapPartitionsRDD[200] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,052  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 167.0 with 2 tasks
2016-06-13 14:04:58,054  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 167.0 (TID 317, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,054  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 167.0 (TID 318, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,054  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 167.0 (TID 317)
2016-06-13 14:04:58,056  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:58,057  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 167.0 (TID 317). 45217 bytes result sent to driver
2016-06-13 14:04:58,057  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 167.0 (TID 318)
2016-06-13 14:04:58,058  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 167.0 (TID 317) in 4 ms on localhost (1/2)
2016-06-13 14:04:58,059  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:58,061  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 167.0 (TID 318). 45217 bytes result sent to driver
2016-06-13 14:04:58,061  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 167.0 (TID 318) in 7 ms on localhost (2/2)
2016-06-13 14:04:58,061  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 167.0, whose tasks have all completed, from pool 
2016-06-13 14:04:58,061  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 167 (treeAggregate at RowMatrix.scala:93) finished in 0.009 s
2016-06-13 14:04:58,061  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 157 finished: treeAggregate at RowMatrix.scala:93, took 0.013029 s
2016-06-13 14:04:58,065  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_318 stored as values in memory (estimated size 124.9 KB, free 126.1 MB)
2016-06-13 14:04:58,067  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_318_piece0 stored as bytes in memory (estimated size 124.7 KB, free 126.2 MB)
2016-06-13 14:04:58,067  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_318_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,067  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 318 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:58,071  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:58,073  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 158 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:58,073  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 168 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,073  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:58,073  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:58,073  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 168 (MapPartitionsRDD[201] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:58,074  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_319 stored as values in memory (estimated size 55.2 KB, free 126.3 MB)
2016-06-13 14:04:58,076  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_319_piece0 stored as bytes in memory (estimated size 8.1 KB, free 126.3 MB)
2016-06-13 14:04:58,076  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_319_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,076  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 319 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:58,076  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 168 (MapPartitionsRDD[201] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,076  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 168.0 with 2 tasks
2016-06-13 14:04:58,077  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 168.0 (TID 319, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,077  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 168.0 (TID 320, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,077  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 168.0 (TID 319)
2016-06-13 14:04:58,077  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 168.0 (TID 320)
2016-06-13 14:04:58,080  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:58,082  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 168.0 (TID 319). 45217 bytes result sent to driver
2016-06-13 14:04:58,084  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 168.0 (TID 319) in 7 ms on localhost (1/2)
2016-06-13 14:04:58,084  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:58,087  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 168.0 (TID 320). 45217 bytes result sent to driver
2016-06-13 14:04:58,088  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 168.0 (TID 320) in 11 ms on localhost (2/2)
2016-06-13 14:04:58,088  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 168.0, whose tasks have all completed, from pool 
2016-06-13 14:04:58,088  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 168 (treeAggregate at RowMatrix.scala:93) finished in 0.012 s
2016-06-13 14:04:58,088  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 158 finished: treeAggregate at RowMatrix.scala:93, took 0.016610 s
2016-06-13 14:04:58,094  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_320 stored as values in memory (estimated size 124.9 KB, free 126.4 MB)
2016-06-13 14:04:58,095  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_320_piece0 stored as bytes in memory (estimated size 124.8 KB, free 126.5 MB)
2016-06-13 14:04:58,095  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_320_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,095  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 320 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:58,100  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:58,101  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 159 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:58,101  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 169 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,101  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:58,101  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:58,101  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 169 (MapPartitionsRDD[202] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:58,102  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_321 stored as values in memory (estimated size 55.2 KB, free 126.6 MB)
2016-06-13 14:04:58,103  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_321_piece0 stored as bytes in memory (estimated size 8.1 KB, free 126.6 MB)
2016-06-13 14:04:58,104  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_321_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,104  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 321 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:58,104  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 169 (MapPartitionsRDD[202] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,104  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 169.0 with 2 tasks
2016-06-13 14:04:58,104  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 169.0 (TID 321, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,105  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 169.0 (TID 322, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,105  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 169.0 (TID 321)
2016-06-13 14:04:58,106  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 169.0 (TID 322)
2016-06-13 14:04:58,107  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:58,108  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:58,109  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 169.0 (TID 321). 45217 bytes result sent to driver
2016-06-13 14:04:58,111  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 169.0 (TID 321) in 7 ms on localhost (1/2)
2016-06-13 14:04:58,111  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 169.0 (TID 322). 45217 bytes result sent to driver
2016-06-13 14:04:58,112  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 169.0 (TID 322) in 8 ms on localhost (2/2)
2016-06-13 14:04:58,112  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 169.0, whose tasks have all completed, from pool 
2016-06-13 14:04:58,112  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 169 (treeAggregate at RowMatrix.scala:93) finished in 0.008 s
2016-06-13 14:04:58,114  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 159 finished: treeAggregate at RowMatrix.scala:93, took 0.013488 s
2016-06-13 14:04:58,120  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_322 stored as values in memory (estimated size 124.9 KB, free 126.7 MB)
2016-06-13 14:04:58,121  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_322_piece0 stored as bytes in memory (estimated size 124.8 KB, free 126.8 MB)
2016-06-13 14:04:58,122  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_322_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,122  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 322 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:58,132  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:58,133  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 160 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:58,133  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 170 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,133  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:58,133  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:58,133  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 170 (MapPartitionsRDD[203] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:58,135  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_323 stored as values in memory (estimated size 55.2 KB, free 126.9 MB)
2016-06-13 14:04:58,136  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_323_piece0 stored as bytes in memory (estimated size 8.1 KB, free 126.9 MB)
2016-06-13 14:04:58,136  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_323_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,137  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 323 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:58,137  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 170 (MapPartitionsRDD[203] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,137  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 170.0 with 2 tasks
2016-06-13 14:04:58,137  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 170.0 (TID 323, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,137  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 170.0 (TID 324, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,138  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 170.0 (TID 323)
2016-06-13 14:04:58,138  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 170.0 (TID 324)
2016-06-13 14:04:58,140  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:58,142  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 170.0 (TID 323). 45217 bytes result sent to driver
2016-06-13 14:04:58,143  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:58,145  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 170.0 (TID 324). 45217 bytes result sent to driver
2016-06-13 14:04:58,146  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 170.0 (TID 323) in 9 ms on localhost (1/2)
2016-06-13 14:04:58,147  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 170.0 (TID 324) in 10 ms on localhost (2/2)
2016-06-13 14:04:58,147  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 170 (treeAggregate at RowMatrix.scala:93) finished in 0.010 s
2016-06-13 14:04:58,147  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 170.0, whose tasks have all completed, from pool 
2016-06-13 14:04:58,147  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 160 finished: treeAggregate at RowMatrix.scala:93, took 0.014755 s
2016-06-13 14:04:58,158  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_324 stored as values in memory (estimated size 124.9 KB, free 127.0 MB)
2016-06-13 14:04:58,160  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_324_piece0 stored as bytes in memory (estimated size 124.7 KB, free 127.1 MB)
2016-06-13 14:04:58,160  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_324_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,161  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 324 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:58,168  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:58,168  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 161 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:58,168  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 171 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,168  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:58,169  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:58,169  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 171 (MapPartitionsRDD[204] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:58,170  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_325 stored as values in memory (estimated size 55.2 KB, free 127.2 MB)
2016-06-13 14:04:58,171  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_325_piece0 stored as bytes in memory (estimated size 8.1 KB, free 127.2 MB)
2016-06-13 14:04:58,171  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_325_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,171  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 325 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:58,172  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 171 (MapPartitionsRDD[204] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,173  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 171.0 with 2 tasks
2016-06-13 14:04:58,173  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 171.0 (TID 325, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,174  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 171.0 (TID 326, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,174  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 171.0 (TID 325)
2016-06-13 14:04:58,174  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 171.0 (TID 326)
2016-06-13 14:04:58,177  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:58,180  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:58,183  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 171.0 (TID 326). 45217 bytes result sent to driver
2016-06-13 14:04:58,184  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 171.0 (TID 325). 45217 bytes result sent to driver
2016-06-13 14:04:58,185  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 171.0 (TID 326) in 12 ms on localhost (1/2)
2016-06-13 14:04:58,185  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 171.0 (TID 325) in 12 ms on localhost (2/2)
2016-06-13 14:04:58,185  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 171.0, whose tasks have all completed, from pool 
2016-06-13 14:04:58,186  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 171 (treeAggregate at RowMatrix.scala:93) finished in 0.004 s
2016-06-13 14:04:58,186  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 161 finished: treeAggregate at RowMatrix.scala:93, took 0.018090 s
2016-06-13 14:04:58,192  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_326 stored as values in memory (estimated size 124.9 KB, free 127.3 MB)
2016-06-13 14:04:58,193  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_326_piece0 stored as bytes in memory (estimated size 124.6 KB, free 127.4 MB)
2016-06-13 14:04:58,194  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_326_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:04:58,194  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 326 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:58,201  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:58,202  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 162 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:58,202  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 172 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,202  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:58,202  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:58,202  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 172 (MapPartitionsRDD[205] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:58,204  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_327 stored as values in memory (estimated size 55.2 KB, free 127.5 MB)
2016-06-13 14:04:58,205  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_327_piece0 stored as bytes in memory (estimated size 8.1 KB, free 127.5 MB)
2016-06-13 14:04:58,205  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_327_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,206  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 327 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:58,206  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 172 (MapPartitionsRDD[205] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,206  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 172.0 with 2 tasks
2016-06-13 14:04:58,207  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 172.0 (TID 327, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,207  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 172.0 (TID 328, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,207  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 172.0 (TID 327)
2016-06-13 14:04:58,207  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 172.0 (TID 328)
2016-06-13 14:04:58,209  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:58,212  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 172.0 (TID 328). 45217 bytes result sent to driver
2016-06-13 14:04:58,212  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:58,212  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 172.0 (TID 328) in 5 ms on localhost (1/2)
2016-06-13 14:04:58,214  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 172.0 (TID 327). 45217 bytes result sent to driver
2016-06-13 14:04:58,215  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 172.0 (TID 327) in 9 ms on localhost (2/2)
2016-06-13 14:04:58,215  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 172 (treeAggregate at RowMatrix.scala:93) finished in 0.004 s
2016-06-13 14:04:58,215  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 172.0, whose tasks have all completed, from pool 
2016-06-13 14:04:58,215  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 162 finished: treeAggregate at RowMatrix.scala:93, took 0.013798 s
2016-06-13 14:04:58,220  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_328 stored as values in memory (estimated size 124.9 KB, free 127.6 MB)
2016-06-13 14:04:58,221  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_328_piece0 stored as bytes in memory (estimated size 124.7 KB, free 127.7 MB)
2016-06-13 14:04:58,221  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_328_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,221  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 328 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:58,227  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:58,228  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 163 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:58,228  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 173 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,228  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:58,228  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:58,228  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 173 (MapPartitionsRDD[206] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:58,230  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_329 stored as values in memory (estimated size 55.2 KB, free 127.8 MB)
2016-06-13 14:04:58,231  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_329_piece0 stored as bytes in memory (estimated size 8.1 KB, free 127.8 MB)
2016-06-13 14:04:58,231  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_329_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,231  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 329 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:58,232  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 173 (MapPartitionsRDD[206] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,232  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 173.0 with 2 tasks
2016-06-13 14:04:58,232  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 173.0 (TID 329, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,232  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 173.0 (TID 330, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,233  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 173.0 (TID 330)
2016-06-13 14:04:58,233  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 173.0 (TID 329)
2016-06-13 14:04:58,235  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:58,235  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:58,237  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 173.0 (TID 330). 45217 bytes result sent to driver
2016-06-13 14:04:58,237  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 173.0 (TID 329). 45217 bytes result sent to driver
2016-06-13 14:04:58,238  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 173.0 (TID 330) in 6 ms on localhost (1/2)
2016-06-13 14:04:58,238  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 173.0 (TID 329) in 6 ms on localhost (2/2)
2016-06-13 14:04:58,238  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 173.0, whose tasks have all completed, from pool 
2016-06-13 14:04:58,238  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 173 (treeAggregate at RowMatrix.scala:93) finished in 0.006 s
2016-06-13 14:04:58,238  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 163 finished: treeAggregate at RowMatrix.scala:93, took 0.010525 s
2016-06-13 14:04:58,242  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_330 stored as values in memory (estimated size 124.9 KB, free 127.9 MB)
2016-06-13 14:04:58,243  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_330_piece0 stored as bytes in memory (estimated size 124.7 KB, free 128.0 MB)
2016-06-13 14:04:58,243  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_330_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,243  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 330 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:58,247  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:58,247  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 164 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:58,247  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 174 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,247  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:58,247  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:58,247  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 174 (MapPartitionsRDD[207] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:58,248  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_331 stored as values in memory (estimated size 55.2 KB, free 128.1 MB)
2016-06-13 14:04:58,249  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_331_piece0 stored as bytes in memory (estimated size 8.1 KB, free 128.1 MB)
2016-06-13 14:04:58,250  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_331_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,250  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 331 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:58,250  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 174 (MapPartitionsRDD[207] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,250  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 174.0 with 2 tasks
2016-06-13 14:04:58,250  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 174.0 (TID 331, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,250  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 174.0 (TID 332, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,251  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 174.0 (TID 331)
2016-06-13 14:04:58,251  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 174.0 (TID 332)
2016-06-13 14:04:58,253  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:58,253  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:58,255  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 174.0 (TID 331). 45217 bytes result sent to driver
2016-06-13 14:04:58,255  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 174.0 (TID 332). 45217 bytes result sent to driver
2016-06-13 14:04:58,255  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 174.0 (TID 331) in 5 ms on localhost (1/2)
2016-06-13 14:04:58,256  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 174.0 (TID 332) in 6 ms on localhost (2/2)
2016-06-13 14:04:58,256  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 174.0, whose tasks have all completed, from pool 
2016-06-13 14:04:58,256  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 174 (treeAggregate at RowMatrix.scala:93) finished in 0.006 s
2016-06-13 14:04:58,256  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 164 finished: treeAggregate at RowMatrix.scala:93, took 0.008953 s
2016-06-13 14:04:58,260  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_332 stored as values in memory (estimated size 124.9 KB, free 128.2 MB)
2016-06-13 14:04:58,261  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_332_piece0 stored as bytes in memory (estimated size 124.7 KB, free 128.4 MB)
2016-06-13 14:04:58,261  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_332_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,261  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 332 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:58,271  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:58,272  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 165 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:58,272  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 175 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,272  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:58,272  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:58,272  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 175 (MapPartitionsRDD[208] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:58,273  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_333 stored as values in memory (estimated size 55.2 KB, free 128.4 MB)
2016-06-13 14:04:58,274  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_333_piece0 stored as bytes in memory (estimated size 8.1 KB, free 128.4 MB)
2016-06-13 14:04:58,275  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_333_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,275  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 333 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:58,275  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 175 (MapPartitionsRDD[208] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,275  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 175.0 with 2 tasks
2016-06-13 14:04:58,275  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 175.0 (TID 333, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,276  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 175.0 (TID 334, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,276  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 175.0 (TID 333)
2016-06-13 14:04:58,276  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 175.0 (TID 334)
2016-06-13 14:04:58,278  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:58,278  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:58,279  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 175.0 (TID 334). 45217 bytes result sent to driver
2016-06-13 14:04:58,280  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 175.0 (TID 334) in 5 ms on localhost (1/2)
2016-06-13 14:04:58,280  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 175.0 (TID 333). 45217 bytes result sent to driver
2016-06-13 14:04:58,281  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 175.0 (TID 333) in 6 ms on localhost (2/2)
2016-06-13 14:04:58,281  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 175 (treeAggregate at RowMatrix.scala:93) finished in 0.006 s
2016-06-13 14:04:58,281  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 165 finished: treeAggregate at RowMatrix.scala:93, took 0.009922 s
2016-06-13 14:04:58,281  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 175.0, whose tasks have all completed, from pool 
2016-06-13 14:04:58,287  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_334 stored as values in memory (estimated size 124.9 KB, free 128.5 MB)
2016-06-13 14:04:58,289  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_334_piece0 stored as bytes in memory (estimated size 124.6 KB, free 128.7 MB)
2016-06-13 14:04:58,289  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_334_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:04:58,289  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 334 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:58,294  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:58,294  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 166 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:58,295  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 176 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,295  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:58,295  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:58,295  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 176 (MapPartitionsRDD[209] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:58,296  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_335 stored as values in memory (estimated size 55.2 KB, free 128.7 MB)
2016-06-13 14:04:58,297  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_335_piece0 stored as bytes in memory (estimated size 8.1 KB, free 128.7 MB)
2016-06-13 14:04:58,297  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_335_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,297  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 335 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:58,298  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 176 (MapPartitionsRDD[209] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,298  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 176.0 with 2 tasks
2016-06-13 14:04:58,298  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 176.0 (TID 335, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,298  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 176.0 (TID 336, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,298  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 176.0 (TID 336)
2016-06-13 14:04:58,298  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 176.0 (TID 335)
2016-06-13 14:04:58,300  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:58,301  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:58,302  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 176.0 (TID 335). 45217 bytes result sent to driver
2016-06-13 14:04:58,302  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 176.0 (TID 335) in 4 ms on localhost (1/2)
2016-06-13 14:04:58,305  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 176.0 (TID 336). 45217 bytes result sent to driver
2016-06-13 14:04:58,310  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 176.0 (TID 336) in 12 ms on localhost (2/2)
2016-06-13 14:04:58,311  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 176.0, whose tasks have all completed, from pool 
2016-06-13 14:04:58,311  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 176 (treeAggregate at RowMatrix.scala:93) finished in 0.013 s
2016-06-13 14:04:58,311  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 166 finished: treeAggregate at RowMatrix.scala:93, took 0.016920 s
2016-06-13 14:04:58,316  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_336 stored as values in memory (estimated size 124.9 KB, free 128.8 MB)
2016-06-13 14:04:58,317  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_336_piece0 stored as bytes in memory (estimated size 124.6 KB, free 129.0 MB)
2016-06-13 14:04:58,317  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_336_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:04:58,317  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 336 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:58,322  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:58,323  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 167 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:58,323  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 177 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,323  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:58,324  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:58,324  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 177 (MapPartitionsRDD[210] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:58,326  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_337 stored as values in memory (estimated size 55.2 KB, free 129.0 MB)
2016-06-13 14:04:58,327  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_337_piece0 stored as bytes in memory (estimated size 8.1 KB, free 129.0 MB)
2016-06-13 14:04:58,327  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_337_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,328  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 337 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:58,328  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 177 (MapPartitionsRDD[210] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,328  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 177.0 with 2 tasks
2016-06-13 14:04:58,329  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 177.0 (TID 337, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,329  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 177.0 (TID 338, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,329  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 177.0 (TID 338)
2016-06-13 14:04:58,329  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 177.0 (TID 337)
2016-06-13 14:04:58,331  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:58,332  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:58,334  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 177.0 (TID 338). 45217 bytes result sent to driver
2016-06-13 14:04:58,334  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 177.0 (TID 338) in 5 ms on localhost (1/2)
2016-06-13 14:04:58,335  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 177.0 (TID 337). 45217 bytes result sent to driver
2016-06-13 14:04:58,336  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 177.0 (TID 337) in 7 ms on localhost (2/2)
2016-06-13 14:04:58,336  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 177.0, whose tasks have all completed, from pool 
2016-06-13 14:04:58,338  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 177 (treeAggregate at RowMatrix.scala:93) finished in 0.009 s
2016-06-13 14:04:58,338  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 167 finished: treeAggregate at RowMatrix.scala:93, took 0.015858 s
2016-06-13 14:04:58,344  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_338 stored as values in memory (estimated size 124.9 KB, free 129.1 MB)
2016-06-13 14:04:58,345  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_338_piece0 stored as bytes in memory (estimated size 124.7 KB, free 129.3 MB)
2016-06-13 14:04:58,346  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_338_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,346  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 338 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:58,354  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:58,355  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 168 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:58,355  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 178 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,355  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:58,355  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:58,355  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 178 (MapPartitionsRDD[211] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:58,356  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_339 stored as values in memory (estimated size 55.2 KB, free 129.3 MB)
2016-06-13 14:04:58,358  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_339_piece0 stored as bytes in memory (estimated size 8.1 KB, free 129.3 MB)
2016-06-13 14:04:58,358  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_339_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,359  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 339 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:58,359  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 178 (MapPartitionsRDD[211] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,359  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 178.0 with 2 tasks
2016-06-13 14:04:58,360  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 178.0 (TID 339, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,360  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 178.0 (TID 340, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,360  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 178.0 (TID 340)
2016-06-13 14:04:58,362  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 178.0 (TID 339)
2016-06-13 14:04:58,362  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:58,365  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 178.0 (TID 340). 45217 bytes result sent to driver
2016-06-13 14:04:58,366  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 178.0 (TID 340) in 6 ms on localhost (1/2)
2016-06-13 14:04:58,368  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:58,371  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 178.0 (TID 339). 45217 bytes result sent to driver
2016-06-13 14:04:58,372  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 178.0 (TID 339) in 13 ms on localhost (2/2)
2016-06-13 14:04:58,372  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 178.0, whose tasks have all completed, from pool 
2016-06-13 14:04:58,372  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 178 (treeAggregate at RowMatrix.scala:93) finished in 0.007 s
2016-06-13 14:04:58,372  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 168 finished: treeAggregate at RowMatrix.scala:93, took 0.018158 s
2016-06-13 14:04:58,379  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_340 stored as values in memory (estimated size 124.9 KB, free 129.5 MB)
2016-06-13 14:04:58,381  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_340_piece0 stored as bytes in memory (estimated size 124.6 KB, free 129.6 MB)
2016-06-13 14:04:58,381  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_340_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:04:58,381  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 340 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:58,386  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:58,386  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 169 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:58,386  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 179 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,386  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:58,386  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:58,386  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 179 (MapPartitionsRDD[212] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:58,387  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_341 stored as values in memory (estimated size 55.2 KB, free 129.6 MB)
2016-06-13 14:04:58,388  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_341_piece0 stored as bytes in memory (estimated size 8.1 KB, free 129.6 MB)
2016-06-13 14:04:58,389  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_341_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,389  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 341 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:58,389  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 179 (MapPartitionsRDD[212] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,389  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 179.0 with 2 tasks
2016-06-13 14:04:58,389  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 179.0 (TID 341, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,390  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 179.0 (TID 342, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,390  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 179.0 (TID 342)
2016-06-13 14:04:58,390  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 179.0 (TID 341)
2016-06-13 14:04:58,392  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:58,392  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:58,395  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 179.0 (TID 342). 45217 bytes result sent to driver
2016-06-13 14:04:58,395  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 179.0 (TID 342) in 6 ms on localhost (1/2)
2016-06-13 14:04:58,396  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 179.0 (TID 341). 45217 bytes result sent to driver
2016-06-13 14:04:58,396  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 179.0 (TID 341) in 7 ms on localhost (2/2)
2016-06-13 14:04:58,397  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 179.0, whose tasks have all completed, from pool 
2016-06-13 14:04:58,397  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 179 (treeAggregate at RowMatrix.scala:93) finished in 0.008 s
2016-06-13 14:04:58,397  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 169 finished: treeAggregate at RowMatrix.scala:93, took 0.011368 s
2016-06-13 14:04:58,403  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_342 stored as values in memory (estimated size 124.9 KB, free 129.8 MB)
2016-06-13 14:04:58,404  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_342_piece0 stored as bytes in memory (estimated size 124.8 KB, free 129.9 MB)
2016-06-13 14:04:58,405  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_342_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,405  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 342 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:58,411  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:58,411  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 170 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:58,411  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 180 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,411  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:58,412  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:58,412  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 180 (MapPartitionsRDD[213] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:58,413  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_343 stored as values in memory (estimated size 55.2 KB, free 129.9 MB)
2016-06-13 14:04:58,414  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_343_piece0 stored as bytes in memory (estimated size 8.1 KB, free 129.9 MB)
2016-06-13 14:04:58,415  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_343_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,415  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 343 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:58,415  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 180 (MapPartitionsRDD[213] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,415  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 180.0 with 2 tasks
2016-06-13 14:04:58,416  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 180.0 (TID 343, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,416  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 180.0 (TID 344, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,416  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 180.0 (TID 343)
2016-06-13 14:04:58,416  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 180.0 (TID 344)
2016-06-13 14:04:58,418  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:58,421  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 180.0 (TID 344). 45217 bytes result sent to driver
2016-06-13 14:04:58,422  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 180.0 (TID 344) in 6 ms on localhost (1/2)
2016-06-13 14:04:58,423  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:58,425  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 180.0 (TID 343). 45217 bytes result sent to driver
2016-06-13 14:04:58,426  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 180.0 (TID 343) in 11 ms on localhost (2/2)
2016-06-13 14:04:58,426  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 180 (treeAggregate at RowMatrix.scala:93) finished in 0.011 s
2016-06-13 14:04:58,426  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 180.0, whose tasks have all completed, from pool 
2016-06-13 14:04:58,426  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 170 finished: treeAggregate at RowMatrix.scala:93, took 0.015183 s
2016-06-13 14:04:58,433  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_344 stored as values in memory (estimated size 124.9 KB, free 130.1 MB)
2016-06-13 14:04:58,436  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_344_piece0 stored as bytes in memory (estimated size 124.7 KB, free 130.2 MB)
2016-06-13 14:04:58,436  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_344_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,437  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 344 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:58,444  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:58,445  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 171 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:58,445  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 181 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,445  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:58,445  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:58,445  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 181 (MapPartitionsRDD[214] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:58,447  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_345 stored as values in memory (estimated size 55.2 KB, free 130.2 MB)
2016-06-13 14:04:58,449  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_345_piece0 stored as bytes in memory (estimated size 8.1 KB, free 130.2 MB)
2016-06-13 14:04:58,451  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_345_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,451  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 345 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:58,451  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 181 (MapPartitionsRDD[214] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,452  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 181.0 with 2 tasks
2016-06-13 14:04:58,452  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 181.0 (TID 345, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,452  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 181.0 (TID 346, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,452  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 181.0 (TID 345)
2016-06-13 14:04:58,454  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 181.0 (TID 346)
2016-06-13 14:04:58,455  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:58,456  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:58,457  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 181.0 (TID 345). 45217 bytes result sent to driver
2016-06-13 14:04:58,459  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 181.0 (TID 345) in 7 ms on localhost (1/2)
2016-06-13 14:04:58,460  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 181.0 (TID 346). 45217 bytes result sent to driver
2016-06-13 14:04:58,461  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 181.0 (TID 346) in 9 ms on localhost (2/2)
2016-06-13 14:04:58,461  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 181.0, whose tasks have all completed, from pool 
2016-06-13 14:04:58,461  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 181 (treeAggregate at RowMatrix.scala:93) finished in 0.009 s
2016-06-13 14:04:58,462  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 171 finished: treeAggregate at RowMatrix.scala:93, took 0.017098 s
2016-06-13 14:04:58,468  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_346 stored as values in memory (estimated size 124.9 KB, free 130.4 MB)
2016-06-13 14:04:58,471  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_346_piece0 stored as bytes in memory (estimated size 124.8 KB, free 130.5 MB)
2016-06-13 14:04:58,471  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_346_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,475  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 346 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:58,484  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:58,484  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 172 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:58,484  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 182 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,484  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:58,485  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:58,485  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 182 (MapPartitionsRDD[215] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:58,487  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_347 stored as values in memory (estimated size 55.2 KB, free 130.5 MB)
2016-06-13 14:04:58,488  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_347_piece0 stored as bytes in memory (estimated size 8.1 KB, free 130.6 MB)
2016-06-13 14:04:58,489  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_347_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,489  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 347 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:58,489  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 182 (MapPartitionsRDD[215] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,489  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 182.0 with 2 tasks
2016-06-13 14:04:58,490  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 182.0 (TID 347, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,490  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 182.0 (TID 348, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,490  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 182.0 (TID 347)
2016-06-13 14:04:58,491  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 182.0 (TID 348)
2016-06-13 14:04:58,493  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:58,493  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:58,496  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 182.0 (TID 347). 45217 bytes result sent to driver
2016-06-13 14:04:58,552  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 182.0 (TID 347) in 62 ms on localhost (1/2)
2016-06-13 14:04:58,554  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 182.0 (TID 348). 45217 bytes result sent to driver
2016-06-13 14:04:58,555  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 182.0 (TID 348) in 65 ms on localhost (2/2)
2016-06-13 14:04:58,555  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 182.0, whose tasks have all completed, from pool 
2016-06-13 14:04:58,555  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 182 (treeAggregate at RowMatrix.scala:93) finished in 0.065 s
2016-06-13 14:04:58,556  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 172 finished: treeAggregate at RowMatrix.scala:93, took 0.072043 s
2016-06-13 14:04:58,565  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_327_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,567  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_237_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,567  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 123
2016-06-13 14:04:58,568  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_236_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,569  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_235_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,570  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 122
2016-06-13 14:04:58,570  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_348 stored as values in memory (estimated size 124.9 KB, free 130.2 MB)
2016-06-13 14:04:58,571  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_234_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,572  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_233_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,572  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_348_piece0 stored as bytes in memory (estimated size 124.6 KB, free 130.1 MB)
2016-06-13 14:04:58,572  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_348_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:04:58,573  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 121
2016-06-13 14:04:58,574  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 348 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:58,574  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_232_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,575  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_231_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,575  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 120
2016-06-13 14:04:58,576  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_230_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,577  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_229_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,578  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 119
2016-06-13 14:04:58,579  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_228_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,580  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_227_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,580  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 118
2016-06-13 14:04:58,581  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_226_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,582  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_225_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,583  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 117
2016-06-13 14:04:58,584  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_224_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,585  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_223_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,586  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 116
2016-06-13 14:04:58,587  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_222_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,588  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_221_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,589  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 115
2016-06-13 14:04:58,589  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_220_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,590  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_219_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,591  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 114
2016-06-13 14:04:58,592  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_218_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,592  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:58,593  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_217_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,593  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 173 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:58,593  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 183 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,593  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:58,593  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:58,594  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 113
2016-06-13 14:04:58,594  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 183 (MapPartitionsRDD[216] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:58,594  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_216_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,595  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_349 stored as values in memory (estimated size 55.2 KB, free 127.4 MB)
2016-06-13 14:04:58,597  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_215_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,597  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_349_piece0 stored as bytes in memory (estimated size 8.1 KB, free 127.4 MB)
2016-06-13 14:04:58,597  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_349_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,598  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 349 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:58,598  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 183 (MapPartitionsRDD[216] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,598  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 183.0 with 2 tasks
2016-06-13 14:04:58,599  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 183.0 (TID 349, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,599  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 183.0 (TID 350, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,599  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 183.0 (TID 349)
2016-06-13 14:04:58,601  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:58,602  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 183.0 (TID 350)
2016-06-13 14:04:58,605  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:58,608  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 183.0 (TID 350). 45217 bytes result sent to driver
2016-06-13 14:04:58,609  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 183.0 (TID 350) in 10 ms on localhost (1/2)
2016-06-13 14:04:58,610  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 183.0 (TID 349). 45217 bytes result sent to driver
2016-06-13 14:04:58,611  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 183.0 (TID 349) in 13 ms on localhost (2/2)
2016-06-13 14:04:58,611  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 183.0, whose tasks have all completed, from pool 
2016-06-13 14:04:58,612  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 183 (treeAggregate at RowMatrix.scala:93) finished in 0.014 s
2016-06-13 14:04:58,612  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 173 finished: treeAggregate at RowMatrix.scala:93, took 0.020268 s
2016-06-13 14:04:58,612  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 112
2016-06-13 14:04:58,613  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_214_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,614  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_213_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,615  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 111
2016-06-13 14:04:58,616  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_212_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,617  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_211_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,617  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 110
2016-06-13 14:04:58,618  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_210_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,619  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_209_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,620  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 109
2016-06-13 14:04:58,620  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_350 stored as values in memory (estimated size 124.9 KB, free 126.6 MB)
2016-06-13 14:04:58,621  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_208_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,621  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_350_piece0 stored as bytes in memory (estimated size 124.6 KB, free 126.5 MB)
2016-06-13 14:04:58,622  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_350_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:04:58,622  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_207_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,623  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 108
2016-06-13 14:04:58,623  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_206_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,624  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_205_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,625  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 107
2016-06-13 14:04:58,626  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_204_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,627  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_203_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,628  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 106
2016-06-13 14:04:58,629  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_202_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,630  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_201_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,630  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 105
2016-06-13 14:04:58,631  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_200_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,633  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_199_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,633  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 104
2016-06-13 14:04:58,634  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_198_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,634  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 350 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:58,635  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_197_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,636  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 103
2016-06-13 14:04:58,637  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_196_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,638  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_195_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,638  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 102
2016-06-13 14:04:58,639  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_194_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,640  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_193_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,641  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 101
2016-06-13 14:04:58,641  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_192_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,642  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_191_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,643  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 100
2016-06-13 14:04:58,643  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_190_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,645  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_189_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,645  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 99
2016-06-13 14:04:58,646  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_188_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,647  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_187_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,647  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 98
2016-06-13 14:04:58,648  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_186_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,649  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_185_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,650  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 97
2016-06-13 14:04:58,650  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_184_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,651  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:58,651  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_183_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,652  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 96
2016-06-13 14:04:58,652  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 174 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:58,652  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 184 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,652  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:58,652  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:58,652  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_182_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,653  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 184 (MapPartitionsRDD[217] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:58,654  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_181_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,654  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_351 stored as values in memory (estimated size 55.2 KB, free 122.5 MB)
2016-06-13 14:04:58,654  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 95
2016-06-13 14:04:58,655  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_180_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,655  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_351_piece0 stored as bytes in memory (estimated size 8.1 KB, free 122.4 MB)
2016-06-13 14:04:58,655  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_351_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,656  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 351 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:58,656  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 184 (MapPartitionsRDD[217] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,656  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 184.0 with 2 tasks
2016-06-13 14:04:58,656  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_179_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,656  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 94
2016-06-13 14:04:58,656  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 184.0 (TID 351, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,656  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 184.0 (TID 352, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,657  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 184.0 (TID 351)
2016-06-13 14:04:58,659  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:58,661  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_178_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,662  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 184.0 (TID 351). 45217 bytes result sent to driver
2016-06-13 14:04:58,662  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 184.0 (TID 352)
2016-06-13 14:04:58,665  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:58,667  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 184.0 (TID 351) in 11 ms on localhost (1/2)
2016-06-13 14:04:58,668  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_177_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,669  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 93
2016-06-13 14:04:58,669  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_176_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,669  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 184.0 (TID 352). 45217 bytes result sent to driver
2016-06-13 14:04:58,670  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 184.0 (TID 352) in 14 ms on localhost (2/2)
2016-06-13 14:04:58,670  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 184 (treeAggregate at RowMatrix.scala:93) finished in 0.014 s
2016-06-13 14:04:58,670  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 184.0, whose tasks have all completed, from pool 
2016-06-13 14:04:58,671  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_175_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,671  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 174 finished: treeAggregate at RowMatrix.scala:93, took 0.019551 s
2016-06-13 14:04:58,671  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 92
2016-06-13 14:04:58,672  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_174_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,673  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_173_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,673  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 91
2016-06-13 14:04:58,674  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_172_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,675  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_171_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,675  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 90
2016-06-13 14:04:58,676  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_170_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,677  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_169_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,678  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 89
2016-06-13 14:04:58,678  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_168_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,679  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_167_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,679  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 88
2016-06-13 14:04:58,683  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_352 stored as values in memory (estimated size 124.9 KB, free 120.5 MB)
2016-06-13 14:04:58,684  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_166_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,686  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_165_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,686  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 87
2016-06-13 14:04:58,686  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_164_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,687  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_352_piece0 stored as bytes in memory (estimated size 124.7 KB, free 120.0 MB)
2016-06-13 14:04:58,688  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_352_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,688  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 352 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:58,688  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_163_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,696  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 86
2016-06-13 14:04:58,696  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:58,697  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 175 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:58,697  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 185 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,697  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:58,706  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_162_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,707  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:58,707  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 185 (MapPartitionsRDD[218] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:58,708  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_353 stored as values in memory (estimated size 55.2 KB, free 119.8 MB)
2016-06-13 14:04:58,709  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_353_piece0 stored as bytes in memory (estimated size 8.1 KB, free 119.8 MB)
2016-06-13 14:04:58,710  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_353_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,710  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_161_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,711  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 85
2016-06-13 14:04:58,711  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 353 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:58,711  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 185 (MapPartitionsRDD[218] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,711  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 185.0 with 2 tasks
2016-06-13 14:04:58,712  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 185.0 (TID 353, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,712  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 185.0 (TID 354, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,712  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 185.0 (TID 354)
2016-06-13 14:04:58,712  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_160_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,712  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 185.0 (TID 353)
2016-06-13 14:04:58,714  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_159_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,714  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 84
2016-06-13 14:04:58,714  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:58,715  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_158_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,718  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:58,719  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_157_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,719  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 83
2016-06-13 14:04:58,720  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_156_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,721  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 185.0 (TID 353). 45217 bytes result sent to driver
2016-06-13 14:04:58,721  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 185.0 (TID 354). 45217 bytes result sent to driver
2016-06-13 14:04:58,722  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 185.0 (TID 353) in 11 ms on localhost (1/2)
2016-06-13 14:04:58,722  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 185.0 (TID 354) in 10 ms on localhost (2/2)
2016-06-13 14:04:58,722  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 185.0, whose tasks have all completed, from pool 
2016-06-13 14:04:58,722  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 185 (treeAggregate at RowMatrix.scala:93) finished in 0.011 s
2016-06-13 14:04:58,722  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_155_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,724  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 82
2016-06-13 14:04:58,724  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 175 finished: treeAggregate at RowMatrix.scala:93, took 0.028084 s
2016-06-13 14:04:58,724  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_154_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:58,725  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_153_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,726  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 81
2016-06-13 14:04:58,726  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_152_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,727  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_151_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,728  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 80
2016-06-13 14:04:58,728  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_150_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:58,729  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_149_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,729  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 79
2016-06-13 14:04:58,730  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_148_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,731  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_147_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,731  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 78
2016-06-13 14:04:58,731  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_354 stored as values in memory (estimated size 124.9 KB, free 117.7 MB)
2016-06-13 14:04:58,732  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_146_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,733  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_354_piece0 stored as bytes in memory (estimated size 124.6 KB, free 117.6 MB)
2016-06-13 14:04:58,733  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_145_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,734  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 77
2016-06-13 14:04:58,734  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_354_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:04:58,735  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_144_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,735  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 354 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:58,736  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_143_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,736  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 76
2016-06-13 14:04:58,737  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_142_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,738  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_141_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,738  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 75
2016-06-13 14:04:58,739  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_140_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,739  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_139_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,740  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 74
2016-06-13 14:04:58,740  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_138_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,741  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_137_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,741  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 73
2016-06-13 14:04:58,742  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_136_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,743  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_135_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,743  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 72
2016-06-13 14:04:58,743  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_134_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:58,744  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_133_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,744  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 71
2016-06-13 14:04:58,745  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_132_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,746  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_131_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,746  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 70
2016-06-13 14:04:58,747  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_130_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:58,747  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_129_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,748  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 69
2016-06-13 14:04:58,748  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_128_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,749  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_127_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,749  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 68
2016-06-13 14:04:58,750  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_126_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,751  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_125_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,751  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 67
2016-06-13 14:04:58,752  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:58,752  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_124_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,753  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_123_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,753  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 66
2016-06-13 14:04:58,754  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 176 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:58,754  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 186 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,754  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:58,754  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_122_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,764  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:58,764  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 186 (MapPartitionsRDD[219] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:58,766  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_355 stored as values in memory (estimated size 55.2 KB, free 114.0 MB)
2016-06-13 14:04:58,767  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_355_piece0 stored as bytes in memory (estimated size 8.1 KB, free 114.0 MB)
2016-06-13 14:04:58,768  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_355_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,768  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_121_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,769  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 65
2016-06-13 14:04:58,771  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_120_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:58,768  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 355 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:58,772  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_119_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,772  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 186 (MapPartitionsRDD[219] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,772  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 186.0 with 2 tasks
2016-06-13 14:04:58,772  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 64
2016-06-13 14:04:58,773  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 186.0 (TID 355, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,773  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 186.0 (TID 356, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,773  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 186.0 (TID 355)
2016-06-13 14:04:58,773  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_118_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:58,774  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_117_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,775  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 63
2016-06-13 14:04:58,775  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:58,776  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_116_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:58,776  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_115_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,777  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 186.0 (TID 356)
2016-06-13 14:04:58,777  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 62
2016-06-13 14:04:58,779  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:58,782  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_114_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,782  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_113_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,783  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 61
2016-06-13 14:04:58,783  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_112_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:58,784  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_111_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,785  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 60
2016-06-13 14:04:58,785  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_110_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:58,786  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 186.0 (TID 355). 45217 bytes result sent to driver
2016-06-13 14:04:58,788  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 186.0 (TID 355) in 16 ms on localhost (1/2)
2016-06-13 14:04:58,787  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 186.0 (TID 356). 45217 bytes result sent to driver
2016-06-13 14:04:58,786  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_109_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,789  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 59
2016-06-13 14:04:58,790  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 186.0 (TID 356) in 16 ms on localhost (2/2)
2016-06-13 14:04:58,790  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 186.0, whose tasks have all completed, from pool 
2016-06-13 14:04:58,790  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_108_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:58,790  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 186 (treeAggregate at RowMatrix.scala:93) finished in 0.018 s
2016-06-13 14:04:58,790  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 176 finished: treeAggregate at RowMatrix.scala:93, took 0.037952 s
2016-06-13 14:04:58,790  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_107_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,791  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 58
2016-06-13 14:04:58,791  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_106_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,792  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_105_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,792  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 57
2016-06-13 14:04:58,793  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_104_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:58,794  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_103_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,794  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 56
2016-06-13 14:04:58,795  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_102_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:58,796  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_101_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,796  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 55
2016-06-13 14:04:58,797  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_356 stored as values in memory (estimated size 124.9 KB, free 111.0 MB)
2016-06-13 14:04:58,797  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_100_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:58,797  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_99_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,798  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 54
2016-06-13 14:04:58,799  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_98_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:58,799  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_97_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,799  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_356_piece0 stored as bytes in memory (estimated size 124.6 KB, free 110.5 MB)
2016-06-13 14:04:58,800  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_356_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:04:58,800  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 53
2016-06-13 14:04:58,800  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_96_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:58,801  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 356 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:58,801  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_95_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,801  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 52
2016-06-13 14:04:58,802  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_94_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:58,803  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_93_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,803  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 51
2016-06-13 14:04:58,804  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_92_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,805  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_91_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,805  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 50
2016-06-13 14:04:58,805  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_90_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:58,806  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_89_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,806  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 49
2016-06-13 14:04:58,807  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_88_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:58,807  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_87_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,808  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 48
2016-06-13 14:04:58,808  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_86_piece0 on localhost:44356 in memory (size: 125.0 KB, free: 9.7 GB)
2016-06-13 14:04:58,809  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_289_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,809  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 149
2016-06-13 14:04:58,810  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_288_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,810  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_287_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,811  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 148
2016-06-13 14:04:58,811  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_286_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,812  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_285_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,813  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 147
2016-06-13 14:04:58,813  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_284_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,814  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_283_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,815  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 146
2016-06-13 14:04:58,815  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_282_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,816  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_281_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,816  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 145
2016-06-13 14:04:58,817  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_280_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,817  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_279_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,818  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 144
2016-06-13 14:04:58,818  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_278_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,819  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_277_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,819  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:58,819  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 143
2016-06-13 14:04:58,820  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_276_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,820  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 177 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:58,820  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 187 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,820  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:58,820  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:58,820  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 187 (MapPartitionsRDD[220] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:58,821  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_275_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,821  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 142
2016-06-13 14:04:58,822  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_357 stored as values in memory (estimated size 55.2 KB, free 106.6 MB)
2016-06-13 14:04:58,823  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_357_piece0 stored as bytes in memory (estimated size 8.1 KB, free 106.6 MB)
2016-06-13 14:04:58,837  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_357_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,838  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_274_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,838  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 357 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:58,838  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 187 (MapPartitionsRDD[220] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,838  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 187.0 with 2 tasks
2016-06-13 14:04:58,839  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_273_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,839  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 187.0 (TID 357, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,839  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 187.0 (TID 358, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,839  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 187.0 (TID 357)
2016-06-13 14:04:58,841  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 187.0 (TID 358)
2016-06-13 14:04:58,842  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:58,843  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:58,844  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 187.0 (TID 357). 45217 bytes result sent to driver
2016-06-13 14:04:58,845  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 187.0 (TID 358). 45217 bytes result sent to driver
2016-06-13 14:04:58,846  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 187.0 (TID 357) in 7 ms on localhost (1/2)
2016-06-13 14:04:58,847  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 187.0 (TID 358) in 8 ms on localhost (2/2)
2016-06-13 14:04:58,847  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 187.0, whose tasks have all completed, from pool 
2016-06-13 14:04:58,847  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 141
2016-06-13 14:04:58,848  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_272_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,848  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_271_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,849  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 187 (treeAggregate at RowMatrix.scala:93) finished in 0.011 s
2016-06-13 14:04:58,849  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 140
2016-06-13 14:04:58,849  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 177 finished: treeAggregate at RowMatrix.scala:93, took 0.029642 s
2016-06-13 14:04:58,849  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_270_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,850  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_269_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,852  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 139
2016-06-13 14:04:58,852  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_268_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,853  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_267_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,854  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 138
2016-06-13 14:04:58,854  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_266_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,858  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_265_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,859  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 137
2016-06-13 14:04:58,859  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_264_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,860  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_263_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,860  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 136
2016-06-13 14:04:58,861  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_262_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,862  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_261_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,862  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 135
2016-06-13 14:04:58,863  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_260_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,863  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_259_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,864  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 134
2016-06-13 14:04:58,868  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_258_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,868  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_257_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,869  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 133
2016-06-13 14:04:58,869  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_256_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,870  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_255_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,870  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 132
2016-06-13 14:04:58,871  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_254_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,872  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_253_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,872  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 131
2016-06-13 14:04:58,873  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_252_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,873  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_251_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,874  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 130
2016-06-13 14:04:58,874  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_250_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,875  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_249_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,875  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_358 stored as values in memory (estimated size 124.9 KB, free 102.7 MB)
2016-06-13 14:04:58,875  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 129
2016-06-13 14:04:58,876  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_248_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,877  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_247_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,877  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 128
2016-06-13 14:04:58,878  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_246_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,879  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_245_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,879  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 127
2016-06-13 14:04:58,880  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_244_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,880  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_243_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,881  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 126
2016-06-13 14:04:58,881  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_242_piece0 on localhost:44356 in memory (size: 124.9 KB, free: 9.7 GB)
2016-06-13 14:04:58,882  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_241_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,882  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 125
2016-06-13 14:04:58,883  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_240_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,883  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_239_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,884  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 124
2016-06-13 14:04:58,884  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_238_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,885  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_345_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,885  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 177
2016-06-13 14:04:58,886  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_344_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,887  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_343_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,887  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 176
2016-06-13 14:04:58,887  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_342_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,887  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_358_piece0 stored as bytes in memory (estimated size 124.6 KB, free 100.6 MB)
2016-06-13 14:04:58,888  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_358_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:04:58,888  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_341_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,889  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 175
2016-06-13 14:04:58,889  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_340_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:04:58,890  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_339_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,890  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 174
2016-06-13 14:04:58,891  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_338_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,892  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_337_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,892  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 173
2016-06-13 14:04:58,893  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_336_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:04:58,893  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_335_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,894  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 172
2016-06-13 14:04:58,894  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_334_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:04:58,895  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_333_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,895  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 171
2016-06-13 14:04:58,896  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_332_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,897  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_331_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,897  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 170
2016-06-13 14:04:58,898  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_330_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,899  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_329_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,899  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 169
2016-06-13 14:04:58,899  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_328_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,900  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 168
2016-06-13 14:04:58,900  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_326_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:04:58,901  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_325_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,901  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 167
2016-06-13 14:04:58,901  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_324_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,902  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_323_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,902  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 166
2016-06-13 14:04:58,902  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_322_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,903  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_321_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,903  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 165
2016-06-13 14:04:58,904  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_320_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,905  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_319_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,905  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 164
2016-06-13 14:04:58,906  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_318_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,907  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_317_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,907  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 163
2016-06-13 14:04:58,907  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_316_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,908  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_315_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,909  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 162
2016-06-13 14:04:58,909  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_314_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,910  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_313_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,911  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 161
2016-06-13 14:04:58,911  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_312_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,912  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_311_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,912  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 160
2016-06-13 14:04:58,913  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_310_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,914  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_309_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,914  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 159
2016-06-13 14:04:58,915  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_308_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,916  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_307_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,916  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 158
2016-06-13 14:04:58,917  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_306_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,919  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 358 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:58,926  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:58,926  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 178 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:58,926  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 188 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,926  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:58,927  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:58,927  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 188 (MapPartitionsRDD[221] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:58,928  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_359 stored as values in memory (estimated size 55.2 KB, free 95.1 MB)
2016-06-13 14:04:58,929  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_359_piece0 stored as bytes in memory (estimated size 8.1 KB, free 95.1 MB)
2016-06-13 14:04:58,929  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_359_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,930  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 359 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:58,930  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 188 (MapPartitionsRDD[221] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,930  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 188.0 with 2 tasks
2016-06-13 14:04:58,930  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 188.0 (TID 359, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,931  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 188.0 (TID 360, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:58,931  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 188.0 (TID 359)
2016-06-13 14:04:58,933  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:58,931  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 188.0 (TID 360)
2016-06-13 14:04:58,938  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 188.0 (TID 359). 45217 bytes result sent to driver
2016-06-13 14:04:58,939  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_305_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,939  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:58,939  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 157
2016-06-13 14:04:58,940  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 188.0 (TID 359) in 10 ms on localhost (1/2)
2016-06-13 14:04:58,941  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 188.0 (TID 360). 45217 bytes result sent to driver
2016-06-13 14:04:58,941  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_304_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,942  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 188.0 (TID 360) in 12 ms on localhost (2/2)
2016-06-13 14:04:58,942  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 188 (treeAggregate at RowMatrix.scala:93) finished in 0.012 s
2016-06-13 14:04:58,942  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 188.0, whose tasks have all completed, from pool 
2016-06-13 14:04:58,942  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 178 finished: treeAggregate at RowMatrix.scala:93, took 0.016559 s
2016-06-13 14:04:58,943  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_303_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,943  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 156
2016-06-13 14:04:58,944  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_302_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,944  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_301_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,945  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 155
2016-06-13 14:04:58,945  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_300_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,946  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_299_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,946  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 154
2016-06-13 14:04:58,946  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_298_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,947  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_297_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,947  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 153
2016-06-13 14:04:58,948  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_296_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,948  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_295_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,949  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 152
2016-06-13 14:04:58,949  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_294_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:58,950  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_293_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,950  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 151
2016-06-13 14:04:58,951  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_292_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,951  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_291_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:58,952  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 150
2016-06-13 14:04:58,952  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_290_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:58,957  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_360 stored as values in memory (estimated size 124.9 KB, free 92.8 MB)
2016-06-13 14:04:58,981  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_360_piece0 stored as bytes in memory (estimated size 124.6 KB, free 92.9 MB)
2016-06-13 14:04:58,981  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_360_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:04:58,982  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 360 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:58,990  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:58,997  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 179 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:58,997  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 189 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:58,997  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:58,997  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:58,997  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 189 (MapPartitionsRDD[222] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:58,999  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_361 stored as values in memory (estimated size 55.2 KB, free 92.9 MB)
2016-06-13 14:04:59,000  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_361_piece0 stored as bytes in memory (estimated size 8.1 KB, free 93.0 MB)
2016-06-13 14:04:59,000  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_361_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:59,001  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 361 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:59,001  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 189 (MapPartitionsRDD[222] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,001  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 189.0 with 2 tasks
2016-06-13 14:04:59,001  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 189.0 (TID 361, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,001  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 189.0 (TID 362, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,002  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 189.0 (TID 361)
2016-06-13 14:04:59,002  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 189.0 (TID 362)
2016-06-13 14:04:59,004  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:59,008  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:59,011  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 189.0 (TID 361). 45217 bytes result sent to driver
2016-06-13 14:04:59,012  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 189.0 (TID 362). 45217 bytes result sent to driver
2016-06-13 14:04:59,013  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 189.0 (TID 361) in 12 ms on localhost (1/2)
2016-06-13 14:04:59,014  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 189.0 (TID 362) in 13 ms on localhost (2/2)
2016-06-13 14:04:59,014  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 189.0, whose tasks have all completed, from pool 
2016-06-13 14:04:59,014  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 189 (treeAggregate at RowMatrix.scala:93) finished in 0.004 s
2016-06-13 14:04:59,015  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 179 finished: treeAggregate at RowMatrix.scala:93, took 0.018396 s
2016-06-13 14:04:59,022  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_362 stored as values in memory (estimated size 124.9 KB, free 93.1 MB)
2016-06-13 14:04:59,023  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_362_piece0 stored as bytes in memory (estimated size 124.7 KB, free 93.2 MB)
2016-06-13 14:04:59,024  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_362_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:59,024  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 362 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:59,033  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:59,033  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 180 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:59,033  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 190 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,033  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:59,034  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:59,034  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 190 (MapPartitionsRDD[223] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:59,035  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_363 stored as values in memory (estimated size 55.2 KB, free 93.3 MB)
2016-06-13 14:04:59,036  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_363_piece0 stored as bytes in memory (estimated size 8.1 KB, free 93.3 MB)
2016-06-13 14:04:59,037  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_363_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:59,037  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 363 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:59,037  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 190 (MapPartitionsRDD[223] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,037  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 190.0 with 2 tasks
2016-06-13 14:04:59,038  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 190.0 (TID 363, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,038  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 190.0 (TID 364, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,038  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 190.0 (TID 363)
2016-06-13 14:04:59,038  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 190.0 (TID 364)
2016-06-13 14:04:59,041  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:59,044  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:59,048  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 190.0 (TID 363). 45217 bytes result sent to driver
2016-06-13 14:04:59,048  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 190.0 (TID 364). 45217 bytes result sent to driver
2016-06-13 14:04:59,054  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 190.0 (TID 364) in 16 ms on localhost (1/2)
2016-06-13 14:04:59,054  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 190.0 (TID 363) in 16 ms on localhost (2/2)
2016-06-13 14:04:59,055  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 190 (treeAggregate at RowMatrix.scala:93) finished in 0.007 s
2016-06-13 14:04:59,055  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 190.0, whose tasks have all completed, from pool 
2016-06-13 14:04:59,055  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 180 finished: treeAggregate at RowMatrix.scala:93, took 0.021748 s
2016-06-13 14:04:59,061  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_364 stored as values in memory (estimated size 124.9 KB, free 93.4 MB)
2016-06-13 14:04:59,064  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_364_piece0 stored as bytes in memory (estimated size 124.6 KB, free 93.5 MB)
2016-06-13 14:04:59,068  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_364_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:04:59,068  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 364 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:59,075  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:59,075  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 181 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:59,076  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 191 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,076  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:59,076  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:59,076  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 191 (MapPartitionsRDD[224] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:59,078  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_365 stored as values in memory (estimated size 55.2 KB, free 93.6 MB)
2016-06-13 14:04:59,079  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_365_piece0 stored as bytes in memory (estimated size 8.1 KB, free 93.6 MB)
2016-06-13 14:04:59,079  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_365_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:59,079  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 365 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:59,080  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 191 (MapPartitionsRDD[224] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,080  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 191.0 with 2 tasks
2016-06-13 14:04:59,080  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 191.0 (TID 365, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,080  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 191.0 (TID 366, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,081  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 191.0 (TID 365)
2016-06-13 14:04:59,081  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 191.0 (TID 366)
2016-06-13 14:04:59,083  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:59,087  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 191.0 (TID 366). 45217 bytes result sent to driver
2016-06-13 14:04:59,087  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:59,090  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 191.0 (TID 365). 45217 bytes result sent to driver
2016-06-13 14:04:59,091  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 191.0 (TID 366) in 11 ms on localhost (1/2)
2016-06-13 14:04:59,091  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 191.0 (TID 365) in 11 ms on localhost (2/2)
2016-06-13 14:04:59,091  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 191.0, whose tasks have all completed, from pool 
2016-06-13 14:04:59,092  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 191 (treeAggregate at RowMatrix.scala:93) finished in 0.005 s
2016-06-13 14:04:59,092  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 181 finished: treeAggregate at RowMatrix.scala:93, took 0.017093 s
2016-06-13 14:04:59,099  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_366 stored as values in memory (estimated size 124.9 KB, free 93.7 MB)
2016-06-13 14:04:59,101  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_366_piece0 stored as bytes in memory (estimated size 124.7 KB, free 93.8 MB)
2016-06-13 14:04:59,101  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_366_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:59,102  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 366 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:59,109  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:59,109  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 182 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:59,109  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 192 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,109  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:59,110  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:59,110  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 192 (MapPartitionsRDD[225] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:59,111  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_367 stored as values in memory (estimated size 55.2 KB, free 93.9 MB)
2016-06-13 14:04:59,112  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_367_piece0 stored as bytes in memory (estimated size 8.1 KB, free 93.9 MB)
2016-06-13 14:04:59,113  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_367_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:59,113  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 367 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:59,113  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 192 (MapPartitionsRDD[225] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,114  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 192.0 with 2 tasks
2016-06-13 14:04:59,114  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 192.0 (TID 367, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,114  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 192.0 (TID 368, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,114  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 192.0 (TID 367)
2016-06-13 14:04:59,115  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 192.0 (TID 368)
2016-06-13 14:04:59,118  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:59,118  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:59,120  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 192.0 (TID 368). 45217 bytes result sent to driver
2016-06-13 14:04:59,121  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 192.0 (TID 367). 45217 bytes result sent to driver
2016-06-13 14:04:59,121  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 192.0 (TID 368) in 7 ms on localhost (1/2)
2016-06-13 14:04:59,122  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 192.0 (TID 367) in 7 ms on localhost (2/2)
2016-06-13 14:04:59,122  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 192 (treeAggregate at RowMatrix.scala:93) finished in 0.007 s
2016-06-13 14:04:59,122  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 192.0, whose tasks have all completed, from pool 
2016-06-13 14:04:59,122  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 182 finished: treeAggregate at RowMatrix.scala:93, took 0.012698 s
2016-06-13 14:04:59,128  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_368 stored as values in memory (estimated size 124.9 KB, free 94.0 MB)
2016-06-13 14:04:59,130  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_368_piece0 stored as bytes in memory (estimated size 124.6 KB, free 94.1 MB)
2016-06-13 14:04:59,130  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_368_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:04:59,131  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 368 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:59,139  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:59,139  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 183 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:59,139  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 193 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,139  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:59,140  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:59,140  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 193 (MapPartitionsRDD[226] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:59,141  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_369 stored as values in memory (estimated size 55.2 KB, free 94.2 MB)
2016-06-13 14:04:59,143  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_369_piece0 stored as bytes in memory (estimated size 8.1 KB, free 94.2 MB)
2016-06-13 14:04:59,143  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_369_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:59,143  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 369 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:59,143  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 193 (MapPartitionsRDD[226] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,144  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 193.0 with 2 tasks
2016-06-13 14:04:59,144  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 193.0 (TID 369, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,144  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 193.0 (TID 370, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,144  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 193.0 (TID 369)
2016-06-13 14:04:59,145  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 193.0 (TID 370)
2016-06-13 14:04:59,147  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:59,147  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:59,149  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 193.0 (TID 370). 45217 bytes result sent to driver
2016-06-13 14:04:59,150  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 193.0 (TID 370) in 6 ms on localhost (1/2)
2016-06-13 14:04:59,150  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 193.0 (TID 369). 45217 bytes result sent to driver
2016-06-13 14:04:59,151  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 193.0 (TID 369) in 7 ms on localhost (2/2)
2016-06-13 14:04:59,151  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 193.0, whose tasks have all completed, from pool 
2016-06-13 14:04:59,151  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 193 (treeAggregate at RowMatrix.scala:93) finished in 0.007 s
2016-06-13 14:04:59,151  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 183 finished: treeAggregate at RowMatrix.scala:93, took 0.012119 s
2016-06-13 14:04:59,156  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_370 stored as values in memory (estimated size 124.9 KB, free 94.3 MB)
2016-06-13 14:04:59,157  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_370_piece0 stored as bytes in memory (estimated size 124.6 KB, free 94.4 MB)
2016-06-13 14:04:59,157  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_370_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:04:59,158  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 370 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:59,162  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:59,162  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 184 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:59,162  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 194 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,163  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:59,163  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:59,163  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 194 (MapPartitionsRDD[227] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:59,164  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_371 stored as values in memory (estimated size 55.2 KB, free 94.5 MB)
2016-06-13 14:04:59,165  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_371_piece0 stored as bytes in memory (estimated size 8.1 KB, free 94.5 MB)
2016-06-13 14:04:59,165  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_371_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:59,166  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 371 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:59,166  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 194 (MapPartitionsRDD[227] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,166  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 194.0 with 2 tasks
2016-06-13 14:04:59,166  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 194.0 (TID 371, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,167  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 194.0 (TID 372, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,167  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 194.0 (TID 371)
2016-06-13 14:04:59,167  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 194.0 (TID 372)
2016-06-13 14:04:59,169  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:59,172  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 194.0 (TID 371). 45217 bytes result sent to driver
2016-06-13 14:04:59,172  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 194.0 (TID 371) in 6 ms on localhost (1/2)
2016-06-13 14:04:59,172  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:59,175  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 194.0 (TID 372). 45217 bytes result sent to driver
2016-06-13 14:04:59,175  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 194.0 (TID 372) in 9 ms on localhost (2/2)
2016-06-13 14:04:59,175  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 194.0, whose tasks have all completed, from pool 
2016-06-13 14:04:59,176  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 194 (treeAggregate at RowMatrix.scala:93) finished in 0.008 s
2016-06-13 14:04:59,176  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 184 finished: treeAggregate at RowMatrix.scala:93, took 0.013503 s
2016-06-13 14:04:59,180  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_372 stored as values in memory (estimated size 124.9 KB, free 94.6 MB)
2016-06-13 14:04:59,181  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_372_piece0 stored as bytes in memory (estimated size 124.6 KB, free 94.7 MB)
2016-06-13 14:04:59,181  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_372_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:04:59,182  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 372 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:59,189  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:59,190  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 185 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:59,190  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 195 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,190  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:59,191  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:59,191  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 195 (MapPartitionsRDD[228] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:59,192  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_373 stored as values in memory (estimated size 55.2 KB, free 94.8 MB)
2016-06-13 14:04:59,193  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_373_piece0 stored as bytes in memory (estimated size 8.1 KB, free 94.8 MB)
2016-06-13 14:04:59,194  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_373_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:59,194  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 373 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:59,194  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 195 (MapPartitionsRDD[228] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,194  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 195.0 with 2 tasks
2016-06-13 14:04:59,194  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 195.0 (TID 373, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,194  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 195.0 (TID 374, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,195  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 195.0 (TID 373)
2016-06-13 14:04:59,196  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:59,198  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 195.0 (TID 374)
2016-06-13 14:04:59,198  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 195.0 (TID 373). 45217 bytes result sent to driver
2016-06-13 14:04:59,199  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 195.0 (TID 373) in 4 ms on localhost (1/2)
2016-06-13 14:04:59,201  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:59,202  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 195.0 (TID 374). 45217 bytes result sent to driver
2016-06-13 14:04:59,203  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 195.0 (TID 374) in 9 ms on localhost (2/2)
2016-06-13 14:04:59,203  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 195.0, whose tasks have all completed, from pool 
2016-06-13 14:04:59,203  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 195 (treeAggregate at RowMatrix.scala:93) finished in 0.009 s
2016-06-13 14:04:59,203  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 185 finished: treeAggregate at RowMatrix.scala:93, took 0.013886 s
2016-06-13 14:04:59,209  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_374 stored as values in memory (estimated size 124.9 KB, free 94.9 MB)
2016-06-13 14:04:59,210  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_374_piece0 stored as bytes in memory (estimated size 124.6 KB, free 95.0 MB)
2016-06-13 14:04:59,211  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_374_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:04:59,211  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 374 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:59,215  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:59,215  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 186 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:59,215  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 196 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,215  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:59,215  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:59,217  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 196 (MapPartitionsRDD[229] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:59,218  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_375 stored as values in memory (estimated size 55.2 KB, free 95.1 MB)
2016-06-13 14:04:59,219  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_375_piece0 stored as bytes in memory (estimated size 8.1 KB, free 95.1 MB)
2016-06-13 14:04:59,219  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_375_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:59,219  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 375 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:59,219  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 196 (MapPartitionsRDD[229] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,219  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 196.0 with 2 tasks
2016-06-13 14:04:59,220  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 196.0 (TID 375, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,220  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 196.0 (TID 376, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,220  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 196.0 (TID 375)
2016-06-13 14:04:59,221  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 196.0 (TID 376)
2016-06-13 14:04:59,222  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:59,224  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:59,224  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 196.0 (TID 375). 45217 bytes result sent to driver
2016-06-13 14:04:59,225  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 196.0 (TID 375) in 5 ms on localhost (1/2)
2016-06-13 14:04:59,226  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 196.0 (TID 376). 45217 bytes result sent to driver
2016-06-13 14:04:59,226  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 196.0 (TID 376) in 6 ms on localhost (2/2)
2016-06-13 14:04:59,226  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 196.0, whose tasks have all completed, from pool 
2016-06-13 14:04:59,226  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 196 (treeAggregate at RowMatrix.scala:93) finished in 0.006 s
2016-06-13 14:04:59,227  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 186 finished: treeAggregate at RowMatrix.scala:93, took 0.012196 s
2016-06-13 14:04:59,233  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_376 stored as values in memory (estimated size 124.9 KB, free 95.2 MB)
2016-06-13 14:04:59,235  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_376_piece0 stored as bytes in memory (estimated size 124.5 KB, free 95.3 MB)
2016-06-13 14:04:59,235  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_376_piece0 in memory on localhost:44356 (size: 124.5 KB, free: 9.7 GB)
2016-06-13 14:04:59,235  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 376 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:59,244  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:59,245  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 187 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:59,245  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 197 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,245  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:59,245  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:59,245  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 197 (MapPartitionsRDD[230] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:59,246  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_377 stored as values in memory (estimated size 55.2 KB, free 95.4 MB)
2016-06-13 14:04:59,248  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_377_piece0 stored as bytes in memory (estimated size 8.1 KB, free 95.4 MB)
2016-06-13 14:04:59,248  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_377_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:59,249  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 377 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:59,249  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 197 (MapPartitionsRDD[230] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,249  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 197.0 with 2 tasks
2016-06-13 14:04:59,252  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 197.0 (TID 377, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,252  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 197.0 (TID 378, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,252  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 197.0 (TID 377)
2016-06-13 14:04:59,253  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 197.0 (TID 378)
2016-06-13 14:04:59,259  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:59,260  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:59,261  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 197.0 (TID 378). 45217 bytes result sent to driver
2016-06-13 14:04:59,261  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 197.0 (TID 378) in 9 ms on localhost (1/2)
2016-06-13 14:04:59,262  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 197.0 (TID 377). 45217 bytes result sent to driver
2016-06-13 14:04:59,263  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 197.0 (TID 377) in 11 ms on localhost (2/2)
2016-06-13 14:04:59,263  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 197 (treeAggregate at RowMatrix.scala:93) finished in 0.014 s
2016-06-13 14:04:59,263  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 197.0, whose tasks have all completed, from pool 
2016-06-13 14:04:59,264  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 187 finished: treeAggregate at RowMatrix.scala:93, took 0.019362 s
2016-06-13 14:04:59,270  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_378 stored as values in memory (estimated size 124.9 KB, free 95.5 MB)
2016-06-13 14:04:59,272  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_378_piece0 stored as bytes in memory (estimated size 124.6 KB, free 95.6 MB)
2016-06-13 14:04:59,272  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_378_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:04:59,275  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 378 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:59,285  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:59,285  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 188 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:59,286  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 198 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,286  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:59,286  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:59,286  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 198 (MapPartitionsRDD[231] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:59,287  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_379 stored as values in memory (estimated size 55.2 KB, free 95.7 MB)
2016-06-13 14:04:59,288  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_379_piece0 stored as bytes in memory (estimated size 8.1 KB, free 95.7 MB)
2016-06-13 14:04:59,288  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_379_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:59,288  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 379 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:59,288  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 198 (MapPartitionsRDD[231] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,288  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 198.0 with 2 tasks
2016-06-13 14:04:59,290  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 198.0 (TID 379, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,291  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 198.0 (TID 380, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,291  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 198.0 (TID 379)
2016-06-13 14:04:59,291  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 198.0 (TID 380)
2016-06-13 14:04:59,293  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:59,295  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 198.0 (TID 379). 45217 bytes result sent to driver
2016-06-13 14:04:59,295  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:59,296  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 198.0 (TID 379) in 6 ms on localhost (1/2)
2016-06-13 14:04:59,297  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 198.0 (TID 380). 45217 bytes result sent to driver
2016-06-13 14:04:59,300  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 198.0 (TID 380) in 10 ms on localhost (2/2)
2016-06-13 14:04:59,300  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 198 (treeAggregate at RowMatrix.scala:93) finished in 0.011 s
2016-06-13 14:04:59,300  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 198.0, whose tasks have all completed, from pool 
2016-06-13 14:04:59,300  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 188 finished: treeAggregate at RowMatrix.scala:93, took 0.015213 s
2016-06-13 14:04:59,306  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_380 stored as values in memory (estimated size 124.9 KB, free 95.8 MB)
2016-06-13 14:04:59,307  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_380_piece0 stored as bytes in memory (estimated size 124.5 KB, free 95.9 MB)
2016-06-13 14:04:59,308  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_380_piece0 in memory on localhost:44356 (size: 124.5 KB, free: 9.7 GB)
2016-06-13 14:04:59,308  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 380 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:59,314  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:59,315  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 189 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:59,315  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 199 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,315  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:59,315  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:59,315  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 199 (MapPartitionsRDD[232] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:59,317  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_381 stored as values in memory (estimated size 55.2 KB, free 96.0 MB)
2016-06-13 14:04:59,318  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_381_piece0 stored as bytes in memory (estimated size 8.1 KB, free 96.0 MB)
2016-06-13 14:04:59,318  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_381_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:59,319  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 381 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:59,319  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 199 (MapPartitionsRDD[232] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,319  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 199.0 with 2 tasks
2016-06-13 14:04:59,319  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 199.0 (TID 381, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,320  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 199.0 (TID 382, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,320  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 199.0 (TID 381)
2016-06-13 14:04:59,322  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:59,322  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 199.0 (TID 382)
2016-06-13 14:04:59,325  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:59,327  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 199.0 (TID 381). 45217 bytes result sent to driver
2016-06-13 14:04:59,327  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 199.0 (TID 381) in 8 ms on localhost (1/2)
2016-06-13 14:04:59,327  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 199.0 (TID 382). 45217 bytes result sent to driver
2016-06-13 14:04:59,328  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 199.0 (TID 382) in 8 ms on localhost (2/2)
2016-06-13 14:04:59,328  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 199.0, whose tasks have all completed, from pool 
2016-06-13 14:04:59,328  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 199 (treeAggregate at RowMatrix.scala:93) finished in 0.008 s
2016-06-13 14:04:59,328  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 189 finished: treeAggregate at RowMatrix.scala:93, took 0.013575 s
2016-06-13 14:04:59,334  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_382 stored as values in memory (estimated size 124.9 KB, free 96.1 MB)
2016-06-13 14:04:59,335  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_382_piece0 stored as bytes in memory (estimated size 124.7 KB, free 96.3 MB)
2016-06-13 14:04:59,335  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_382_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:59,335  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 382 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:59,341  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:59,341  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 190 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:59,341  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 200 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,341  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:59,342  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:59,342  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 200 (MapPartitionsRDD[233] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:59,343  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_383 stored as values in memory (estimated size 55.2 KB, free 96.3 MB)
2016-06-13 14:04:59,344  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_383_piece0 stored as bytes in memory (estimated size 8.1 KB, free 96.3 MB)
2016-06-13 14:04:59,345  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_383_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:59,345  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 383 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:59,345  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 200 (MapPartitionsRDD[233] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,345  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 200.0 with 2 tasks
2016-06-13 14:04:59,346  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 200.0 (TID 383, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,346  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 200.0 (TID 384, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,346  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 200.0 (TID 384)
2016-06-13 14:04:59,346  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 200.0 (TID 383)
2016-06-13 14:04:59,349  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:59,349  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:59,351  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 200.0 (TID 384). 45217 bytes result sent to driver
2016-06-13 14:04:59,352  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 200.0 (TID 384) in 5 ms on localhost (1/2)
2016-06-13 14:04:59,352  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 200.0 (TID 383). 45217 bytes result sent to driver
2016-06-13 14:04:59,353  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 200.0 (TID 383) in 7 ms on localhost (2/2)
2016-06-13 14:04:59,353  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 200.0, whose tasks have all completed, from pool 
2016-06-13 14:04:59,353  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 200 (treeAggregate at RowMatrix.scala:93) finished in 0.007 s
2016-06-13 14:04:59,353  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 190 finished: treeAggregate at RowMatrix.scala:93, took 0.012226 s
2016-06-13 14:04:59,360  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_384 stored as values in memory (estimated size 124.9 KB, free 96.4 MB)
2016-06-13 14:04:59,361  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_384_piece0 stored as bytes in memory (estimated size 124.6 KB, free 96.6 MB)
2016-06-13 14:04:59,362  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_384_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:04:59,362  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 384 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:59,369  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:59,370  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 191 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:59,370  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 201 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,370  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:59,370  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:59,370  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 201 (MapPartitionsRDD[234] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:59,371  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_385 stored as values in memory (estimated size 55.2 KB, free 96.6 MB)
2016-06-13 14:04:59,372  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_385_piece0 stored as bytes in memory (estimated size 8.1 KB, free 96.6 MB)
2016-06-13 14:04:59,373  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_385_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:59,373  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 385 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:59,373  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 201 (MapPartitionsRDD[234] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,373  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 201.0 with 2 tasks
2016-06-13 14:04:59,376  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 201.0 (TID 385, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,376  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 201.0 (TID 386, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,376  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 201.0 (TID 386)
2016-06-13 14:04:59,378  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 201.0 (TID 385)
2016-06-13 14:04:59,379  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:59,381  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 201.0 (TID 386). 45217 bytes result sent to driver
2016-06-13 14:04:59,387  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 201.0 (TID 386) in 11 ms on localhost (1/2)
2016-06-13 14:04:59,389  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:59,391  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 201.0 (TID 385). 45217 bytes result sent to driver
2016-06-13 14:04:59,392  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 201.0 (TID 385) in 16 ms on localhost (2/2)
2016-06-13 14:04:59,392  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 201 (treeAggregate at RowMatrix.scala:93) finished in 0.019 s
2016-06-13 14:04:59,392  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 201.0, whose tasks have all completed, from pool 
2016-06-13 14:04:59,392  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 191 finished: treeAggregate at RowMatrix.scala:93, took 0.022966 s
2016-06-13 14:04:59,399  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_386 stored as values in memory (estimated size 124.9 KB, free 96.7 MB)
2016-06-13 14:04:59,401  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_386_piece0 stored as bytes in memory (estimated size 124.5 KB, free 96.9 MB)
2016-06-13 14:04:59,401  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_386_piece0 in memory on localhost:44356 (size: 124.5 KB, free: 9.7 GB)
2016-06-13 14:04:59,402  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 386 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:59,409  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:59,409  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 192 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:59,409  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 202 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,409  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:59,409  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:59,410  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 202 (MapPartitionsRDD[235] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:59,411  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_387 stored as values in memory (estimated size 55.2 KB, free 96.9 MB)
2016-06-13 14:04:59,412  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_387_piece0 stored as bytes in memory (estimated size 8.1 KB, free 96.9 MB)
2016-06-13 14:04:59,412  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_387_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:59,413  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 387 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:59,413  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 202 (MapPartitionsRDD[235] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,413  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 202.0 with 2 tasks
2016-06-13 14:04:59,414  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 202.0 (TID 387, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,414  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 202.0 (TID 388, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,414  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 202.0 (TID 387)
2016-06-13 14:04:59,414  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 202.0 (TID 388)
2016-06-13 14:04:59,417  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:59,419  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 202.0 (TID 388). 45217 bytes result sent to driver
2016-06-13 14:04:59,420  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:59,420  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 202.0 (TID 388) in 6 ms on localhost (1/2)
2016-06-13 14:04:59,423  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 202.0 (TID 387). 45217 bytes result sent to driver
2016-06-13 14:04:59,424  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 202.0 (TID 387) in 10 ms on localhost (2/2)
2016-06-13 14:04:59,424  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 202 (treeAggregate at RowMatrix.scala:93) finished in 0.008 s
2016-06-13 14:04:59,424  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 202.0, whose tasks have all completed, from pool 
2016-06-13 14:04:59,424  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 192 finished: treeAggregate at RowMatrix.scala:93, took 0.015552 s
2016-06-13 14:04:59,430  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_388 stored as values in memory (estimated size 124.9 KB, free 97.0 MB)
2016-06-13 14:04:59,431  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_388_piece0 stored as bytes in memory (estimated size 124.6 KB, free 97.2 MB)
2016-06-13 14:04:59,432  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_388_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:04:59,432  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 388 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:59,437  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:59,437  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 193 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:59,437  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 203 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,437  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:59,438  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:59,438  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 203 (MapPartitionsRDD[236] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:59,439  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_389 stored as values in memory (estimated size 55.2 KB, free 97.2 MB)
2016-06-13 14:04:59,440  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_389_piece0 stored as bytes in memory (estimated size 8.1 KB, free 97.2 MB)
2016-06-13 14:04:59,441  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_389_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:59,441  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 389 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:59,441  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 203 (MapPartitionsRDD[236] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,441  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 203.0 with 2 tasks
2016-06-13 14:04:59,442  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 203.0 (TID 389, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,442  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 203.0 (TID 390, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,442  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 203.0 (TID 390)
2016-06-13 14:04:59,445  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:59,446  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 203.0 (TID 389)
2016-06-13 14:04:59,447  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 203.0 (TID 390). 45217 bytes result sent to driver
2016-06-13 14:04:59,448  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 203.0 (TID 390) in 6 ms on localhost (1/2)
2016-06-13 14:04:59,448  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:59,451  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 203.0 (TID 389). 45217 bytes result sent to driver
2016-06-13 14:04:59,451  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 203.0 (TID 389) in 9 ms on localhost (2/2)
2016-06-13 14:04:59,451  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 203.0, whose tasks have all completed, from pool 
2016-06-13 14:04:59,452  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 203 (treeAggregate at RowMatrix.scala:93) finished in 0.006 s
2016-06-13 14:04:59,453  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 193 finished: treeAggregate at RowMatrix.scala:93, took 0.015646 s
2016-06-13 14:04:59,458  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_390 stored as values in memory (estimated size 124.9 KB, free 97.4 MB)
2016-06-13 14:04:59,459  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_390_piece0 stored as bytes in memory (estimated size 124.6 KB, free 97.5 MB)
2016-06-13 14:04:59,459  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_390_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:04:59,460  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 390 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:59,465  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:59,465  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 194 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:59,465  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 204 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,465  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:59,465  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:59,465  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 204 (MapPartitionsRDD[237] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:59,467  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_391 stored as values in memory (estimated size 55.2 KB, free 97.5 MB)
2016-06-13 14:04:59,468  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_391_piece0 stored as bytes in memory (estimated size 8.1 KB, free 97.5 MB)
2016-06-13 14:04:59,469  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_391_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:59,469  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 391 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:59,470  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 204 (MapPartitionsRDD[237] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,470  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 204.0 with 2 tasks
2016-06-13 14:04:59,471  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 204.0 (TID 391, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,471  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 204.0 (TID 392, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,471  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 204.0 (TID 391)
2016-06-13 14:04:59,471  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 204.0 (TID 392)
2016-06-13 14:04:59,474  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:59,476  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 204.0 (TID 392). 45217 bytes result sent to driver
2016-06-13 14:04:59,477  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:59,477  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 204.0 (TID 392) in 6 ms on localhost (1/2)
2016-06-13 14:04:59,481  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 204.0 (TID 391). 45217 bytes result sent to driver
2016-06-13 14:04:59,481  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 204.0 (TID 391) in 10 ms on localhost (2/2)
2016-06-13 14:04:59,481  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 204.0, whose tasks have all completed, from pool 
2016-06-13 14:04:59,481  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 204 (treeAggregate at RowMatrix.scala:93) finished in 0.009 s
2016-06-13 14:04:59,481  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 194 finished: treeAggregate at RowMatrix.scala:93, took 0.016904 s
2016-06-13 14:04:59,488  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_392 stored as values in memory (estimated size 124.9 KB, free 97.7 MB)
2016-06-13 14:04:59,489  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_392_piece0 stored as bytes in memory (estimated size 124.6 KB, free 97.8 MB)
2016-06-13 14:04:59,489  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_392_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:04:59,490  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 392 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:59,494  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:59,494  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 195 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:59,494  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 205 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,494  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:59,495  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:59,495  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 205 (MapPartitionsRDD[238] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:59,496  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_393 stored as values in memory (estimated size 55.2 KB, free 97.8 MB)
2016-06-13 14:04:59,497  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_393_piece0 stored as bytes in memory (estimated size 8.1 KB, free 97.8 MB)
2016-06-13 14:04:59,497  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_393_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:59,498  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 393 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:59,498  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 205 (MapPartitionsRDD[238] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,498  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 205.0 with 2 tasks
2016-06-13 14:04:59,498  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 205.0 (TID 393, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,499  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 205.0 (TID 394, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,499  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 205.0 (TID 394)
2016-06-13 14:04:59,499  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 205.0 (TID 393)
2016-06-13 14:04:59,502  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:59,504  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 205.0 (TID 394). 45217 bytes result sent to driver
2016-06-13 14:04:59,505  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 205.0 (TID 394) in 6 ms on localhost (1/2)
2016-06-13 14:04:59,505  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:59,507  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 205.0 (TID 393). 45217 bytes result sent to driver
2016-06-13 14:04:59,508  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 205.0 (TID 393) in 10 ms on localhost (2/2)
2016-06-13 14:04:59,508  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 205.0, whose tasks have all completed, from pool 
2016-06-13 14:04:59,509  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 205 (treeAggregate at RowMatrix.scala:93) finished in 0.005 s
2016-06-13 14:04:59,509  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 195 finished: treeAggregate at RowMatrix.scala:93, took 0.015280 s
2016-06-13 14:04:59,708  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_394 stored as values in memory (estimated size 124.9 KB, free 98.0 MB)
2016-06-13 14:04:59,709  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_394_piece0 stored as bytes in memory (estimated size 125.1 KB, free 98.1 MB)
2016-06-13 14:04:59,710  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_394_piece0 in memory on localhost:44356 (size: 125.1 KB, free: 9.7 GB)
2016-06-13 14:04:59,711  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 394 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:59,716  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:59,717  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 196 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:59,717  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 206 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,717  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:59,717  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:59,717  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 206 (MapPartitionsRDD[239] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:59,719  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_395 stored as values in memory (estimated size 55.2 KB, free 98.1 MB)
2016-06-13 14:04:59,720  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_395_piece0 stored as bytes in memory (estimated size 8.1 KB, free 98.1 MB)
2016-06-13 14:04:59,720  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_395_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:59,720  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 395 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:59,720  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 206 (MapPartitionsRDD[239] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,720  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 206.0 with 2 tasks
2016-06-13 14:04:59,721  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 206.0 (TID 395, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,721  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 206.0 (TID 396, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,721  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 206.0 (TID 395)
2016-06-13 14:04:59,721  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 206.0 (TID 396)
2016-06-13 14:04:59,723  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:59,723  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:59,725  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 206.0 (TID 395). 45217 bytes result sent to driver
2016-06-13 14:04:59,725  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 206.0 (TID 396). 45217 bytes result sent to driver
2016-06-13 14:04:59,726  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 206.0 (TID 396) in 5 ms on localhost (1/2)
2016-06-13 14:04:59,726  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 206.0 (TID 395) in 6 ms on localhost (2/2)
2016-06-13 14:04:59,726  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 206.0, whose tasks have all completed, from pool 
2016-06-13 14:04:59,727  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 206 (treeAggregate at RowMatrix.scala:93) finished in 0.007 s
2016-06-13 14:04:59,727  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 196 finished: treeAggregate at RowMatrix.scala:93, took 0.010358 s
2016-06-13 14:04:59,731  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_396 stored as values in memory (estimated size 124.9 KB, free 98.3 MB)
2016-06-13 14:04:59,732  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_396_piece0 stored as bytes in memory (estimated size 124.7 KB, free 98.4 MB)
2016-06-13 14:04:59,733  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_396_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:59,734  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 396 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:59,742  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:59,743  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 197 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:59,743  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 207 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,743  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:59,743  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:59,743  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 207 (MapPartitionsRDD[240] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:59,745  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_397 stored as values in memory (estimated size 55.2 KB, free 98.4 MB)
2016-06-13 14:04:59,746  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_397_piece0 stored as bytes in memory (estimated size 8.1 KB, free 98.5 MB)
2016-06-13 14:04:59,746  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_397_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:59,746  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 397 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:59,746  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 207 (MapPartitionsRDD[240] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,746  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 207.0 with 2 tasks
2016-06-13 14:04:59,747  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 207.0 (TID 397, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,747  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 207.0 (TID 398, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,747  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 207.0 (TID 397)
2016-06-13 14:04:59,750  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:59,750  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 207.0 (TID 398)
2016-06-13 14:04:59,752  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 207.0 (TID 397). 45217 bytes result sent to driver
2016-06-13 14:04:59,753  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:59,755  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 207.0 (TID 397) in 8 ms on localhost (1/2)
2016-06-13 14:04:59,757  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 207.0 (TID 398). 45217 bytes result sent to driver
2016-06-13 14:04:59,758  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 207.0 (TID 398) in 11 ms on localhost (2/2)
2016-06-13 14:04:59,758  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 207.0, whose tasks have all completed, from pool 
2016-06-13 14:04:59,761  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 207 (treeAggregate at RowMatrix.scala:93) finished in 0.015 s
2016-06-13 14:04:59,762  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 197 finished: treeAggregate at RowMatrix.scala:93, took 0.019277 s
2016-06-13 14:04:59,766  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_398 stored as values in memory (estimated size 124.9 KB, free 98.6 MB)
2016-06-13 14:04:59,767  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_398_piece0 stored as bytes in memory (estimated size 124.7 KB, free 98.7 MB)
2016-06-13 14:04:59,768  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_398_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:59,768  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 398 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:59,773  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:59,773  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 198 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:59,773  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 208 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,773  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:59,774  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:59,774  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 208 (MapPartitionsRDD[241] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:59,776  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_399 stored as values in memory (estimated size 55.2 KB, free 98.8 MB)
2016-06-13 14:04:59,777  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_399_piece0 stored as bytes in memory (estimated size 8.1 KB, free 98.8 MB)
2016-06-13 14:04:59,777  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_399_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:59,777  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 399 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:59,777  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 208 (MapPartitionsRDD[241] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,777  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 208.0 with 2 tasks
2016-06-13 14:04:59,778  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 208.0 (TID 399, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,778  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 208.0 (TID 400, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,778  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 208.0 (TID 400)
2016-06-13 14:04:59,778  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 208.0 (TID 399)
2016-06-13 14:04:59,781  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:59,783  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:59,786  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 208.0 (TID 400). 45217 bytes result sent to driver
2016-06-13 14:04:59,786  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 208.0 (TID 399). 45217 bytes result sent to driver
2016-06-13 14:04:59,786  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 208.0 (TID 400) in 8 ms on localhost (1/2)
2016-06-13 14:04:59,787  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 208.0 (TID 399) in 9 ms on localhost (2/2)
2016-06-13 14:04:59,787  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 208.0, whose tasks have all completed, from pool 
2016-06-13 14:04:59,787  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 208 (treeAggregate at RowMatrix.scala:93) finished in 0.009 s
2016-06-13 14:04:59,788  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 198 finished: treeAggregate at RowMatrix.scala:93, took 0.014864 s
2016-06-13 14:04:59,792  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_400 stored as values in memory (estimated size 124.9 KB, free 98.9 MB)
2016-06-13 14:04:59,794  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_400_piece0 stored as bytes in memory (estimated size 124.7 KB, free 99.0 MB)
2016-06-13 14:04:59,794  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_400_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:59,794  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 400 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:59,799  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:59,799  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 199 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:59,799  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 209 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,799  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:59,799  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:59,800  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 209 (MapPartitionsRDD[242] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:59,800  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_401 stored as values in memory (estimated size 55.2 KB, free 99.1 MB)
2016-06-13 14:04:59,801  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_401_piece0 stored as bytes in memory (estimated size 8.1 KB, free 99.1 MB)
2016-06-13 14:04:59,801  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_401_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:59,802  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 401 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:59,802  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 209 (MapPartitionsRDD[242] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,802  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 209.0 with 2 tasks
2016-06-13 14:04:59,802  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 209.0 (TID 401, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,802  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 209.0 (TID 402, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,802  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 209.0 (TID 401)
2016-06-13 14:04:59,802  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 209.0 (TID 402)
2016-06-13 14:04:59,804  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:59,805  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:59,806  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 209.0 (TID 402). 45217 bytes result sent to driver
2016-06-13 14:04:59,806  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 209.0 (TID 402) in 4 ms on localhost (1/2)
2016-06-13 14:04:59,807  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 209.0 (TID 401). 45217 bytes result sent to driver
2016-06-13 14:04:59,807  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 209.0 (TID 401) in 5 ms on localhost (2/2)
2016-06-13 14:04:59,808  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 209.0, whose tasks have all completed, from pool 
2016-06-13 14:04:59,808  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 209 (treeAggregate at RowMatrix.scala:93) finished in 0.005 s
2016-06-13 14:04:59,808  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 199 finished: treeAggregate at RowMatrix.scala:93, took 0.009033 s
2016-06-13 14:04:59,813  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_402 stored as values in memory (estimated size 124.9 KB, free 99.2 MB)
2016-06-13 14:04:59,814  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_402_piece0 stored as bytes in memory (estimated size 124.7 KB, free 99.3 MB)
2016-06-13 14:04:59,814  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_402_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:59,814  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 402 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:59,820  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:59,820  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 200 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:59,820  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 210 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,820  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:59,820  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:59,821  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 210 (MapPartitionsRDD[243] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:59,822  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_403 stored as values in memory (estimated size 55.2 KB, free 99.4 MB)
2016-06-13 14:04:59,823  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_403_piece0 stored as bytes in memory (estimated size 8.1 KB, free 99.4 MB)
2016-06-13 14:04:59,823  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_403_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:59,824  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 403 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:59,824  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 210 (MapPartitionsRDD[243] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,824  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 210.0 with 2 tasks
2016-06-13 14:04:59,825  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 210.0 (TID 403, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,825  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 210.0 (TID 404, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,825  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 210.0 (TID 403)
2016-06-13 14:04:59,828  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:59,829  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 210.0 (TID 403). 45217 bytes result sent to driver
2016-06-13 14:04:59,830  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 210.0 (TID 404)
2016-06-13 14:04:59,830  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 210.0 (TID 403) in 5 ms on localhost (1/2)
2016-06-13 14:04:59,832  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:59,835  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 210.0 (TID 404). 45217 bytes result sent to driver
2016-06-13 14:04:59,835  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 210.0 (TID 404) in 10 ms on localhost (2/2)
2016-06-13 14:04:59,835  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 210.0, whose tasks have all completed, from pool 
2016-06-13 14:04:59,836  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 210 (treeAggregate at RowMatrix.scala:93) finished in 0.010 s
2016-06-13 14:04:59,836  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 200 finished: treeAggregate at RowMatrix.scala:93, took 0.015890 s
2016-06-13 14:04:59,840  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_404 stored as values in memory (estimated size 124.9 KB, free 99.5 MB)
2016-06-13 14:04:59,841  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_404_piece0 stored as bytes in memory (estimated size 124.8 KB, free 99.6 MB)
2016-06-13 14:04:59,841  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_404_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:59,842  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 404 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:59,847  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:59,847  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 201 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:59,847  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 211 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,847  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:59,848  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:59,848  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 211 (MapPartitionsRDD[244] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:59,849  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_405 stored as values in memory (estimated size 55.2 KB, free 99.7 MB)
2016-06-13 14:04:59,850  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_405_piece0 stored as bytes in memory (estimated size 8.1 KB, free 99.7 MB)
2016-06-13 14:04:59,850  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_405_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:59,850  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 405 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:59,850  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 211 (MapPartitionsRDD[244] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,850  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 211.0 with 2 tasks
2016-06-13 14:04:59,851  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 211.0 (TID 405, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,851  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 211.0 (TID 406, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,851  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 211.0 (TID 405)
2016-06-13 14:04:59,851  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 211.0 (TID 406)
2016-06-13 14:04:59,853  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:59,853  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:59,855  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 211.0 (TID 405). 45217 bytes result sent to driver
2016-06-13 14:04:59,855  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 211.0 (TID 406). 45217 bytes result sent to driver
2016-06-13 14:04:59,856  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 211.0 (TID 405) in 6 ms on localhost (1/2)
2016-06-13 14:04:59,856  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 211.0 (TID 406) in 5 ms on localhost (2/2)
2016-06-13 14:04:59,856  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 211.0, whose tasks have all completed, from pool 
2016-06-13 14:04:59,856  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 211 (treeAggregate at RowMatrix.scala:93) finished in 0.005 s
2016-06-13 14:04:59,857  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 201 finished: treeAggregate at RowMatrix.scala:93, took 0.009606 s
2016-06-13 14:04:59,863  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_406 stored as values in memory (estimated size 124.9 KB, free 99.8 MB)
2016-06-13 14:04:59,864  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_406_piece0 stored as bytes in memory (estimated size 124.6 KB, free 99.9 MB)
2016-06-13 14:04:59,864  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_406_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:04:59,865  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 406 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:59,872  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:59,873  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 202 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:59,873  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 212 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,873  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:59,873  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:59,873  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 212 (MapPartitionsRDD[245] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:59,875  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_407 stored as values in memory (estimated size 55.2 KB, free 100.0 MB)
2016-06-13 14:04:59,876  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_407_piece0 stored as bytes in memory (estimated size 8.1 KB, free 100.0 MB)
2016-06-13 14:04:59,877  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_407_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:59,877  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 407 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:59,877  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 212 (MapPartitionsRDD[245] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,877  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 212.0 with 2 tasks
2016-06-13 14:04:59,878  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 212.0 (TID 407, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,878  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 212.0 (TID 408, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,878  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 212.0 (TID 408)
2016-06-13 14:04:59,880  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 212.0 (TID 407)
2016-06-13 14:04:59,881  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:59,882  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:59,883  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 212.0 (TID 408). 45217 bytes result sent to driver
2016-06-13 14:04:59,884  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 212.0 (TID 408) in 6 ms on localhost (1/2)
2016-06-13 14:04:59,884  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 212.0 (TID 407). 45217 bytes result sent to driver
2016-06-13 14:04:59,885  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 212.0 (TID 407) in 7 ms on localhost (2/2)
2016-06-13 14:04:59,885  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 212 (treeAggregate at RowMatrix.scala:93) finished in 0.005 s
2016-06-13 14:04:59,885  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 202 finished: treeAggregate at RowMatrix.scala:93, took 0.012873 s
2016-06-13 14:04:59,885  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 212.0, whose tasks have all completed, from pool 
2016-06-13 14:04:59,891  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_408 stored as values in memory (estimated size 124.9 KB, free 100.1 MB)
2016-06-13 14:04:59,893  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_408_piece0 stored as bytes in memory (estimated size 124.8 KB, free 100.2 MB)
2016-06-13 14:04:59,893  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_408_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:59,893  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 408 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:59,901  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:59,902  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 203 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:59,902  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 213 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,902  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:59,902  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:59,902  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 213 (MapPartitionsRDD[246] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:59,904  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_409 stored as values in memory (estimated size 55.2 KB, free 100.3 MB)
2016-06-13 14:04:59,905  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_409_piece0 stored as bytes in memory (estimated size 8.1 KB, free 100.3 MB)
2016-06-13 14:04:59,905  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_409_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:59,905  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 409 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:59,906  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 213 (MapPartitionsRDD[246] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,906  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 213.0 with 2 tasks
2016-06-13 14:04:59,906  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 213.0 (TID 409, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,906  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 213.0 (TID 410, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,906  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 213.0 (TID 409)
2016-06-13 14:04:59,906  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 213.0 (TID 410)
2016-06-13 14:04:59,908  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:59,910  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 213.0 (TID 410). 45217 bytes result sent to driver
2016-06-13 14:04:59,913  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:59,915  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 213.0 (TID 410) in 9 ms on localhost (1/2)
2016-06-13 14:04:59,919  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 213.0 (TID 409). 45217 bytes result sent to driver
2016-06-13 14:04:59,921  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 213.0 (TID 409) in 15 ms on localhost (2/2)
2016-06-13 14:04:59,921  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 213.0, whose tasks have all completed, from pool 
2016-06-13 14:04:59,921  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 213 (treeAggregate at RowMatrix.scala:93) finished in 0.015 s
2016-06-13 14:04:59,921  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 203 finished: treeAggregate at RowMatrix.scala:93, took 0.020092 s
2016-06-13 14:04:59,927  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_410 stored as values in memory (estimated size 124.9 KB, free 100.4 MB)
2016-06-13 14:04:59,930  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_410_piece0 stored as bytes in memory (estimated size 124.7 KB, free 100.5 MB)
2016-06-13 14:04:59,930  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_410_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:59,931  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 410 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:59,936  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:59,936  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 204 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:59,936  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 214 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,936  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:59,936  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:59,936  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 214 (MapPartitionsRDD[247] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:59,938  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_411 stored as values in memory (estimated size 55.2 KB, free 100.6 MB)
2016-06-13 14:04:59,939  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_411_piece0 stored as bytes in memory (estimated size 8.1 KB, free 100.6 MB)
2016-06-13 14:04:59,939  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_411_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:59,940  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 411 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:59,940  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 214 (MapPartitionsRDD[247] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,940  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 214.0 with 2 tasks
2016-06-13 14:04:59,941  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 214.0 (TID 411, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,941  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 214.0 (TID 412, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,941  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 214.0 (TID 411)
2016-06-13 14:04:59,941  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 214.0 (TID 412)
2016-06-13 14:04:59,944  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:59,947  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 214.0 (TID 412). 45217 bytes result sent to driver
2016-06-13 14:04:59,948  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 214.0 (TID 412) in 7 ms on localhost (1/2)
2016-06-13 14:04:59,948  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:59,949  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 214.0 (TID 411). 45217 bytes result sent to driver
2016-06-13 14:04:59,950  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 214.0 (TID 411) in 10 ms on localhost (2/2)
2016-06-13 14:04:59,950  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 214.0, whose tasks have all completed, from pool 
2016-06-13 14:04:59,950  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 214 (treeAggregate at RowMatrix.scala:93) finished in 0.006 s
2016-06-13 14:04:59,950  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 204 finished: treeAggregate at RowMatrix.scala:93, took 0.014735 s
2016-06-13 14:04:59,955  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_412 stored as values in memory (estimated size 124.9 KB, free 100.7 MB)
2016-06-13 14:04:59,956  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_412_piece0 stored as bytes in memory (estimated size 124.8 KB, free 100.8 MB)
2016-06-13 14:04:59,957  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_412_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:04:59,957  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 412 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:59,962  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:59,962  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 205 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:59,962  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 215 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,962  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:59,963  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:59,963  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 215 (MapPartitionsRDD[248] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:59,964  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_413 stored as values in memory (estimated size 55.2 KB, free 100.9 MB)
2016-06-13 14:04:59,965  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_413_piece0 stored as bytes in memory (estimated size 8.1 KB, free 100.9 MB)
2016-06-13 14:04:59,965  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_413_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:59,965  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 413 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:59,965  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 215 (MapPartitionsRDD[248] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,965  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 215.0 with 2 tasks
2016-06-13 14:04:59,966  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 215.0 (TID 413, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,966  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 215.0 (TID 414, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,966  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 215.0 (TID 413)
2016-06-13 14:04:59,966  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 215.0 (TID 414)
2016-06-13 14:04:59,968  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:59,968  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:59,969  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 215.0 (TID 413). 45217 bytes result sent to driver
2016-06-13 14:04:59,970  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 215.0 (TID 413) in 4 ms on localhost (1/2)
2016-06-13 14:04:59,971  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 215.0 (TID 414). 45217 bytes result sent to driver
2016-06-13 14:04:59,972  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 215.0 (TID 414) in 6 ms on localhost (2/2)
2016-06-13 14:04:59,972  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 215 (treeAggregate at RowMatrix.scala:93) finished in 0.007 s
2016-06-13 14:04:59,972  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 215.0, whose tasks have all completed, from pool 
2016-06-13 14:04:59,972  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 205 finished: treeAggregate at RowMatrix.scala:93, took 0.010031 s
2016-06-13 14:04:59,976  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_414 stored as values in memory (estimated size 124.9 KB, free 101.0 MB)
2016-06-13 14:04:59,977  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_414_piece0 stored as bytes in memory (estimated size 124.7 KB, free 101.1 MB)
2016-06-13 14:04:59,978  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_414_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:04:59,978  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 414 from broadcast at RowMatrix.scala:92
2016-06-13 14:04:59,982  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:04:59,983  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 206 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:04:59,983  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 216 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,983  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:04:59,983  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:04:59,984  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 216 (MapPartitionsRDD[249] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:04:59,985  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_415 stored as values in memory (estimated size 55.2 KB, free 101.2 MB)
2016-06-13 14:04:59,986  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_415_piece0 stored as bytes in memory (estimated size 8.1 KB, free 101.2 MB)
2016-06-13 14:04:59,987  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_415_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:04:59,987  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 415 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:04:59,987  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 216 (MapPartitionsRDD[249] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:04:59,987  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 216.0 with 2 tasks
2016-06-13 14:04:59,987  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 216.0 (TID 415, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,988  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 216.0 (TID 416, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:04:59,988  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 216.0 (TID 416)
2016-06-13 14:04:59,990  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:04:59,991  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 216.0 (TID 415)
2016-06-13 14:04:59,992  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 216.0 (TID 416). 45217 bytes result sent to driver
2016-06-13 14:04:59,993  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 216.0 (TID 416) in 6 ms on localhost (1/2)
2016-06-13 14:04:59,996  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:04:59,998  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 216.0 (TID 415). 45217 bytes result sent to driver
2016-06-13 14:04:59,999  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 216.0 (TID 415) in 12 ms on localhost (2/2)
2016-06-13 14:04:59,999  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 216.0, whose tasks have all completed, from pool 
2016-06-13 14:04:59,999  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 216 (treeAggregate at RowMatrix.scala:93) finished in 0.011 s
2016-06-13 14:05:00,000  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 206 finished: treeAggregate at RowMatrix.scala:93, took 0.017446 s
2016-06-13 14:05:00,005  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_416 stored as values in memory (estimated size 124.9 KB, free 101.3 MB)
2016-06-13 14:05:00,006  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_416_piece0 stored as bytes in memory (estimated size 124.7 KB, free 101.4 MB)
2016-06-13 14:05:00,006  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_416_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:05:00,006  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 416 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,011  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,011  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 207 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,011  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 217 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,011  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,011  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,011  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 217 (MapPartitionsRDD[250] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,013  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_417 stored as values in memory (estimated size 55.2 KB, free 101.5 MB)
2016-06-13 14:05:00,014  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_417_piece0 stored as bytes in memory (estimated size 8.1 KB, free 101.5 MB)
2016-06-13 14:05:00,014  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_417_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,014  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 417 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,014  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 217 (MapPartitionsRDD[250] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,014  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 217.0 with 2 tasks
2016-06-13 14:05:00,015  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 217.0 (TID 417, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,015  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 217.0 (TID 418, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,015  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 217.0 (TID 417)
2016-06-13 14:05:00,015  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 217.0 (TID 418)
2016-06-13 14:05:00,017  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,018  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,019  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 217.0 (TID 417). 45217 bytes result sent to driver
2016-06-13 14:05:00,021  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 217.0 (TID 417) in 6 ms on localhost (1/2)
2016-06-13 14:05:00,026  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 217.0 (TID 418). 45217 bytes result sent to driver
2016-06-13 14:05:00,028  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 217.0 (TID 418) in 13 ms on localhost (2/2)
2016-06-13 14:05:00,028  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 217 (treeAggregate at RowMatrix.scala:93) finished in 0.013 s
2016-06-13 14:05:00,028  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 217.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,028  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 207 finished: treeAggregate at RowMatrix.scala:93, took 0.017311 s
2016-06-13 14:05:00,035  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_418 stored as values in memory (estimated size 124.9 KB, free 101.6 MB)
2016-06-13 14:05:00,036  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_418_piece0 stored as bytes in memory (estimated size 124.6 KB, free 101.8 MB)
2016-06-13 14:05:00,037  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_418_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:00,037  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 418 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,045  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,046  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 208 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,046  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 218 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,046  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,046  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,046  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 218 (MapPartitionsRDD[251] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,048  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_419 stored as values in memory (estimated size 55.2 KB, free 101.8 MB)
2016-06-13 14:05:00,049  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_419_piece0 stored as bytes in memory (estimated size 8.1 KB, free 101.8 MB)
2016-06-13 14:05:00,050  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_419_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,050  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 419 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,050  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 218 (MapPartitionsRDD[251] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,050  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 218.0 with 2 tasks
2016-06-13 14:05:00,051  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 218.0 (TID 419, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,051  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 218.0 (TID 420, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,051  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 218.0 (TID 419)
2016-06-13 14:05:00,051  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 218.0 (TID 420)
2016-06-13 14:05:00,056  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,059  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,060  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 218.0 (TID 419). 45217 bytes result sent to driver
2016-06-13 14:05:00,061  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 218.0 (TID 420). 45217 bytes result sent to driver
2016-06-13 14:05:00,062  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 218.0 (TID 419) in 11 ms on localhost (1/2)
2016-06-13 14:05:00,062  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 218.0 (TID 420) in 11 ms on localhost (2/2)
2016-06-13 14:05:00,062  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 218.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,062  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 218 (treeAggregate at RowMatrix.scala:93) finished in 0.002 s
2016-06-13 14:05:00,063  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 208 finished: treeAggregate at RowMatrix.scala:93, took 0.017350 s
2016-06-13 14:05:00,067  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_420 stored as values in memory (estimated size 124.9 KB, free 101.9 MB)
2016-06-13 14:05:00,068  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_420_piece0 stored as bytes in memory (estimated size 124.7 KB, free 102.1 MB)
2016-06-13 14:05:00,068  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_420_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:05:00,069  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 420 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,073  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,074  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 209 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,074  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 219 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,074  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,074  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,074  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 219 (MapPartitionsRDD[252] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,075  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_421 stored as values in memory (estimated size 55.2 KB, free 102.1 MB)
2016-06-13 14:05:00,076  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_421_piece0 stored as bytes in memory (estimated size 8.1 KB, free 102.1 MB)
2016-06-13 14:05:00,076  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_421_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,076  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 421 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,077  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 219 (MapPartitionsRDD[252] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,077  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 219.0 with 2 tasks
2016-06-13 14:05:00,077  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 219.0 (TID 421, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,077  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 219.0 (TID 422, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,077  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 219.0 (TID 422)
2016-06-13 14:05:00,077  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 219.0 (TID 421)
2016-06-13 14:05:00,079  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,079  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,081  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 219.0 (TID 422). 45217 bytes result sent to driver
2016-06-13 14:05:00,082  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 219.0 (TID 421). 45217 bytes result sent to driver
2016-06-13 14:05:00,082  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 219.0 (TID 421) in 5 ms on localhost (1/2)
2016-06-13 14:05:00,083  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 219.0 (TID 422) in 6 ms on localhost (2/2)
2016-06-13 14:05:00,083  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 219.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,083  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 219 (treeAggregate at RowMatrix.scala:93) finished in 0.006 s
2016-06-13 14:05:00,084  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 209 finished: treeAggregate at RowMatrix.scala:93, took 0.010106 s
2016-06-13 14:05:00,088  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_422 stored as values in memory (estimated size 124.9 KB, free 102.2 MB)
2016-06-13 14:05:00,089  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_422_piece0 stored as bytes in memory (estimated size 124.6 KB, free 102.4 MB)
2016-06-13 14:05:00,089  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_422_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:00,090  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 422 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,095  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,095  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 210 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,095  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 220 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,095  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,095  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,096  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 220 (MapPartitionsRDD[253] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,097  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_423 stored as values in memory (estimated size 55.2 KB, free 102.4 MB)
2016-06-13 14:05:00,098  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_423_piece0 stored as bytes in memory (estimated size 8.1 KB, free 102.4 MB)
2016-06-13 14:05:00,098  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_423_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,101  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 423 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,101  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 220 (MapPartitionsRDD[253] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,101  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 220.0 with 2 tasks
2016-06-13 14:05:00,102  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 220.0 (TID 423, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,102  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 220.0 (TID 424, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,103  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 220.0 (TID 423)
2016-06-13 14:05:00,103  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 220.0 (TID 424)
2016-06-13 14:05:00,105  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,105  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,107  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 220.0 (TID 423). 45217 bytes result sent to driver
2016-06-13 14:05:00,108  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 220.0 (TID 423) in 6 ms on localhost (1/2)
2016-06-13 14:05:00,109  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 220.0 (TID 424). 45217 bytes result sent to driver
2016-06-13 14:05:00,109  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 220.0 (TID 424) in 7 ms on localhost (2/2)
2016-06-13 14:05:00,109  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 220.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,110  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 220 (treeAggregate at RowMatrix.scala:93) finished in 0.009 s
2016-06-13 14:05:00,110  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 210 finished: treeAggregate at RowMatrix.scala:93, took 0.014970 s
2016-06-13 14:05:00,115  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_424 stored as values in memory (estimated size 124.9 KB, free 102.5 MB)
2016-06-13 14:05:00,116  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_424_piece0 stored as bytes in memory (estimated size 124.8 KB, free 102.7 MB)
2016-06-13 14:05:00,116  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_424_piece0 in memory on localhost:44356 (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:05:00,116  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 424 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,121  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,121  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 211 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,121  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 221 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,121  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,121  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,122  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 221 (MapPartitionsRDD[254] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,123  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_425 stored as values in memory (estimated size 55.2 KB, free 102.7 MB)
2016-06-13 14:05:00,124  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_425_piece0 stored as bytes in memory (estimated size 8.1 KB, free 102.7 MB)
2016-06-13 14:05:00,125  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_425_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,125  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 425 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,125  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 221 (MapPartitionsRDD[254] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,125  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 221.0 with 2 tasks
2016-06-13 14:05:00,126  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 221.0 (TID 425, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,126  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 221.0 (TID 426, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,126  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 221.0 (TID 426)
2016-06-13 14:05:00,126  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 221.0 (TID 425)
2016-06-13 14:05:00,128  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,129  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,129  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 221.0 (TID 426). 45217 bytes result sent to driver
2016-06-13 14:05:00,130  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 221.0 (TID 426) in 4 ms on localhost (1/2)
2016-06-13 14:05:00,131  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 221.0 (TID 425). 45217 bytes result sent to driver
2016-06-13 14:05:00,132  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 221.0 (TID 425) in 6 ms on localhost (2/2)
2016-06-13 14:05:00,132  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 221.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,132  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 221 (treeAggregate at RowMatrix.scala:93) finished in 0.006 s
2016-06-13 14:05:00,132  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 211 finished: treeAggregate at RowMatrix.scala:93, took 0.011473 s
2016-06-13 14:05:00,138  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_426 stored as values in memory (estimated size 124.9 KB, free 102.9 MB)
2016-06-13 14:05:00,139  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_426_piece0 stored as bytes in memory (estimated size 124.6 KB, free 103.0 MB)
2016-06-13 14:05:00,139  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_426_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:00,141  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 426 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,149  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,150  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 212 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,150  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 222 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,150  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,150  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,150  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 222 (MapPartitionsRDD[255] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,152  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_427 stored as values in memory (estimated size 55.2 KB, free 103.0 MB)
2016-06-13 14:05:00,154  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_427_piece0 stored as bytes in memory (estimated size 8.1 KB, free 103.0 MB)
2016-06-13 14:05:00,154  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_427_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,155  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 427 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,155  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 222 (MapPartitionsRDD[255] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,155  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 222.0 with 2 tasks
2016-06-13 14:05:00,155  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 222.0 (TID 427, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,156  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 222.0 (TID 428, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,156  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 222.0 (TID 428)
2016-06-13 14:05:00,156  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 222.0 (TID 427)
2016-06-13 14:05:00,158  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,158  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,161  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 222.0 (TID 428). 45217 bytes result sent to driver
2016-06-13 14:05:00,161  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 222.0 (TID 428) in 6 ms on localhost (1/2)
2016-06-13 14:05:00,162  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 222.0 (TID 427). 45217 bytes result sent to driver
2016-06-13 14:05:00,162  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 222.0 (TID 427) in 7 ms on localhost (2/2)
2016-06-13 14:05:00,162  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 222.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,162  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 222 (treeAggregate at RowMatrix.scala:93) finished in 0.006 s
2016-06-13 14:05:00,163  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 212 finished: treeAggregate at RowMatrix.scala:93, took 0.013069 s
2016-06-13 14:05:00,168  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_428 stored as values in memory (estimated size 124.9 KB, free 103.2 MB)
2016-06-13 14:05:00,170  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_428_piece0 stored as bytes in memory (estimated size 124.7 KB, free 103.3 MB)
2016-06-13 14:05:00,170  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_428_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:05:00,170  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 428 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,177  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,177  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 213 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,177  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 223 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,177  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,177  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,178  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 223 (MapPartitionsRDD[256] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,179  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_429 stored as values in memory (estimated size 55.2 KB, free 103.3 MB)
2016-06-13 14:05:00,180  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_429_piece0 stored as bytes in memory (estimated size 8.1 KB, free 103.3 MB)
2016-06-13 14:05:00,180  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_429_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,180  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 429 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,180  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 223 (MapPartitionsRDD[256] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,180  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 223.0 with 2 tasks
2016-06-13 14:05:00,181  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 223.0 (TID 429, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,181  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 223.0 (TID 430, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,181  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 223.0 (TID 430)
2016-06-13 14:05:00,183  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,186  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 223.0 (TID 430). 45217 bytes result sent to driver
2016-06-13 14:05:00,190  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 223.0 (TID 429)
2016-06-13 14:05:00,191  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 223.0 (TID 430) in 9 ms on localhost (1/2)
2016-06-13 14:05:00,193  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,196  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 223.0 (TID 429). 45217 bytes result sent to driver
2016-06-13 14:05:00,202  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 223.0 (TID 429) in 21 ms on localhost (2/2)
2016-06-13 14:05:00,203  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 223.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,203  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 223 (treeAggregate at RowMatrix.scala:93) finished in 0.022 s
2016-06-13 14:05:00,204  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 213 finished: treeAggregate at RowMatrix.scala:93, took 0.026865 s
2016-06-13 14:05:00,210  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_430 stored as values in memory (estimated size 124.9 KB, free 103.5 MB)
2016-06-13 14:05:00,212  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_430_piece0 stored as bytes in memory (estimated size 124.6 KB, free 103.6 MB)
2016-06-13 14:05:00,212  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_430_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:00,212  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 430 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,220  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,220  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 214 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,220  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 224 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,220  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,220  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,221  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 224 (MapPartitionsRDD[257] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,222  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_431 stored as values in memory (estimated size 55.2 KB, free 103.6 MB)
2016-06-13 14:05:00,223  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_431_piece0 stored as bytes in memory (estimated size 8.1 KB, free 103.6 MB)
2016-06-13 14:05:00,223  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_431_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,224  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 431 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,224  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 224 (MapPartitionsRDD[257] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,224  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 224.0 with 2 tasks
2016-06-13 14:05:00,224  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 224.0 (TID 431, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,224  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 224.0 (TID 432, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,225  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 224.0 (TID 431)
2016-06-13 14:05:00,226  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 224.0 (TID 432)
2016-06-13 14:05:00,226  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,229  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 224.0 (TID 431). 45217 bytes result sent to driver
2016-06-13 14:05:00,231  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,231  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 224.0 (TID 431) in 7 ms on localhost (1/2)
2016-06-13 14:05:00,233  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 224.0 (TID 432). 45217 bytes result sent to driver
2016-06-13 14:05:00,234  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 224.0 (TID 432) in 10 ms on localhost (2/2)
2016-06-13 14:05:00,234  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 224 (treeAggregate at RowMatrix.scala:93) finished in 0.010 s
2016-06-13 14:05:00,234  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 224.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,235  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 214 finished: treeAggregate at RowMatrix.scala:93, took 0.014938 s
2016-06-13 14:05:00,241  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_432 stored as values in memory (estimated size 124.9 KB, free 103.8 MB)
2016-06-13 14:05:00,243  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_432_piece0 stored as bytes in memory (estimated size 124.6 KB, free 103.9 MB)
2016-06-13 14:05:00,244  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_432_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:00,244  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 432 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,252  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,252  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 215 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,252  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 225 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,252  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,253  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,253  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 225 (MapPartitionsRDD[258] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,255  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_433 stored as values in memory (estimated size 55.2 KB, free 103.9 MB)
2016-06-13 14:05:00,255  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_433_piece0 stored as bytes in memory (estimated size 8.1 KB, free 104.0 MB)
2016-06-13 14:05:00,256  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_433_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,256  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 433 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,256  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 225 (MapPartitionsRDD[258] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,256  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 225.0 with 2 tasks
2016-06-13 14:05:00,256  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 225.0 (TID 433, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,256  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 225.0 (TID 434, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,257  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 225.0 (TID 433)
2016-06-13 14:05:00,257  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 225.0 (TID 434)
2016-06-13 14:05:00,259  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,260  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,261  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 225.0 (TID 433). 45217 bytes result sent to driver
2016-06-13 14:05:00,262  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 225.0 (TID 433) in 6 ms on localhost (1/2)
2016-06-13 14:05:00,264  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 225.0 (TID 434). 45217 bytes result sent to driver
2016-06-13 14:05:00,264  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 225.0 (TID 434) in 8 ms on localhost (2/2)
2016-06-13 14:05:00,264  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 225 (treeAggregate at RowMatrix.scala:93) finished in 0.008 s
2016-06-13 14:05:00,264  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 225.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,266  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 215 finished: treeAggregate at RowMatrix.scala:93, took 0.014375 s
2016-06-13 14:05:00,272  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_434 stored as values in memory (estimated size 124.9 KB, free 104.1 MB)
2016-06-13 14:05:00,273  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_434_piece0 stored as bytes in memory (estimated size 124.7 KB, free 104.2 MB)
2016-06-13 14:05:00,273  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_434_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:05:00,273  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 434 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,278  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,279  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 216 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,279  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 226 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,279  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,279  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,279  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 226 (MapPartitionsRDD[259] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,280  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_435 stored as values in memory (estimated size 55.2 KB, free 104.2 MB)
2016-06-13 14:05:00,281  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_435_piece0 stored as bytes in memory (estimated size 8.1 KB, free 104.3 MB)
2016-06-13 14:05:00,281  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_435_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,281  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 435 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,281  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 226 (MapPartitionsRDD[259] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,281  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 226.0 with 2 tasks
2016-06-13 14:05:00,282  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 226.0 (TID 435, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,282  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 226.0 (TID 436, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,282  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 226.0 (TID 435)
2016-06-13 14:05:00,282  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 226.0 (TID 436)
2016-06-13 14:05:00,284  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,284  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,287  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 226.0 (TID 435). 45217 bytes result sent to driver
2016-06-13 14:05:00,287  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 226.0 (TID 435) in 6 ms on localhost (1/2)
2016-06-13 14:05:00,290  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 226.0 (TID 436). 45217 bytes result sent to driver
2016-06-13 14:05:00,290  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 226.0 (TID 436) in 8 ms on localhost (2/2)
2016-06-13 14:05:00,290  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 226 (treeAggregate at RowMatrix.scala:93) finished in 0.009 s
2016-06-13 14:05:00,290  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 226.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,291  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 216 finished: treeAggregate at RowMatrix.scala:93, took 0.012362 s
2016-06-13 14:05:00,296  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_436 stored as values in memory (estimated size 124.9 KB, free 104.4 MB)
2016-06-13 14:05:00,298  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_436_piece0 stored as bytes in memory (estimated size 124.6 KB, free 104.5 MB)
2016-06-13 14:05:00,298  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_436_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:00,299  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 436 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,306  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,306  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 217 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,306  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 227 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,306  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,307  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,307  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 227 (MapPartitionsRDD[260] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,308  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_437 stored as values in memory (estimated size 55.2 KB, free 104.6 MB)
2016-06-13 14:05:00,309  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_437_piece0 stored as bytes in memory (estimated size 8.1 KB, free 104.6 MB)
2016-06-13 14:05:00,311  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_437_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,311  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 437 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,311  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 227 (MapPartitionsRDD[260] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,311  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 227.0 with 2 tasks
2016-06-13 14:05:00,312  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 227.0 (TID 437, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,312  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 227.0 (TID 438, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,312  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 227.0 (TID 437)
2016-06-13 14:05:00,315  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,317  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 227.0 (TID 437). 45217 bytes result sent to driver
2016-06-13 14:05:00,317  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 227.0 (TID 438)
2016-06-13 14:05:00,320  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,322  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 227.0 (TID 438). 45217 bytes result sent to driver
2016-06-13 14:05:00,322  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 227.0 (TID 437) in 10 ms on localhost (1/2)
2016-06-13 14:05:00,324  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 227.0 (TID 438) in 12 ms on localhost (2/2)
2016-06-13 14:05:00,324  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 227.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,325  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 227 (treeAggregate at RowMatrix.scala:93) finished in 0.013 s
2016-06-13 14:05:00,325  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 217 finished: treeAggregate at RowMatrix.scala:93, took 0.019491 s
2016-06-13 14:05:00,335  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_438 stored as values in memory (estimated size 124.9 KB, free 104.7 MB)
2016-06-13 14:05:00,337  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_438_piece0 stored as bytes in memory (estimated size 124.7 KB, free 104.8 MB)
2016-06-13 14:05:00,337  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_438_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:05:00,338  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 438 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,345  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,345  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 218 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,345  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 228 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,345  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,346  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,346  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 228 (MapPartitionsRDD[261] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,347  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_439 stored as values in memory (estimated size 55.2 KB, free 104.9 MB)
2016-06-13 14:05:00,348  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_439_piece0 stored as bytes in memory (estimated size 8.1 KB, free 104.9 MB)
2016-06-13 14:05:00,349  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_439_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,349  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 439 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,349  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 228 (MapPartitionsRDD[261] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,349  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 228.0 with 2 tasks
2016-06-13 14:05:00,350  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 228.0 (TID 439, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,350  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 228.0 (TID 440, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,350  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 228.0 (TID 439)
2016-06-13 14:05:00,353  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,354  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 228.0 (TID 440)
2016-06-13 14:05:00,356  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,360  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 228.0 (TID 440). 45217 bytes result sent to driver
2016-06-13 14:05:00,361  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 228.0 (TID 439). 45217 bytes result sent to driver
2016-06-13 14:05:00,361  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 228.0 (TID 440) in 11 ms on localhost (1/2)
2016-06-13 14:05:00,361  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 228.0 (TID 439) in 11 ms on localhost (2/2)
2016-06-13 14:05:00,362  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 228.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,362  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 228 (treeAggregate at RowMatrix.scala:93) finished in 0.012 s
2016-06-13 14:05:00,363  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 218 finished: treeAggregate at RowMatrix.scala:93, took 0.018037 s
2016-06-13 14:05:00,370  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_440 stored as values in memory (estimated size 124.9 KB, free 105.0 MB)
2016-06-13 14:05:00,372  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_440_piece0 stored as bytes in memory (estimated size 124.6 KB, free 105.1 MB)
2016-06-13 14:05:00,373  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_440_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:00,374  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 440 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,381  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,382  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 219 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,382  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 229 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,382  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,383  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,384  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 229 (MapPartitionsRDD[262] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,385  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_441 stored as values in memory (estimated size 55.2 KB, free 105.2 MB)
2016-06-13 14:05:00,386  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_441_piece0 stored as bytes in memory (estimated size 8.1 KB, free 105.2 MB)
2016-06-13 14:05:00,387  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_441_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,388  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 441 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,389  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 229 (MapPartitionsRDD[262] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,390  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 229.0 with 2 tasks
2016-06-13 14:05:00,391  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 229.0 (TID 441, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,391  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 229.0 (TID 442, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,391  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 229.0 (TID 441)
2016-06-13 14:05:00,392  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 229.0 (TID 442)
2016-06-13 14:05:00,395  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,398  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,401  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 229.0 (TID 442). 45217 bytes result sent to driver
2016-06-13 14:05:00,403  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 229.0 (TID 441). 45217 bytes result sent to driver
2016-06-13 14:05:00,404  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 229.0 (TID 442) in 13 ms on localhost (1/2)
2016-06-13 14:05:00,404  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 229.0 (TID 441) in 14 ms on localhost (2/2)
2016-06-13 14:05:00,404  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 229.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,406  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 229 (treeAggregate at RowMatrix.scala:93) finished in 0.016 s
2016-06-13 14:05:00,407  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 219 finished: treeAggregate at RowMatrix.scala:93, took 0.025810 s
2016-06-13 14:05:00,413  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_442 stored as values in memory (estimated size 124.9 KB, free 105.3 MB)
2016-06-13 14:05:00,415  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_442_piece0 stored as bytes in memory (estimated size 124.6 KB, free 105.4 MB)
2016-06-13 14:05:00,415  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_442_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:00,416  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 442 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,423  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,423  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 220 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,423  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 230 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,423  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,424  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,424  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 230 (MapPartitionsRDD[263] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,425  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_443 stored as values in memory (estimated size 55.2 KB, free 105.5 MB)
2016-06-13 14:05:00,426  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_443_piece0 stored as bytes in memory (estimated size 8.1 KB, free 105.5 MB)
2016-06-13 14:05:00,427  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_443_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,427  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 443 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,427  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 230 (MapPartitionsRDD[263] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,428  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 230.0 with 2 tasks
2016-06-13 14:05:00,428  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 230.0 (TID 443, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,428  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 230.0 (TID 444, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,429  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 230.0 (TID 443)
2016-06-13 14:05:00,429  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 230.0 (TID 444)
2016-06-13 14:05:00,432  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,434  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 230.0 (TID 444). 45217 bytes result sent to driver
2016-06-13 14:05:00,436  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,439  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 230.0 (TID 443). 45217 bytes result sent to driver
2016-06-13 14:05:00,440  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 230.0 (TID 444) in 12 ms on localhost (1/2)
2016-06-13 14:05:00,440  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 230.0 (TID 443) in 12 ms on localhost (2/2)
2016-06-13 14:05:00,440  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 230.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,441  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 230 (treeAggregate at RowMatrix.scala:93) finished in 0.004 s
2016-06-13 14:05:00,441  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 220 finished: treeAggregate at RowMatrix.scala:93, took 0.018175 s
2016-06-13 14:05:00,449  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_444 stored as values in memory (estimated size 124.9 KB, free 105.6 MB)
2016-06-13 14:05:00,451  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_444_piece0 stored as bytes in memory (estimated size 124.7 KB, free 105.7 MB)
2016-06-13 14:05:00,451  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_444_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:05:00,453  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 444 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,460  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,461  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 221 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,461  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 231 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,461  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,462  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,462  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 231 (MapPartitionsRDD[264] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,463  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_445 stored as values in memory (estimated size 55.2 KB, free 105.8 MB)
2016-06-13 14:05:00,464  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_445_piece0 stored as bytes in memory (estimated size 8.1 KB, free 105.8 MB)
2016-06-13 14:05:00,464  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_445_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,465  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 445 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,465  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 231 (MapPartitionsRDD[264] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,465  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 231.0 with 2 tasks
2016-06-13 14:05:00,465  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 231.0 (TID 445, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,466  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 231.0 (TID 446, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,466  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 231.0 (TID 445)
2016-06-13 14:05:00,466  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 231.0 (TID 446)
2016-06-13 14:05:00,468  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,472  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,475  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 231.0 (TID 445). 45217 bytes result sent to driver
2016-06-13 14:05:00,476  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 231.0 (TID 446). 45217 bytes result sent to driver
2016-06-13 14:05:00,477  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 231.0 (TID 445) in 12 ms on localhost (1/2)
2016-06-13 14:05:00,477  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 231.0 (TID 446) in 11 ms on localhost (2/2)
2016-06-13 14:05:00,477  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 231.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,477  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 231 (treeAggregate at RowMatrix.scala:93) finished in 0.003 s
2016-06-13 14:05:00,477  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 221 finished: treeAggregate at RowMatrix.scala:93, took 0.016151 s
2016-06-13 14:05:00,484  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_446 stored as values in memory (estimated size 124.9 KB, free 105.9 MB)
2016-06-13 14:05:00,485  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_446_piece0 stored as bytes in memory (estimated size 124.6 KB, free 106.0 MB)
2016-06-13 14:05:00,486  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_446_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:00,486  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 446 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,493  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,493  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 222 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,493  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 232 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,493  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,494  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,494  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 232 (MapPartitionsRDD[265] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,495  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_447 stored as values in memory (estimated size 55.2 KB, free 106.1 MB)
2016-06-13 14:05:00,496  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_447_piece0 stored as bytes in memory (estimated size 8.1 KB, free 106.1 MB)
2016-06-13 14:05:00,497  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_447_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,498  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 447 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,498  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 232 (MapPartitionsRDD[265] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,498  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 232.0 with 2 tasks
2016-06-13 14:05:00,498  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 232.0 (TID 447, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,498  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 232.0 (TID 448, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,499  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 232.0 (TID 447)
2016-06-13 14:05:00,499  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 232.0 (TID 448)
2016-06-13 14:05:00,501  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,501  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,504  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 232.0 (TID 448). 45217 bytes result sent to driver
2016-06-13 14:05:00,504  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 232.0 (TID 447). 45217 bytes result sent to driver
2016-06-13 14:05:00,504  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 232.0 (TID 447) in 6 ms on localhost (1/2)
2016-06-13 14:05:00,504  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 232.0 (TID 448) in 6 ms on localhost (2/2)
2016-06-13 14:05:00,505  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 232.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,505  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 232 (treeAggregate at RowMatrix.scala:93) finished in 0.007 s
2016-06-13 14:05:00,505  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 222 finished: treeAggregate at RowMatrix.scala:93, took 0.012058 s
2016-06-13 14:05:00,512  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_448 stored as values in memory (estimated size 124.9 KB, free 106.2 MB)
2016-06-13 14:05:00,513  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_448_piece0 stored as bytes in memory (estimated size 124.6 KB, free 106.3 MB)
2016-06-13 14:05:00,513  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_448_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:00,514  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 448 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,526  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,527  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 223 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,527  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 233 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,527  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,527  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,527  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 233 (MapPartitionsRDD[266] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,529  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_449 stored as values in memory (estimated size 55.2 KB, free 106.4 MB)
2016-06-13 14:05:00,530  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_449_piece0 stored as bytes in memory (estimated size 8.1 KB, free 106.4 MB)
2016-06-13 14:05:00,531  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_449_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,531  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 449 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,531  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 233 (MapPartitionsRDD[266] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,531  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 233.0 with 2 tasks
2016-06-13 14:05:00,531  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 233.0 (TID 449, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,532  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 233.0 (TID 450, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,532  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 233.0 (TID 449)
2016-06-13 14:05:00,532  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 233.0 (TID 450)
2016-06-13 14:05:00,534  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,536  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 233.0 (TID 450). 45217 bytes result sent to driver
2016-06-13 14:05:00,537  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 233.0 (TID 450) in 5 ms on localhost (1/2)
2016-06-13 14:05:00,539  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,542  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 233.0 (TID 449). 45217 bytes result sent to driver
2016-06-13 14:05:00,543  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 233.0 (TID 449) in 12 ms on localhost (2/2)
2016-06-13 14:05:00,543  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 233.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,543  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 233 (treeAggregate at RowMatrix.scala:93) finished in 0.001 s
2016-06-13 14:05:00,544  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 223 finished: treeAggregate at RowMatrix.scala:93, took 0.017326 s
2016-06-13 14:05:00,551  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_450 stored as values in memory (estimated size 124.9 KB, free 106.5 MB)
2016-06-13 14:05:00,553  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_450_piece0 stored as bytes in memory (estimated size 124.6 KB, free 106.6 MB)
2016-06-13 14:05:00,553  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_450_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:00,553  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 450 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,565  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,566  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 224 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,566  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 234 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,566  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,567  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,567  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 234 (MapPartitionsRDD[267] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,570  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_451 stored as values in memory (estimated size 55.2 KB, free 106.7 MB)
2016-06-13 14:05:00,571  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_451_piece0 stored as bytes in memory (estimated size 8.1 KB, free 106.7 MB)
2016-06-13 14:05:00,572  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_451_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,573  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 451 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,573  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 234 (MapPartitionsRDD[267] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,573  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 234.0 with 2 tasks
2016-06-13 14:05:00,574  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 234.0 (TID 451, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,575  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 234.0 (TID 452, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,575  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 234.0 (TID 451)
2016-06-13 14:05:00,575  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 234.0 (TID 452)
2016-06-13 14:05:00,581  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,581  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,583  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 234.0 (TID 452). 45217 bytes result sent to driver
2016-06-13 14:05:00,584  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 234.0 (TID 451). 45217 bytes result sent to driver
2016-06-13 14:05:00,585  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 234.0 (TID 452) in 10 ms on localhost (1/2)
2016-06-13 14:05:00,585  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 234.0 (TID 451) in 11 ms on localhost (2/2)
2016-06-13 14:05:00,585  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 234.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,586  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 234 (treeAggregate at RowMatrix.scala:93) finished in 0.005 s
2016-06-13 14:05:00,586  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 224 finished: treeAggregate at RowMatrix.scala:93, took 0.021209 s
2016-06-13 14:05:00,592  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_452 stored as values in memory (estimated size 124.9 KB, free 106.8 MB)
2016-06-13 14:05:00,593  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_452_piece0 stored as bytes in memory (estimated size 124.6 KB, free 106.9 MB)
2016-06-13 14:05:00,593  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_452_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:00,593  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 452 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,598  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,598  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 225 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,598  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 235 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,598  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,598  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,598  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 235 (MapPartitionsRDD[268] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,599  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_453 stored as values in memory (estimated size 55.2 KB, free 107.0 MB)
2016-06-13 14:05:00,600  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_453_piece0 stored as bytes in memory (estimated size 8.1 KB, free 107.0 MB)
2016-06-13 14:05:00,600  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_453_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,600  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 453 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,601  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 235 (MapPartitionsRDD[268] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,601  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 235.0 with 2 tasks
2016-06-13 14:05:00,601  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 235.0 (TID 453, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,601  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 235.0 (TID 454, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,601  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 235.0 (TID 454)
2016-06-13 14:05:00,601  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 235.0 (TID 453)
2016-06-13 14:05:00,603  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,603  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,605  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 235.0 (TID 454). 45217 bytes result sent to driver
2016-06-13 14:05:00,605  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 235.0 (TID 453). 45217 bytes result sent to driver
2016-06-13 14:05:00,606  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 235.0 (TID 454) in 5 ms on localhost (1/2)
2016-06-13 14:05:00,606  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 235.0 (TID 453) in 5 ms on localhost (2/2)
2016-06-13 14:05:00,606  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 235 (treeAggregate at RowMatrix.scala:93) finished in 0.005 s
2016-06-13 14:05:00,606  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 235.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,606  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 225 finished: treeAggregate at RowMatrix.scala:93, took 0.008227 s
2016-06-13 14:05:00,610  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_454 stored as values in memory (estimated size 124.9 KB, free 107.1 MB)
2016-06-13 14:05:00,611  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_454_piece0 stored as bytes in memory (estimated size 124.6 KB, free 107.2 MB)
2016-06-13 14:05:00,611  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_454_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:00,612  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 454 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,616  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,616  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 226 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,616  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 236 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,616  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,616  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,617  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 236 (MapPartitionsRDD[269] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,617  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_455 stored as values in memory (estimated size 55.2 KB, free 107.3 MB)
2016-06-13 14:05:00,618  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_455_piece0 stored as bytes in memory (estimated size 8.1 KB, free 107.3 MB)
2016-06-13 14:05:00,619  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_455_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,619  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 455 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,619  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 236 (MapPartitionsRDD[269] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,619  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 236.0 with 2 tasks
2016-06-13 14:05:00,619  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 236.0 (TID 455, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,621  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 236.0 (TID 456, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,622  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 236.0 (TID 455)
2016-06-13 14:05:00,622  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 236.0 (TID 456)
2016-06-13 14:05:00,625  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,627  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 236.0 (TID 456). 45217 bytes result sent to driver
2016-06-13 14:05:00,628  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 236.0 (TID 456) in 9 ms on localhost (1/2)
2016-06-13 14:05:00,631  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,633  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 236.0 (TID 455). 45217 bytes result sent to driver
2016-06-13 14:05:00,633  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 236.0 (TID 455) in 14 ms on localhost (2/2)
2016-06-13 14:05:00,633  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 236.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,633  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 236 (treeAggregate at RowMatrix.scala:93) finished in 0.014 s
2016-06-13 14:05:00,634  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 226 finished: treeAggregate at RowMatrix.scala:93, took 0.017609 s
2016-06-13 14:05:00,638  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_456 stored as values in memory (estimated size 124.9 KB, free 107.4 MB)
2016-06-13 14:05:00,639  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_456_piece0 stored as bytes in memory (estimated size 124.6 KB, free 107.6 MB)
2016-06-13 14:05:00,639  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_456_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:00,640  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 456 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,644  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,644  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 227 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,644  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 237 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,644  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,644  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,644  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 237 (MapPartitionsRDD[270] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,645  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_457 stored as values in memory (estimated size 55.2 KB, free 107.6 MB)
2016-06-13 14:05:00,646  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_457_piece0 stored as bytes in memory (estimated size 8.1 KB, free 107.6 MB)
2016-06-13 14:05:00,646  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_457_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,646  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 457 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,647  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 237 (MapPartitionsRDD[270] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,647  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 237.0 with 2 tasks
2016-06-13 14:05:00,647  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 237.0 (TID 457, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,647  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 237.0 (TID 458, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,647  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 237.0 (TID 457)
2016-06-13 14:05:00,647  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 237.0 (TID 458)
2016-06-13 14:05:00,649  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,649  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,650  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 237.0 (TID 458). 45217 bytes result sent to driver
2016-06-13 14:05:00,651  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 237.0 (TID 458) in 4 ms on localhost (1/2)
2016-06-13 14:05:00,651  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 237.0 (TID 457). 45217 bytes result sent to driver
2016-06-13 14:05:00,652  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 237.0 (TID 457) in 4 ms on localhost (2/2)
2016-06-13 14:05:00,652  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 237.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,652  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 237 (treeAggregate at RowMatrix.scala:93) finished in 0.005 s
2016-06-13 14:05:00,652  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 227 finished: treeAggregate at RowMatrix.scala:93, took 0.008178 s
2016-06-13 14:05:00,657  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_458 stored as values in memory (estimated size 124.9 KB, free 107.7 MB)
2016-06-13 14:05:00,658  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_458_piece0 stored as bytes in memory (estimated size 124.6 KB, free 107.9 MB)
2016-06-13 14:05:00,658  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_458_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:00,658  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 458 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,663  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,665  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 228 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,665  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 238 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,665  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,666  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,666  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 238 (MapPartitionsRDD[271] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,668  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_459 stored as values in memory (estimated size 55.2 KB, free 107.9 MB)
2016-06-13 14:05:00,670  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_459_piece0 stored as bytes in memory (estimated size 8.1 KB, free 107.9 MB)
2016-06-13 14:05:00,670  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_459_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,671  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 459 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,671  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 238 (MapPartitionsRDD[271] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,671  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 238.0 with 2 tasks
2016-06-13 14:05:00,672  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 238.0 (TID 459, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,673  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 238.0 (TID 460, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,673  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 238.0 (TID 459)
2016-06-13 14:05:00,675  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 238.0 (TID 460)
2016-06-13 14:05:00,676  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,677  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,678  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 238.0 (TID 459). 45217 bytes result sent to driver
2016-06-13 14:05:00,679  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 238.0 (TID 459) in 7 ms on localhost (1/2)
2016-06-13 14:05:00,681  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 238.0 (TID 460). 45217 bytes result sent to driver
2016-06-13 14:05:00,682  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 238.0 (TID 460) in 10 ms on localhost (2/2)
2016-06-13 14:05:00,682  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 238.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,683  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 238 (treeAggregate at RowMatrix.scala:93) finished in 0.011 s
2016-06-13 14:05:00,685  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 228 finished: treeAggregate at RowMatrix.scala:93, took 0.022330 s
2016-06-13 14:05:00,692  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_460 stored as values in memory (estimated size 124.9 KB, free 108.0 MB)
2016-06-13 14:05:00,693  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_460_piece0 stored as bytes in memory (estimated size 124.7 KB, free 108.2 MB)
2016-06-13 14:05:00,694  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_460_piece0 in memory on localhost:44356 (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:05:00,694  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 460 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,701  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,702  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 229 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,702  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 239 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,702  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,702  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,703  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 239 (MapPartitionsRDD[272] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,704  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_461 stored as values in memory (estimated size 55.2 KB, free 108.2 MB)
2016-06-13 14:05:00,705  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_461_piece0 stored as bytes in memory (estimated size 8.1 KB, free 108.2 MB)
2016-06-13 14:05:00,706  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_461_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,706  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 461 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,706  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 239 (MapPartitionsRDD[272] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,706  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 239.0 with 2 tasks
2016-06-13 14:05:00,707  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 239.0 (TID 461, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,707  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 239.0 (TID 462, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,707  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 239.0 (TID 461)
2016-06-13 14:05:00,710  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,712  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 239.0 (TID 462)
2016-06-13 14:05:00,713  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 239.0 (TID 461). 45217 bytes result sent to driver
2016-06-13 14:05:00,714  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 239.0 (TID 461) in 7 ms on localhost (1/2)
2016-06-13 14:05:00,717  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,720  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 239.0 (TID 462). 45217 bytes result sent to driver
2016-06-13 14:05:00,721  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 239.0 (TID 462) in 14 ms on localhost (2/2)
2016-06-13 14:05:00,721  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 239.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,721  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 239 (treeAggregate at RowMatrix.scala:93) finished in 0.014 s
2016-06-13 14:05:00,721  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 229 finished: treeAggregate at RowMatrix.scala:93, took 0.019813 s
2016-06-13 14:05:00,728  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_462 stored as values in memory (estimated size 124.9 KB, free 108.4 MB)
2016-06-13 14:05:00,729  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_462_piece0 stored as bytes in memory (estimated size 124.6 KB, free 108.5 MB)
2016-06-13 14:05:00,730  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_462_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:00,730  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 462 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,735  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,735  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 230 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,735  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 240 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,735  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,735  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,735  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 240 (MapPartitionsRDD[273] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,736  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_463 stored as values in memory (estimated size 55.2 KB, free 108.5 MB)
2016-06-13 14:05:00,737  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_463_piece0 stored as bytes in memory (estimated size 8.1 KB, free 108.5 MB)
2016-06-13 14:05:00,738  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_463_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,738  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 463 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,738  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 240 (MapPartitionsRDD[273] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,738  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 240.0 with 2 tasks
2016-06-13 14:05:00,738  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 240.0 (TID 463, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,739  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 240.0 (TID 464, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,739  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 240.0 (TID 464)
2016-06-13 14:05:00,740  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 240.0 (TID 463)
2016-06-13 14:05:00,741  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,743  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,743  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 240.0 (TID 464). 45217 bytes result sent to driver
2016-06-13 14:05:00,744  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 240.0 (TID 464) in 6 ms on localhost (1/2)
2016-06-13 14:05:00,745  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 240.0 (TID 463). 45217 bytes result sent to driver
2016-06-13 14:05:00,746  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 240.0 (TID 463) in 8 ms on localhost (2/2)
2016-06-13 14:05:00,746  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 240.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,746  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 240 (treeAggregate at RowMatrix.scala:93) finished in 0.008 s
2016-06-13 14:05:00,746  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 230 finished: treeAggregate at RowMatrix.scala:93, took 0.011323 s
2016-06-13 14:05:00,751  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_464 stored as values in memory (estimated size 124.9 KB, free 108.7 MB)
2016-06-13 14:05:00,752  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_464_piece0 stored as bytes in memory (estimated size 124.6 KB, free 108.8 MB)
2016-06-13 14:05:00,752  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_464_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:00,752  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 464 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,757  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,757  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 231 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,757  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 241 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,757  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,757  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,757  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 241 (MapPartitionsRDD[274] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,758  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_465 stored as values in memory (estimated size 55.2 KB, free 108.8 MB)
2016-06-13 14:05:00,759  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_465_piece0 stored as bytes in memory (estimated size 8.1 KB, free 108.8 MB)
2016-06-13 14:05:00,759  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_465_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,760  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 465 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,760  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 241 (MapPartitionsRDD[274] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,760  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 241.0 with 2 tasks
2016-06-13 14:05:00,760  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 241.0 (TID 465, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,761  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 241.0 (TID 466, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,761  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 241.0 (TID 465)
2016-06-13 14:05:00,761  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 241.0 (TID 466)
2016-06-13 14:05:00,763  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,764  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,765  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 241.0 (TID 465). 45217 bytes result sent to driver
2016-06-13 14:05:00,765  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 241.0 (TID 465) in 5 ms on localhost (1/2)
2016-06-13 14:05:00,766  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 241.0 (TID 466). 45217 bytes result sent to driver
2016-06-13 14:05:00,767  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 241.0 (TID 466) in 7 ms on localhost (2/2)
2016-06-13 14:05:00,767  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 241 (treeAggregate at RowMatrix.scala:93) finished in 0.007 s
2016-06-13 14:05:00,767  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 241.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,768  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 231 finished: treeAggregate at RowMatrix.scala:93, took 0.010700 s
2016-06-13 14:05:00,772  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_466 stored as values in memory (estimated size 124.9 KB, free 109.0 MB)
2016-06-13 14:05:00,774  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_466_piece0 stored as bytes in memory (estimated size 124.6 KB, free 109.1 MB)
2016-06-13 14:05:00,774  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_466_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:00,774  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 466 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,779  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,779  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 232 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,779  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 242 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,779  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,779  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,779  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 242 (MapPartitionsRDD[275] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,781  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_467 stored as values in memory (estimated size 55.2 KB, free 109.1 MB)
2016-06-13 14:05:00,782  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_467_piece0 stored as bytes in memory (estimated size 8.1 KB, free 109.1 MB)
2016-06-13 14:05:00,782  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_467_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,782  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 467 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,782  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 242 (MapPartitionsRDD[275] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,782  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 242.0 with 2 tasks
2016-06-13 14:05:00,783  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 242.0 (TID 467, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,783  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 242.0 (TID 468, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,783  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 242.0 (TID 467)
2016-06-13 14:05:00,783  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 242.0 (TID 468)
2016-06-13 14:05:00,785  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,787  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 242.0 (TID 468). 45217 bytes result sent to driver
2016-06-13 14:05:00,787  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 242.0 (TID 468) in 4 ms on localhost (1/2)
2016-06-13 14:05:00,789  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,791  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 242.0 (TID 467). 45217 bytes result sent to driver
2016-06-13 14:05:00,792  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 242.0 (TID 467) in 9 ms on localhost (2/2)
2016-06-13 14:05:00,792  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 242.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,792  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 242 (treeAggregate at RowMatrix.scala:93) finished in 0.009 s
2016-06-13 14:05:00,792  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 232 finished: treeAggregate at RowMatrix.scala:93, took 0.013539 s
2016-06-13 14:05:00,799  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_468 stored as values in memory (estimated size 124.9 KB, free 109.3 MB)
2016-06-13 14:05:00,800  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_468_piece0 stored as bytes in memory (estimated size 124.6 KB, free 109.4 MB)
2016-06-13 14:05:00,800  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_468_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:00,801  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 468 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,807  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,807  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 233 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,807  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 243 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,807  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,808  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,808  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 243 (MapPartitionsRDD[276] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,809  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_469 stored as values in memory (estimated size 55.2 KB, free 109.4 MB)
2016-06-13 14:05:00,810  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_469_piece0 stored as bytes in memory (estimated size 8.1 KB, free 109.4 MB)
2016-06-13 14:05:00,811  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_469_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,811  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 469 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,811  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 243 (MapPartitionsRDD[276] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,811  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 243.0 with 2 tasks
2016-06-13 14:05:00,812  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 243.0 (TID 469, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,812  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 243.0 (TID 470, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,812  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 243.0 (TID 469)
2016-06-13 14:05:00,813  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 243.0 (TID 470)
2016-06-13 14:05:00,815  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,817  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 243.0 (TID 470). 45217 bytes result sent to driver
2016-06-13 14:05:00,818  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 243.0 (TID 470) in 6 ms on localhost (1/2)
2016-06-13 14:05:00,820  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,824  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 243.0 (TID 469). 45217 bytes result sent to driver
2016-06-13 14:05:00,825  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 243.0 (TID 469) in 13 ms on localhost (2/2)
2016-06-13 14:05:00,825  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 243.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,825  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 243 (treeAggregate at RowMatrix.scala:93) finished in 0.007 s
2016-06-13 14:05:00,825  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 233 finished: treeAggregate at RowMatrix.scala:93, took 0.018254 s
2016-06-13 14:05:00,832  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_470 stored as values in memory (estimated size 124.9 KB, free 109.6 MB)
2016-06-13 14:05:00,833  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_470_piece0 stored as bytes in memory (estimated size 124.6 KB, free 109.7 MB)
2016-06-13 14:05:00,834  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_470_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:00,834  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 470 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,840  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,840  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 234 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,840  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 244 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,841  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,841  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,841  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 244 (MapPartitionsRDD[277] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,842  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_471 stored as values in memory (estimated size 55.2 KB, free 109.7 MB)
2016-06-13 14:05:00,843  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_471_piece0 stored as bytes in memory (estimated size 8.1 KB, free 109.8 MB)
2016-06-13 14:05:00,844  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_471_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,844  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 471 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,844  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 244 (MapPartitionsRDD[277] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,844  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 244.0 with 2 tasks
2016-06-13 14:05:00,845  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 244.0 (TID 471, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,845  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 244.0 (TID 472, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,845  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 244.0 (TID 472)
2016-06-13 14:05:00,846  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 244.0 (TID 471)
2016-06-13 14:05:00,848  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,851  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 244.0 (TID 471). 45217 bytes result sent to driver
2016-06-13 14:05:00,854  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,855  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 244.0 (TID 471) in 11 ms on localhost (1/2)
2016-06-13 14:05:00,856  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 244.0 (TID 472). 45217 bytes result sent to driver
2016-06-13 14:05:00,858  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 244.0 (TID 472) in 13 ms on localhost (2/2)
2016-06-13 14:05:00,858  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 244.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,866  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 244 (treeAggregate at RowMatrix.scala:93) finished in 0.021 s
2016-06-13 14:05:00,867  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 234 finished: treeAggregate at RowMatrix.scala:93, took 0.026818 s
2016-06-13 14:05:00,876  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_472 stored as values in memory (estimated size 124.9 KB, free 109.9 MB)
2016-06-13 14:05:00,877  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_472_piece0 stored as bytes in memory (estimated size 124.6 KB, free 110.0 MB)
2016-06-13 14:05:00,878  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_472_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:00,879  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 472 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,894  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,897  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 235 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,897  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 245 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,897  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,897  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,897  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 245 (MapPartitionsRDD[278] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,899  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_473 stored as values in memory (estimated size 55.2 KB, free 110.1 MB)
2016-06-13 14:05:00,900  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_473_piece0 stored as bytes in memory (estimated size 8.1 KB, free 110.1 MB)
2016-06-13 14:05:00,900  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_473_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,901  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 473 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,901  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 245 (MapPartitionsRDD[278] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,902  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 245.0 with 2 tasks
2016-06-13 14:05:00,902  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 245.0 (TID 473, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,902  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 245.0 (TID 474, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,902  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 245.0 (TID 473)
2016-06-13 14:05:00,905  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,906  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 245.0 (TID 474)
2016-06-13 14:05:00,908  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 245.0 (TID 473). 45217 bytes result sent to driver
2016-06-13 14:05:00,908  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,911  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 245.0 (TID 474). 45217 bytes result sent to driver
2016-06-13 14:05:00,914  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 245.0 (TID 473) in 11 ms on localhost (1/2)
2016-06-13 14:05:00,914  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 245.0 (TID 474) in 12 ms on localhost (2/2)
2016-06-13 14:05:00,914  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 245.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,914  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 245 (treeAggregate at RowMatrix.scala:93) finished in 0.012 s
2016-06-13 14:05:00,914  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 235 finished: treeAggregate at RowMatrix.scala:93, took 0.020030 s
2016-06-13 14:05:00,920  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_474 stored as values in memory (estimated size 124.9 KB, free 110.2 MB)
2016-06-13 14:05:00,922  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_474_piece0 stored as bytes in memory (estimated size 124.6 KB, free 110.3 MB)
2016-06-13 14:05:00,922  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_474_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:00,923  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 474 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,932  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,933  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 236 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,933  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 246 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,933  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,934  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,934  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 246 (MapPartitionsRDD[279] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,935  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_475 stored as values in memory (estimated size 55.2 KB, free 110.4 MB)
2016-06-13 14:05:00,936  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_475_piece0 stored as bytes in memory (estimated size 8.1 KB, free 110.4 MB)
2016-06-13 14:05:00,938  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_475_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,938  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 475 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,939  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 246 (MapPartitionsRDD[279] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,939  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 246.0 with 2 tasks
2016-06-13 14:05:00,939  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 246.0 (TID 475, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,940  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 246.0 (TID 476, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,940  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 246.0 (TID 475)
2016-06-13 14:05:00,940  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 246.0 (TID 476)
2016-06-13 14:05:00,941  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,942  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,943  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 246.0 (TID 475). 45217 bytes result sent to driver
2016-06-13 14:05:00,944  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 246.0 (TID 476). 45217 bytes result sent to driver
2016-06-13 14:05:00,944  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 246.0 (TID 475) in 5 ms on localhost (1/2)
2016-06-13 14:05:00,944  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 246.0 (TID 476) in 5 ms on localhost (2/2)
2016-06-13 14:05:00,944  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 246.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,944  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 246 (treeAggregate at RowMatrix.scala:93) finished in 0.005 s
2016-06-13 14:05:00,945  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 236 finished: treeAggregate at RowMatrix.scala:93, took 0.012053 s
2016-06-13 14:05:00,952  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_476 stored as values in memory (estimated size 124.9 KB, free 110.5 MB)
2016-06-13 14:05:00,953  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_476_piece0 stored as bytes in memory (estimated size 124.6 KB, free 110.6 MB)
2016-06-13 14:05:00,953  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_476_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:00,953  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 476 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,959  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,960  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 237 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,960  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 247 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,960  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,960  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,960  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 247 (MapPartitionsRDD[280] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,961  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_477 stored as values in memory (estimated size 55.2 KB, free 110.7 MB)
2016-06-13 14:05:00,962  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_477_piece0 stored as bytes in memory (estimated size 8.1 KB, free 110.7 MB)
2016-06-13 14:05:00,963  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_477_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,963  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 477 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,963  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 247 (MapPartitionsRDD[280] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,963  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 247.0 with 2 tasks
2016-06-13 14:05:00,963  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 247.0 (TID 477, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,963  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 247.0 (TID 478, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,964  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 247.0 (TID 477)
2016-06-13 14:05:00,964  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 247.0 (TID 478)
2016-06-13 14:05:00,965  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,966  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,967  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 247.0 (TID 478). 45217 bytes result sent to driver
2016-06-13 14:05:00,968  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 247.0 (TID 478) in 5 ms on localhost (1/2)
2016-06-13 14:05:00,968  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 247.0 (TID 477). 45217 bytes result sent to driver
2016-06-13 14:05:00,969  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 247.0 (TID 477) in 5 ms on localhost (2/2)
2016-06-13 14:05:00,969  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 247.0, whose tasks have all completed, from pool 
2016-06-13 14:05:00,969  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 247 (treeAggregate at RowMatrix.scala:93) finished in 0.006 s
2016-06-13 14:05:00,969  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 237 finished: treeAggregate at RowMatrix.scala:93, took 0.009380 s
2016-06-13 14:05:00,975  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_478 stored as values in memory (estimated size 124.9 KB, free 110.8 MB)
2016-06-13 14:05:00,976  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_478_piece0 stored as bytes in memory (estimated size 124.5 KB, free 110.9 MB)
2016-06-13 14:05:00,977  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_478_piece0 in memory on localhost:44356 (size: 124.5 KB, free: 9.7 GB)
2016-06-13 14:05:00,977  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 478 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:00,984  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:00,985  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 238 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:00,985  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 248 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,985  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:00,985  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:00,985  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 248 (MapPartitionsRDD[281] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:00,987  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_479 stored as values in memory (estimated size 55.2 KB, free 111.0 MB)
2016-06-13 14:05:00,988  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_479_piece0 stored as bytes in memory (estimated size 8.1 KB, free 111.0 MB)
2016-06-13 14:05:00,988  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_479_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:00,988  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 479 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:00,989  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 248 (MapPartitionsRDD[281] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:00,989  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 248.0 with 2 tasks
2016-06-13 14:05:00,989  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 248.0 (TID 479, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,989  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 248.0 (TID 480, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:00,989  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 248.0 (TID 479)
2016-06-13 14:05:00,989  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 248.0 (TID 480)
2016-06-13 14:05:00,992  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:00,994  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 248.0 (TID 480). 45217 bytes result sent to driver
2016-06-13 14:05:00,996  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:00,999  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 248.0 (TID 479). 45217 bytes result sent to driver
2016-06-13 14:05:01,000  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 248.0 (TID 480) in 11 ms on localhost (1/2)
2016-06-13 14:05:01,001  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 248.0 (TID 479) in 12 ms on localhost (2/2)
2016-06-13 14:05:01,001  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 248 (treeAggregate at RowMatrix.scala:93) finished in 0.012 s
2016-06-13 14:05:01,001  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 248.0, whose tasks have all completed, from pool 
2016-06-13 14:05:01,001  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 238 finished: treeAggregate at RowMatrix.scala:93, took 0.016786 s
2016-06-13 14:05:01,008  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_480 stored as values in memory (estimated size 124.9 KB, free 111.1 MB)
2016-06-13 14:05:01,009  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_480_piece0 stored as bytes in memory (estimated size 124.5 KB, free 111.2 MB)
2016-06-13 14:05:01,009  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_480_piece0 in memory on localhost:44356 (size: 124.5 KB, free: 9.7 GB)
2016-06-13 14:05:01,010  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 480 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:01,016  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:01,016  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 239 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:01,016  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 249 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:01,016  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:01,017  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:01,017  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 249 (MapPartitionsRDD[282] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:01,018  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_481 stored as values in memory (estimated size 55.2 KB, free 111.3 MB)
2016-06-13 14:05:01,019  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_481_piece0 stored as bytes in memory (estimated size 8.1 KB, free 111.3 MB)
2016-06-13 14:05:01,020  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_481_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:01,020  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 481 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:01,020  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 249 (MapPartitionsRDD[282] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:01,020  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 249.0 with 2 tasks
2016-06-13 14:05:01,021  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 249.0 (TID 481, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:01,021  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 249.0 (TID 482, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:01,021  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 249.0 (TID 482)
2016-06-13 14:05:01,022  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 249.0 (TID 481)
2016-06-13 14:05:01,024  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:01,026  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 249.0 (TID 481). 45217 bytes result sent to driver
2016-06-13 14:05:01,026  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 249.0 (TID 481) in 5 ms on localhost (1/2)
2016-06-13 14:05:01,028  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:01,030  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 249.0 (TID 482). 45217 bytes result sent to driver
2016-06-13 14:05:01,030  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 249.0 (TID 482) in 9 ms on localhost (2/2)
2016-06-13 14:05:01,030  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 249 (treeAggregate at RowMatrix.scala:93) finished in 0.008 s
2016-06-13 14:05:01,030  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 249.0, whose tasks have all completed, from pool 
2016-06-13 14:05:01,031  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 239 finished: treeAggregate at RowMatrix.scala:93, took 0.014632 s
2016-06-13 14:05:01,036  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_482 stored as values in memory (estimated size 124.9 KB, free 111.4 MB)
2016-06-13 14:05:01,037  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_482_piece0 stored as bytes in memory (estimated size 124.6 KB, free 111.5 MB)
2016-06-13 14:05:01,037  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_482_piece0 in memory on localhost:44356 (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:01,037  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 482 from broadcast at RowMatrix.scala:92
2016-06-13 14:05:01,041  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: treeAggregate at RowMatrix.scala:93
2016-06-13 14:05:01,042  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 240 (treeAggregate at RowMatrix.scala:93) with 2 output partitions
2016-06-13 14:05:01,042  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 250 (treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:01,042  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:01,042  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:01,042  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 250 (MapPartitionsRDD[283] at treeAggregate at RowMatrix.scala:93), which has no missing parents
2016-06-13 14:05:01,043  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_483 stored as values in memory (estimated size 55.2 KB, free 111.6 MB)
2016-06-13 14:05:01,044  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_483_piece0 stored as bytes in memory (estimated size 8.1 KB, free 111.6 MB)
2016-06-13 14:05:01,044  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_483_piece0 in memory on localhost:44356 (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:01,045  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 483 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:01,045  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 250 (MapPartitionsRDD[283] at treeAggregate at RowMatrix.scala:93)
2016-06-13 14:05:01,045  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 250.0 with 2 tasks
2016-06-13 14:05:01,045  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 250.0 (TID 483, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:01,045  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 250.0 (TID 484, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:01,045  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 250.0 (TID 483)
2016-06-13 14:05:01,046  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 250.0 (TID 484)
2016-06-13 14:05:01,048  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:01,048  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:01,050  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 250.0 (TID 483). 45217 bytes result sent to driver
2016-06-13 14:05:01,050  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 250.0 (TID 484). 45217 bytes result sent to driver
2016-06-13 14:05:01,051  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 250.0 (TID 483) in 6 ms on localhost (1/2)
2016-06-13 14:05:01,051  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 250.0 (TID 484) in 6 ms on localhost (2/2)
2016-06-13 14:05:01,051  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 250.0, whose tasks have all completed, from pool 
2016-06-13 14:05:01,051  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 250 (treeAggregate at RowMatrix.scala:93) finished in 0.006 s
2016-06-13 14:05:01,051  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 240 finished: treeAggregate at RowMatrix.scala:93, took 0.009920 s
2016-06-13 14:05:01,351  WARN [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.mllib.linalg.distributed.RowMatrix) - The input data was not directly cached, which may hurt performance if its parent RDDs are also uncached.
2016-06-13 14:05:01,412  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_484 stored as values in memory (estimated size 3.7 MB, free 115.2 MB)
2016-06-13 14:05:01,422  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.storage.MemoryStore) - Block broadcast_484_piece0 stored as bytes in memory (estimated size 3.7 MB, free 118.9 MB)
2016-06-13 14:05:01,422  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_484_piece0 in memory on localhost:44356 (size: 3.7 MB, free: 9.7 GB)
2016-06-13 14:05:01,423  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Created broadcast 484 from broadcast at RowMatrix.scala:428
2016-06-13 14:05:02,852  INFO [Remote-akka.actor.default-dispatcher-20] (org.apache.spark.SparkContext) - Starting job: top at <console>:133
2016-06-13 14:05:02,854  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 241 (top at <console>:133) with 2 output partitions
2016-06-13 14:05:02,854  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 251 (top at <console>:133)
2016-06-13 14:05:02,854  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:02,858  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:02,858  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 251 (MapPartitionsRDD[287] at top at <console>:133), which has no missing parents
2016-06-13 14:05:02,867  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_485 stored as values in memory (estimated size 14.2 KB, free 118.9 MB)
2016-06-13 14:05:02,871  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_485_piece0 stored as bytes in memory (estimated size 6.3 KB, free 118.9 MB)
2016-06-13 14:05:02,887  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_485_piece0 in memory on localhost:44356 (size: 6.3 KB, free: 9.7 GB)
2016-06-13 14:05:02,888  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 485 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:02,888  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 251 (MapPartitionsRDD[287] at top at <console>:133)
2016-06-13 14:05:02,888  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 251.0 with 2 tasks
2016-06-13 14:05:02,889  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 251.0 (TID 485, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:02,889  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 251.0 (TID 486, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:02,889  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 251.0 (TID 486)
2016-06-13 14:05:02,889  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 251.0 (TID 485)
2016-06-13 14:05:02,892  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:02,895  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:03,159  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 251.0 (TID 485). 2883 bytes result sent to driver
2016-06-13 14:05:03,159  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 251.0 (TID 486). 2883 bytes result sent to driver
2016-06-13 14:05:03,161  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 251.0 (TID 485) in 272 ms on localhost (1/2)
2016-06-13 14:05:03,162  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 251.0 (TID 486) in 273 ms on localhost (2/2)
2016-06-13 14:05:03,162  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 251 (top at <console>:133) finished in 0.274 s
2016-06-13 14:05:03,162  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 251.0, whose tasks have all completed, from pool 
2016-06-13 14:05:03,163  INFO [Remote-akka.actor.default-dispatcher-20] (org.apache.spark.scheduler.DAGScheduler) - Job 241 finished: top at <console>:133, took 0.310725 s
2016-06-13 14:05:03,175  INFO [Remote-akka.actor.default-dispatcher-20] (org.apache.spark.SparkContext) - Starting job: top at <console>:133
2016-06-13 14:05:03,176  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 242 (top at <console>:133) with 2 output partitions
2016-06-13 14:05:03,176  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 252 (top at <console>:133)
2016-06-13 14:05:03,176  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:03,176  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:03,176  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 252 (MapPartitionsRDD[290] at top at <console>:133), which has no missing parents
2016-06-13 14:05:03,177  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_486 stored as values in memory (estimated size 14.2 KB, free 118.9 MB)
2016-06-13 14:05:03,178  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_486_piece0 stored as bytes in memory (estimated size 6.3 KB, free 118.9 MB)
2016-06-13 14:05:03,179  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_486_piece0 in memory on localhost:44356 (size: 6.3 KB, free: 9.7 GB)
2016-06-13 14:05:03,179  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 486 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:03,179  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 252 (MapPartitionsRDD[290] at top at <console>:133)
2016-06-13 14:05:03,179  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 252.0 with 2 tasks
2016-06-13 14:05:03,180  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 252.0 (TID 487, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:03,180  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 252.0 (TID 488, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:03,180  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 252.0 (TID 487)
2016-06-13 14:05:03,180  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 252.0 (TID 488)
2016-06-13 14:05:03,183  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:03,188  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:03,322  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 252.0 (TID 488). 2883 bytes result sent to driver
2016-06-13 14:05:03,322  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 252.0 (TID 488) in 142 ms on localhost (1/2)
2016-06-13 14:05:03,329  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 252.0 (TID 487). 2883 bytes result sent to driver
2016-06-13 14:05:03,329  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 252.0 (TID 487) in 150 ms on localhost (2/2)
2016-06-13 14:05:03,329  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 252.0, whose tasks have all completed, from pool 
2016-06-13 14:05:03,329  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 252 (top at <console>:133) finished in 0.140 s
2016-06-13 14:05:03,330  INFO [Remote-akka.actor.default-dispatcher-20] (org.apache.spark.scheduler.DAGScheduler) - Job 242 finished: top at <console>:133, took 0.154262 s
2016-06-13 14:05:03,338  INFO [Remote-akka.actor.default-dispatcher-20] (org.apache.spark.SparkContext) - Starting job: top at <console>:133
2016-06-13 14:05:03,338  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 243 (top at <console>:133) with 2 output partitions
2016-06-13 14:05:03,338  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 253 (top at <console>:133)
2016-06-13 14:05:03,338  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:03,338  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:03,339  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 253 (MapPartitionsRDD[293] at top at <console>:133), which has no missing parents
2016-06-13 14:05:03,340  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_487 stored as values in memory (estimated size 14.2 KB, free 119.0 MB)
2016-06-13 14:05:03,340  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_487_piece0 stored as bytes in memory (estimated size 6.3 KB, free 119.0 MB)
2016-06-13 14:05:03,341  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_487_piece0 in memory on localhost:44356 (size: 6.3 KB, free: 9.7 GB)
2016-06-13 14:05:03,341  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 487 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:03,341  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 253 (MapPartitionsRDD[293] at top at <console>:133)
2016-06-13 14:05:03,341  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 253.0 with 2 tasks
2016-06-13 14:05:03,341  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 253.0 (TID 489, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:03,341  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 253.0 (TID 490, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:03,342  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 253.0 (TID 489)
2016-06-13 14:05:03,342  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 253.0 (TID 490)
2016-06-13 14:05:03,343  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:03,344  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:03,408  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 253.0 (TID 490). 2883 bytes result sent to driver
2016-06-13 14:05:03,409  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 253.0 (TID 490) in 68 ms on localhost (1/2)
2016-06-13 14:05:03,439  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 253.0 (TID 489). 2883 bytes result sent to driver
2016-06-13 14:05:03,440  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 253.0 (TID 489) in 99 ms on localhost (2/2)
2016-06-13 14:05:03,440  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 253 (top at <console>:133) finished in 0.099 s
2016-06-13 14:05:03,440  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 253.0, whose tasks have all completed, from pool 
2016-06-13 14:05:03,440  INFO [Remote-akka.actor.default-dispatcher-20] (org.apache.spark.scheduler.DAGScheduler) - Job 243 finished: top at <console>:133, took 0.102478 s
2016-06-13 14:05:03,452  INFO [Remote-akka.actor.default-dispatcher-20] (org.apache.spark.SparkContext) - Starting job: top at <console>:133
2016-06-13 14:05:03,452  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 244 (top at <console>:133) with 2 output partitions
2016-06-13 14:05:03,452  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 254 (top at <console>:133)
2016-06-13 14:05:03,452  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:03,452  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:03,453  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 254 (MapPartitionsRDD[296] at top at <console>:133), which has no missing parents
2016-06-13 14:05:03,454  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_488 stored as values in memory (estimated size 14.2 KB, free 119.0 MB)
2016-06-13 14:05:03,456  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_488_piece0 stored as bytes in memory (estimated size 6.3 KB, free 119.0 MB)
2016-06-13 14:05:03,456  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_488_piece0 in memory on localhost:44356 (size: 6.3 KB, free: 9.7 GB)
2016-06-13 14:05:03,457  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 488 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:03,457  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 254 (MapPartitionsRDD[296] at top at <console>:133)
2016-06-13 14:05:03,457  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 254.0 with 2 tasks
2016-06-13 14:05:03,458  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 254.0 (TID 491, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:03,459  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 254.0 (TID 492, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:03,459  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 254.0 (TID 491)
2016-06-13 14:05:03,459  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 254.0 (TID 492)
2016-06-13 14:05:03,462  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:03,462  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:03,562  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 254.0 (TID 492). 2883 bytes result sent to driver
2016-06-13 14:05:03,563  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 254.0 (TID 492) in 104 ms on localhost (1/2)
2016-06-13 14:05:03,568  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 254.0 (TID 491). 2883 bytes result sent to driver
2016-06-13 14:05:03,569  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 254.0 (TID 491) in 110 ms on localhost (2/2)
2016-06-13 14:05:03,569  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 254 (top at <console>:133) finished in 0.110 s
2016-06-13 14:05:03,569  INFO [Remote-akka.actor.default-dispatcher-20] (org.apache.spark.scheduler.DAGScheduler) - Job 244 finished: top at <console>:133, took 0.117077 s
2016-06-13 14:05:03,569  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 254.0, whose tasks have all completed, from pool 
2016-06-13 14:05:03,577  INFO [Remote-akka.actor.default-dispatcher-20] (org.apache.spark.SparkContext) - Starting job: top at <console>:133
2016-06-13 14:05:03,578  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 245 (top at <console>:133) with 2 output partitions
2016-06-13 14:05:03,578  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 255 (top at <console>:133)
2016-06-13 14:05:03,578  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:03,578  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:03,578  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 255 (MapPartitionsRDD[299] at top at <console>:133), which has no missing parents
2016-06-13 14:05:03,579  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_489 stored as values in memory (estimated size 14.2 KB, free 119.0 MB)
2016-06-13 14:05:03,580  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_489_piece0 stored as bytes in memory (estimated size 6.3 KB, free 119.0 MB)
2016-06-13 14:05:03,580  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_489_piece0 in memory on localhost:44356 (size: 6.3 KB, free: 9.7 GB)
2016-06-13 14:05:03,581  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 489 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:03,581  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 255 (MapPartitionsRDD[299] at top at <console>:133)
2016-06-13 14:05:03,581  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 255.0 with 2 tasks
2016-06-13 14:05:03,581  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 255.0 (TID 493, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:03,581  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 255.0 (TID 494, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:03,582  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 255.0 (TID 493)
2016-06-13 14:05:03,582  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 255.0 (TID 494)
2016-06-13 14:05:03,584  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:03,584  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:03,660  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 255.0 (TID 493). 2883 bytes result sent to driver
2016-06-13 14:05:03,661  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 255.0 (TID 494). 2883 bytes result sent to driver
2016-06-13 14:05:03,661  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 255.0 (TID 493) in 80 ms on localhost (1/2)
2016-06-13 14:05:03,661  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 255.0 (TID 494) in 80 ms on localhost (2/2)
2016-06-13 14:05:03,661  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 255 (top at <console>:133) finished in 0.080 s
2016-06-13 14:05:03,661  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 255.0, whose tasks have all completed, from pool 
2016-06-13 14:05:03,662  INFO [Remote-akka.actor.default-dispatcher-20] (org.apache.spark.scheduler.DAGScheduler) - Job 245 finished: top at <console>:133, took 0.084126 s
2016-06-13 14:05:06,419  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_489_piece0 on localhost:44356 in memory (size: 6.3 KB, free: 9.7 GB)
2016-06-13 14:05:06,421  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 251
2016-06-13 14:05:06,422  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_488_piece0 on localhost:44356 in memory (size: 6.3 KB, free: 9.7 GB)
2016-06-13 14:05:06,424  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 250
2016-06-13 14:05:06,424  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_487_piece0 on localhost:44356 in memory (size: 6.3 KB, free: 9.7 GB)
2016-06-13 14:05:06,426  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 249
2016-06-13 14:05:06,427  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_486_piece0 on localhost:44356 in memory (size: 6.3 KB, free: 9.7 GB)
2016-06-13 14:05:06,428  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 248
2016-06-13 14:05:06,429  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_485_piece0 on localhost:44356 in memory (size: 6.3 KB, free: 9.7 GB)
2016-06-13 14:05:06,431  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 247
2016-06-13 14:05:06,432  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_483_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,433  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 246
2016-06-13 14:05:06,434  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_482_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,437  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_481_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,441  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 245
2016-06-13 14:05:06,442  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_480_piece0 on localhost:44356 in memory (size: 124.5 KB, free: 9.7 GB)
2016-06-13 14:05:06,444  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_479_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,445  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 244
2016-06-13 14:05:06,447  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_478_piece0 on localhost:44356 in memory (size: 124.5 KB, free: 9.7 GB)
2016-06-13 14:05:06,448  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_477_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,449  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 243
2016-06-13 14:05:06,451  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_476_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,453  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_475_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,454  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 242
2016-06-13 14:05:06,455  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_474_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,457  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_473_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,458  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 241
2016-06-13 14:05:06,459  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_472_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,463  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_471_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,463  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 240
2016-06-13 14:05:06,464  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_470_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,466  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_469_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,467  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 239
2016-06-13 14:05:06,468  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_468_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,469  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_467_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,469  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 238
2016-06-13 14:05:06,470  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_466_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,472  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_465_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,472  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 237
2016-06-13 14:05:06,473  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_464_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,474  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_463_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,474  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 236
2016-06-13 14:05:06,475  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_462_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,476  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_461_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,476  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 235
2016-06-13 14:05:06,477  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_460_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:05:06,477  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_459_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,478  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 234
2016-06-13 14:05:06,478  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_458_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,479  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_457_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,479  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 233
2016-06-13 14:05:06,480  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_456_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,480  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_455_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,481  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 232
2016-06-13 14:05:06,481  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_454_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,482  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_453_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,482  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 231
2016-06-13 14:05:06,482  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_452_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,483  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_451_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,483  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 230
2016-06-13 14:05:06,484  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_450_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,485  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_449_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,485  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 229
2016-06-13 14:05:06,485  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_448_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,486  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_447_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,486  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 228
2016-06-13 14:05:06,487  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_446_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,487  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_445_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,488  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 227
2016-06-13 14:05:06,488  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_444_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:05:06,489  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_443_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,489  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 226
2016-06-13 14:05:06,490  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_442_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,490  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_441_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,490  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 225
2016-06-13 14:05:06,491  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_440_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,492  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_439_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,492  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 224
2016-06-13 14:05:06,492  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_438_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:05:06,493  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_437_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,493  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 223
2016-06-13 14:05:06,494  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_436_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,495  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_435_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,495  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 222
2016-06-13 14:05:06,495  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_434_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:05:06,496  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_433_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,497  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 221
2016-06-13 14:05:06,497  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_432_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,511  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_431_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,511  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 220
2016-06-13 14:05:06,511  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_430_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,512  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_429_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,513  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 219
2016-06-13 14:05:06,513  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_428_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:05:06,514  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_427_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,514  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 218
2016-06-13 14:05:06,514  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_426_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,515  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_425_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,515  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 217
2016-06-13 14:05:06,516  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_424_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:05:06,516  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_423_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,517  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 216
2016-06-13 14:05:06,517  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_422_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,518  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_421_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,518  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 215
2016-06-13 14:05:06,519  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_420_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:05:06,519  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_419_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,520  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 214
2016-06-13 14:05:06,520  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_418_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,521  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_417_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,521  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 213
2016-06-13 14:05:06,521  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_416_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:05:06,522  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_415_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,523  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 212
2016-06-13 14:05:06,523  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_414_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:05:06,524  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_413_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,524  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 211
2016-06-13 14:05:06,532  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_412_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:05:06,533  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_411_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,534  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 210
2016-06-13 14:05:06,534  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_410_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:05:06,535  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_409_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,535  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 209
2016-06-13 14:05:06,536  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_408_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:05:06,536  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_407_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,537  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 208
2016-06-13 14:05:06,537  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_406_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,538  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_405_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,538  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 207
2016-06-13 14:05:06,542  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_404_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:05:06,543  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_403_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,543  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 206
2016-06-13 14:05:06,544  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_402_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:05:06,544  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_401_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,545  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 205
2016-06-13 14:05:06,545  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_400_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:05:06,546  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_399_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,546  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 204
2016-06-13 14:05:06,547  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_398_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:05:06,547  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_397_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,547  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 203
2016-06-13 14:05:06,548  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_396_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:05:06,548  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_395_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,549  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 202
2016-06-13 14:05:06,549  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_394_piece0 on localhost:44356 in memory (size: 125.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,550  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_393_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,550  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 201
2016-06-13 14:05:06,550  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_392_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,551  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_391_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,551  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 200
2016-06-13 14:05:06,552  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_390_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,552  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_389_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,553  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 199
2016-06-13 14:05:06,553  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_388_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,554  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_387_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,554  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 198
2016-06-13 14:05:06,554  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_386_piece0 on localhost:44356 in memory (size: 124.5 KB, free: 9.7 GB)
2016-06-13 14:05:06,555  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_385_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,555  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 197
2016-06-13 14:05:06,556  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_384_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,556  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_383_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,557  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 196
2016-06-13 14:05:06,557  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_382_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:05:06,558  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_381_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,558  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 195
2016-06-13 14:05:06,558  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_380_piece0 on localhost:44356 in memory (size: 124.5 KB, free: 9.7 GB)
2016-06-13 14:05:06,559  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_379_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,559  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 194
2016-06-13 14:05:06,560  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_378_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,560  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_377_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,561  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 193
2016-06-13 14:05:06,561  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_376_piece0 on localhost:44356 in memory (size: 124.5 KB, free: 9.7 GB)
2016-06-13 14:05:06,562  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_375_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,562  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 192
2016-06-13 14:05:06,563  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_374_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,563  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_373_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,564  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 191
2016-06-13 14:05:06,564  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_372_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,565  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_371_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,565  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 190
2016-06-13 14:05:06,566  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_370_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,567  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_369_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,567  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 189
2016-06-13 14:05:06,567  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_368_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,573  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_367_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,573  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 188
2016-06-13 14:05:06,573  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_366_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:05:06,574  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_365_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,574  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 187
2016-06-13 14:05:06,575  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_364_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,575  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_363_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,576  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 186
2016-06-13 14:05:06,576  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_362_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:05:06,577  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_361_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,577  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 185
2016-06-13 14:05:06,577  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_360_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,578  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_359_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,578  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 184
2016-06-13 14:05:06,579  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_358_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,579  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_357_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,580  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 183
2016-06-13 14:05:06,580  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_356_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,581  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_355_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,581  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 182
2016-06-13 14:05:06,581  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_354_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,582  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_353_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,582  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 181
2016-06-13 14:05:06,582  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_352_piece0 on localhost:44356 in memory (size: 124.7 KB, free: 9.7 GB)
2016-06-13 14:05:06,583  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_351_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,583  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 180
2016-06-13 14:05:06,584  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_350_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,584  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_349_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,585  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 179
2016-06-13 14:05:06,585  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_348_piece0 on localhost:44356 in memory (size: 124.6 KB, free: 9.7 GB)
2016-06-13 14:05:06,586  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_347_piece0 on localhost:44356 in memory (size: 8.1 KB, free: 9.7 GB)
2016-06-13 14:05:06,586  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 178
2016-06-13 14:05:06,586  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_346_piece0 on localhost:44356 in memory (size: 124.8 KB, free: 9.7 GB)
2016-06-13 14:05:09,147  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkContext) - Starting job: lookup at <console>:106
2016-06-13 14:05:09,148  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 246 (lookup at <console>:106) with 2 output partitions
2016-06-13 14:05:09,148  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 256 (lookup at <console>:106)
2016-06-13 14:05:09,148  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:09,148  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:09,149  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 256 (MapPartitionsRDD[305] at lookup at <console>:106), which has no missing parents
2016-06-13 14:05:09,150  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_490 stored as values in memory (estimated size 15.3 KB, free 97.8 MB)
2016-06-13 14:05:09,151  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_490_piece0 stored as bytes in memory (estimated size 6.9 KB, free 97.8 MB)
2016-06-13 14:05:09,151  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_490_piece0 in memory on localhost:44356 (size: 6.9 KB, free: 9.7 GB)
2016-06-13 14:05:09,152  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 490 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:09,152  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 256 (MapPartitionsRDD[305] at lookup at <console>:106)
2016-06-13 14:05:09,152  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 256.0 with 2 tasks
2016-06-13 14:05:09,153  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 256.0 (TID 495, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:09,153  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 256.0 (TID 496, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:09,153  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 256.0 (TID 495)
2016-06-13 14:05:09,153  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 256.0 (TID 496)
2016-06-13 14:05:09,160  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:09,167  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:09,367  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 256.0 (TID 496). 2243 bytes result sent to driver
2016-06-13 14:05:09,367  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 256.0 (TID 496) in 214 ms on localhost (1/2)
2016-06-13 14:05:09,391  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 256.0 (TID 495). 3061 bytes result sent to driver
2016-06-13 14:05:09,392  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 256 (lookup at <console>:106) finished in 0.230 s
2016-06-13 14:05:09,392  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 256.0 (TID 495) in 240 ms on localhost (2/2)
2016-06-13 14:05:09,392  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 256.0, whose tasks have all completed, from pool 
2016-06-13 14:05:09,393  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.scheduler.DAGScheduler) - Job 246 finished: lookup at <console>:106, took 0.245363 s
2016-06-13 14:05:09,399  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkContext) - Starting job: first at RowMatrix.scala:61
2016-06-13 14:05:09,399  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 247 (first at RowMatrix.scala:61) with 1 output partitions
2016-06-13 14:05:09,399  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 257 (first at RowMatrix.scala:61)
2016-06-13 14:05:09,399  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:09,400  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:09,400  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 257 (MapPartitionsRDD[301] at map at <console>:126), which has no missing parents
2016-06-13 14:05:09,402  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_491 stored as values in memory (estimated size 14.1 KB, free 97.9 MB)
2016-06-13 14:05:09,403  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_491_piece0 stored as bytes in memory (estimated size 6.6 KB, free 97.9 MB)
2016-06-13 14:05:09,404  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_491_piece0 in memory on localhost:44356 (size: 6.6 KB, free: 9.7 GB)
2016-06-13 14:05:09,404  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 491 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:09,405  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 1 missing tasks from ResultStage 257 (MapPartitionsRDD[301] at map at <console>:126)
2016-06-13 14:05:09,405  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 257.0 with 1 tasks
2016-06-13 14:05:09,406  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 257.0 (TID 497, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:09,406  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 257.0 (TID 497)
2016-06-13 14:05:09,408  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:09,409  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 257.0 (TID 497). 3061 bytes result sent to driver
2016-06-13 14:05:09,409  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 257.0 (TID 497) in 3 ms on localhost (1/1)
2016-06-13 14:05:09,409  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 257 (first at RowMatrix.scala:61) finished in 0.003 s
2016-06-13 14:05:09,409  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 257.0, whose tasks have all completed, from pool 
2016-06-13 14:05:09,411  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.scheduler.DAGScheduler) - Job 247 finished: first at RowMatrix.scala:61, took 0.011986 s
2016-06-13 14:05:09,412  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.MemoryStore) - Block broadcast_492 stored as values in memory (estimated size 760.0 B, free 97.9 MB)
2016-06-13 14:05:09,413  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.MemoryStore) - Block broadcast_492_piece0 stored as bytes in memory (estimated size 772.0 B, free 97.9 MB)
2016-06-13 14:05:09,414  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_492_piece0 in memory on localhost:44356 (size: 772.0 B, free: 9.7 GB)
2016-06-13 14:05:09,414  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkContext) - Created broadcast 492 from broadcast at RowMatrix.scala:428
2016-06-13 14:05:09,435  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkContext) - Starting job: top at <console>:140
2016-06-13 14:05:09,436  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 248 (top at <console>:140) with 2 output partitions
2016-06-13 14:05:09,436  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 258 (top at <console>:140)
2016-06-13 14:05:09,436  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:09,436  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:09,436  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 258 (MapPartitionsRDD[310] at top at <console>:140), which has no missing parents
2016-06-13 14:05:09,438  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_493 stored as values in memory (estimated size 15.8 KB, free 97.9 MB)
2016-06-13 14:05:09,439  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_493_piece0 stored as bytes in memory (estimated size 7.2 KB, free 97.9 MB)
2016-06-13 14:05:09,440  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_493_piece0 in memory on localhost:44356 (size: 7.2 KB, free: 9.7 GB)
2016-06-13 14:05:09,440  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 493 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:09,440  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 258 (MapPartitionsRDD[310] at top at <console>:140)
2016-06-13 14:05:09,440  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 258.0 with 2 tasks
2016-06-13 14:05:09,441  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 258.0 (TID 498, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:09,444  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 258.0 (TID 499, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:09,444  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 258.0 (TID 498)
2016-06-13 14:05:09,445  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 258.0 (TID 499)
2016-06-13 14:05:09,448  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:09,448  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:09,647  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 258.0 (TID 498). 3500 bytes result sent to driver
2016-06-13 14:05:09,648  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 258.0 (TID 498) in 207 ms on localhost (1/2)
2016-06-13 14:05:09,675  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 258.0 (TID 499). 3500 bytes result sent to driver
2016-06-13 14:05:09,676  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 258.0 (TID 499) in 235 ms on localhost (2/2)
2016-06-13 14:05:09,676  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 258 (top at <console>:140) finished in 0.235 s
2016-06-13 14:05:09,676  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 258.0, whose tasks have all completed, from pool 
2016-06-13 14:05:09,676  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.scheduler.DAGScheduler) - Job 248 finished: top at <console>:140, took 0.241014 s
2016-06-13 14:05:10,069 ERROR [Remote-akka.actor.default-dispatcher-15] (notebook.JsonCodec$) - Exception doc not found {}
org.apache.spark.sql.AnalysisException: Table not found: Videos;
	at org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)
	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.getTable(Analyzer.scala:306)
	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:315)
	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$$anonfun$apply$8.applyOrElse(Analyzer.scala:310)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$resolveOperators$1.apply(LogicalPlan.scala:57)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$resolveOperators$1.apply(LogicalPlan.scala:57)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:53)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:56)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:54)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:54)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:265)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:370)
	at scala.collection.Iterator$class.foreach(Iterator.scala:742)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1194)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:308)
	at scala.collection.AbstractIterator.to(Iterator.scala:1194)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:300)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1194)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:287)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1194)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformChildren(TreeNode.scala:305)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:54)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:54)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan$$anonfun$1.apply(LogicalPlan.scala:54)
	at org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$4.apply(TreeNode.scala:265)
	at scala.collection.Iterator$$anon$11.next(Iterator.scala:370)
	at scala.collection.Iterator$class.foreach(Iterator.scala:742)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1194)
	at scala.collection.generic.Growable$class.$plus$plus$eq(Growable.scala:59)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:104)
	at scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:48)
	at scala.collection.TraversableOnce$class.to(TraversableOnce.scala:308)
	at scala.collection.AbstractIterator.to(Iterator.scala:1194)
	at scala.collection.TraversableOnce$class.toBuffer(TraversableOnce.scala:300)
	at scala.collection.AbstractIterator.toBuffer(Iterator.scala:1194)
	at scala.collection.TraversableOnce$class.toArray(TraversableOnce.scala:287)
	at scala.collection.AbstractIterator.toArray(Iterator.scala:1194)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformChildren(TreeNode.scala:305)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperators(LogicalPlan.scala:54)
	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:310)
	at org.apache.spark.sql.catalyst.analysis.Analyzer$ResolveRelations$.apply(Analyzer.scala:300)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:83)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1$$anonfun$apply$1.apply(RuleExecutor.scala:80)
	at scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124)
	at scala.collection.immutable.List.foldLeft(List.scala:84)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:80)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor$$anonfun$execute$1.apply(RuleExecutor.scala:72)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:72)
	at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:36)
	at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:36)
	at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:34)
	at org.apache.spark.sql.DataFrame.<init>(DataFrame.scala:133)
	at org.apache.spark.sql.DataFrame$.apply(DataFrame.scala:52)
	at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:817)
	at $line107.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$anonfun$printIdWeights$2.apply(<console>:114)
	at $line107.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$anonfun$printIdWeights$2.apply(<console>:110)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at $line107.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$.printIdWeights(<console>:110)
	at $line107.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$.printTopDocsForDoc(<console>:123)
	at $line109.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$.<init>(<console>:116)
	at $line109.$read$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$.<clinit>(<console>)
	at $line109.$eval$.$print$lzycompute(<console>:7)
	at $line109.$eval$.$print(<console>:6)
	at $line109.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at scala.tools.nsc.interpreter.IMain$ReadEvalPrint.call(IMain.scala:784)
	at scala.tools.nsc.interpreter.IMain$Request.loadAndRun(IMain.scala:1039)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:636)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest$$anonfun$loadAndRunReq$1.apply(IMain.scala:635)
	at scala.reflect.internal.util.ScalaClassLoader$class.asContext(ScalaClassLoader.scala:31)
	at scala.reflect.internal.util.AbstractFileClassLoader.asContext(AbstractFileClassLoader.scala:19)
	at scala.tools.nsc.interpreter.IMain$WrappedRequest.loadAndRunReq(IMain.scala:635)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:567)
	at scala.tools.nsc.interpreter.IMain.interpret(IMain.scala:563)
	at notebook.kernel.Repl$$anonfun$4.apply(Repl.scala:170)
	at notebook.kernel.Repl$$anonfun$4.apply(Repl.scala:170)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at scala.Console$.withOut(Console.scala:65)
	at notebook.kernel.Repl.evaluate(Repl.scala:169)
	at notebook.client.ReplCalculator$$anonfun$15$$anon$1$$anonfun$29.apply(ReplCalculator.scala:378)
	at notebook.client.ReplCalculator$$anonfun$15$$anon$1$$anonfun$29.apply(ReplCalculator.scala:375)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
2016-06-13 14:05:12,057  INFO [Remote-akka.actor.default-dispatcher-22] (org.apache.spark.storage.MemoryStore) - Block broadcast_494 stored as values in memory (estimated size 760.0 B, free 97.9 MB)
2016-06-13 14:05:12,058  INFO [Remote-akka.actor.default-dispatcher-22] (org.apache.spark.storage.MemoryStore) - Block broadcast_494_piece0 stored as bytes in memory (estimated size 772.0 B, free 97.9 MB)
2016-06-13 14:05:12,059  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_494_piece0 in memory on localhost:44356 (size: 772.0 B, free: 9.7 GB)
2016-06-13 14:05:12,060  INFO [Remote-akka.actor.default-dispatcher-22] (org.apache.spark.SparkContext) - Created broadcast 494 from broadcast at RowMatrix.scala:428
2016-06-13 14:05:12,085  INFO [Remote-akka.actor.default-dispatcher-22] (org.apache.spark.SparkContext) - Starting job: top at <console>:198
2016-06-13 14:05:12,086  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 249 (top at <console>:198) with 2 output partitions
2016-06-13 14:05:12,086  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 259 (top at <console>:198)
2016-06-13 14:05:12,086  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:12,087  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:12,087  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 259 (MapPartitionsRDD[315] at top at <console>:198), which has no missing parents
2016-06-13 14:05:12,089  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_495 stored as values in memory (estimated size 15.8 KB, free 97.9 MB)
2016-06-13 14:05:12,090  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_495_piece0 stored as bytes in memory (estimated size 7.2 KB, free 97.9 MB)
2016-06-13 14:05:12,091  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_495_piece0 in memory on localhost:44356 (size: 7.2 KB, free: 9.7 GB)
2016-06-13 14:05:12,092  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 495 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:12,093  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 259 (MapPartitionsRDD[315] at top at <console>:198)
2016-06-13 14:05:12,093  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 259.0 with 2 tasks
2016-06-13 14:05:12,095  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 259.0 (TID 500, localhost, partition 0,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:12,095  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 259.0 (TID 501, localhost, partition 1,PROCESS_LOCAL, 2319 bytes)
2016-06-13 14:05:12,095  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 259.0 (TID 500)
2016-06-13 14:05:12,095  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 259.0 (TID 501)
2016-06-13 14:05:12,102  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_57_1 locally
2016-06-13 14:05:12,103  INFO [Executor task launch worker-0] (org.apache.spark.storage.BlockManager) - Found block rdd_57_0 locally
2016-06-13 14:05:12,287  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 259.0 (TID 501). 3155 bytes result sent to driver
2016-06-13 14:05:12,288  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 259.0 (TID 501) in 193 ms on localhost (1/2)
2016-06-13 14:05:12,334  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 259.0 (TID 500). 3155 bytes result sent to driver
2016-06-13 14:05:12,335  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 259.0 (TID 500) in 241 ms on localhost (2/2)
2016-06-13 14:05:12,335  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 259.0, whose tasks have all completed, from pool 
2016-06-13 14:05:12,335  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 259 (top at <console>:198) finished in 0.232 s
2016-06-13 14:05:12,335  INFO [Remote-akka.actor.default-dispatcher-22] (org.apache.spark.scheduler.DAGScheduler) - Job 249 finished: top at <console>:198, took 0.250001 s
2016-06-13 14:05:13,562  INFO [Remote-akka.actor.default-dispatcher-22] (org.apache.spark.sql.execution.datasources.json.JSONRelation) - Listing file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/user_history_only.json on driver
2016-06-13 14:05:13,567  INFO [Remote-akka.actor.default-dispatcher-22] (org.apache.spark.storage.MemoryStore) - Block broadcast_496 stored as values in memory (estimated size 128.2 KB, free 98.0 MB)
2016-06-13 14:05:13,577  INFO [Remote-akka.actor.default-dispatcher-22] (org.apache.spark.storage.MemoryStore) - Block broadcast_496_piece0 stored as bytes in memory (estimated size 14.2 KB, free 98.1 MB)
2016-06-13 14:05:13,578  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_496_piece0 in memory on localhost:44356 (size: 14.2 KB, free: 9.7 GB)
2016-06-13 14:05:13,579  INFO [Remote-akka.actor.default-dispatcher-22] (org.apache.spark.SparkContext) - Created broadcast 496 from json at <console>:88
2016-06-13 14:05:13,588  INFO [Remote-akka.actor.default-dispatcher-22] (org.apache.hadoop.mapred.FileInputFormat) - Total input paths to process : 1
2016-06-13 14:05:13,596  INFO [Remote-akka.actor.default-dispatcher-22] (org.apache.spark.SparkContext) - Starting job: json at <console>:88
2016-06-13 14:05:13,597  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 250 (json at <console>:88) with 2 output partitions
2016-06-13 14:05:13,597  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 260 (json at <console>:88)
2016-06-13 14:05:13,597  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:13,597  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:13,597  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 260 (MapPartitionsRDD[319] at json at <console>:88), which has no missing parents
2016-06-13 14:05:13,598  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_497 stored as values in memory (estimated size 4.2 KB, free 98.1 MB)
2016-06-13 14:05:13,599  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_497_piece0 stored as bytes in memory (estimated size 2.4 KB, free 98.1 MB)
2016-06-13 14:05:13,602  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_497_piece0 in memory on localhost:44356 (size: 2.4 KB, free: 9.7 GB)
2016-06-13 14:05:13,604  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 497 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:13,605  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 260 (MapPartitionsRDD[319] at json at <console>:88)
2016-06-13 14:05:13,606  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 260.0 with 2 tasks
2016-06-13 14:05:13,607  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 260.0 (TID 502, localhost, partition 0,PROCESS_LOCAL, 2328 bytes)
2016-06-13 14:05:13,607  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 260.0 (TID 503, localhost, partition 1,PROCESS_LOCAL, 2328 bytes)
2016-06-13 14:05:13,607  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 260.0 (TID 503)
2016-06-13 14:05:13,607  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 260.0 (TID 502)
2016-06-13 14:05:13,609  INFO [Executor task launch worker-0] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/user_history_only.json:0+23464789
2016-06-13 14:05:13,613  INFO [Executor task launch worker-1] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/user_history_only.json:23464789+23464790
2016-06-13 14:05:14,719  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_495_piece0 on localhost:44356 in memory (size: 7.2 KB, free: 9.7 GB)
2016-06-13 14:05:14,720  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 255
2016-06-13 14:05:14,723  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_494_piece0 on localhost:44356 in memory (size: 772.0 B, free: 9.7 GB)
2016-06-13 14:05:14,725  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_493_piece0 on localhost:44356 in memory (size: 7.2 KB, free: 9.7 GB)
2016-06-13 14:05:14,725  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 254
2016-06-13 14:05:14,726  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_492_piece0 on localhost:44356 in memory (size: 772.0 B, free: 9.7 GB)
2016-06-13 14:05:14,727  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_491_piece0 on localhost:44356 in memory (size: 6.6 KB, free: 9.7 GB)
2016-06-13 14:05:14,728  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 253
2016-06-13 14:05:14,734  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_490_piece0 on localhost:44356 in memory (size: 6.9 KB, free: 9.7 GB)
2016-06-13 14:05:14,735  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 252
2016-06-13 14:05:15,160  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 260.0 (TID 502). 3145 bytes result sent to driver
2016-06-13 14:05:15,162  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 260.0 (TID 502) in 1555 ms on localhost (1/2)
2016-06-13 14:05:15,478  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 260.0 (TID 503). 3649 bytes result sent to driver
2016-06-13 14:05:15,479  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 260.0 (TID 503) in 1872 ms on localhost (2/2)
2016-06-13 14:05:15,479  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 260 (json at <console>:88) finished in 1.871 s
2016-06-13 14:05:15,479  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 260.0, whose tasks have all completed, from pool 
2016-06-13 14:05:15,480  INFO [Remote-akka.actor.default-dispatcher-22] (org.apache.spark.scheduler.DAGScheduler) - Job 250 finished: json at <console>:88, took 1.883416 s
2016-06-13 14:05:15,483  INFO [Remote-akka.actor.default-dispatcher-22] (org.apache.spark.storage.MemoryStore) - Block broadcast_498 stored as values in memory (estimated size 127.1 KB, free 98.1 MB)
2016-06-13 14:05:15,489  INFO [Remote-akka.actor.default-dispatcher-22] (org.apache.spark.storage.MemoryStore) - Block broadcast_498_piece0 stored as bytes in memory (estimated size 13.8 KB, free 98.1 MB)
2016-06-13 14:05:15,489  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_498_piece0 in memory on localhost:44356 (size: 13.8 KB, free: 9.7 GB)
2016-06-13 14:05:15,490  INFO [Remote-akka.actor.default-dispatcher-22] (org.apache.spark.SparkContext) - Created broadcast 498 from cache at <console>:88
2016-06-13 14:05:15,493  INFO [Remote-akka.actor.default-dispatcher-22] (org.apache.spark.storage.MemoryStore) - Block broadcast_499 stored as values in memory (estimated size 128.2 KB, free 98.2 MB)
2016-06-13 14:05:15,501  INFO [Remote-akka.actor.default-dispatcher-22] (org.apache.spark.storage.MemoryStore) - Block broadcast_499_piece0 stored as bytes in memory (estimated size 14.2 KB, free 98.2 MB)
2016-06-13 14:05:15,501  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_499_piece0 in memory on localhost:44356 (size: 14.2 KB, free: 9.7 GB)
2016-06-13 14:05:15,502  INFO [Remote-akka.actor.default-dispatcher-22] (org.apache.spark.SparkContext) - Created broadcast 499 from cache at <console>:88
2016-06-13 14:05:15,821 ERROR [Remote-akka.actor.default-dispatcher-22] (notebook.kernel.Repl) - Ooops, exception in the cell
java.lang.ExceptionInInitializerError
	at sun.misc.Unsafe.ensureClassInitialized(Native Method)
	at sun.reflect.UnsafeFieldAccessorFactory.newFieldAccessor(UnsafeFieldAccessorFactory.java:43)
	at sun.reflect.ReflectionFactory.newFieldAccessor(ReflectionFactory.java:142)
	at java.lang.reflect.Field.acquireFieldAccessor(Field.java:1088)
	at java.lang.reflect.Field.getFieldAccessor(Field.java:1069)
	at java.lang.reflect.Field.get(Field.java:393)
	at notebook.kernel.Repl.getModule$1(Repl.scala:203)
	at notebook.kernel.Repl.iws$1(Repl.scala:212)
	at notebook.kernel.Repl.liftedTree1$1(Repl.scala:219)
	at notebook.kernel.Repl.evaluate(Repl.scala:199)
	at notebook.client.ReplCalculator$$anonfun$15$$anon$1$$anonfun$29.apply(ReplCalculator.scala:378)
	at notebook.client.ReplCalculator$$anonfun$15$$anon$1$$anonfun$29.apply(ReplCalculator.scala:375)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: java.io.IOException: java.lang.NoSuchMethodException: org.apache.spark.io.SnappyCompressionCodec.<init>(org.apache.spark.SparkConf)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1222)
	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)
	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)
	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)
	at org.apache.spark.rdd.HadoopRDD.getJobConf(HadoopRDD.scala:144)
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:195)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.ZippedWithIndexRDD.<init>(ZippedWithIndexRDD.scala:44)
	at org.apache.spark.rdd.RDD$$anonfun$zipWithIndex$1.apply(RDD.scala:1258)
	at org.apache.spark.rdd.RDD$$anonfun$zipWithIndex$1.apply(RDD.scala:1258)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:111)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:316)
	at org.apache.spark.rdd.RDD.zipWithIndex(RDD.scala:1257)
	at notebook.front.widgets.DataFrameView$class.notebook$front$widgets$DataFrameView$$json(DataFrame.scala:40)
	at notebook.front.widgets.DataFrameWidget.notebook$front$widgets$DataFrameView$$json$lzycompute(DataFrame.scala:64)
	at notebook.front.widgets.DataFrameWidget.notebook$front$widgets$DataFrameView$$json(DataFrame.scala:64)
	at notebook.front.widgets.DataFrameView$class.$init$(DataFrame.scala:41)
	at notebook.front.widgets.DataFrameWidget.<init>(DataFrame.scala:69)
	at notebook.front.ExtraLowPriorityRenderers$dataFrameAsTable$.render(renderer.scala:13)
	at notebook.front.ExtraLowPriorityRenderers$dataFrameAsTable$.render(renderer.scala:12)
	at notebook.front.Widget$.fromRenderer(Widget.scala:32)
	at $line113.$rendered$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$.<init>(<console>:85)
	at $line113.$rendered$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$.<clinit>(<console>)
	... 20 more
Caused by: java.lang.NoSuchMethodException: org.apache.spark.io.SnappyCompressionCodec.<init>(org.apache.spark.SparkConf)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.spark.io.CompressionCodec$.createCodec(CompressionCodec.scala:71)
	at org.apache.spark.io.CompressionCodec$.createCodec(CompressionCodec.scala:65)
	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$setConf(TorrentBroadcast.scala:73)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:167)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1219)
	... 78 more
2016-06-13 14:05:16,087  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.hadoop.mapred.FileInputFormat) - Total input paths to process : 1
2016-06-13 14:05:16,089  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: show at <console>:89
2016-06-13 14:05:16,090  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 251 (show at <console>:89) with 1 output partitions
2016-06-13 14:05:16,090  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 261 (show at <console>:89)
2016-06-13 14:05:16,090  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:16,090  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:16,090  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 261 (MapPartitionsRDD[330] at show at <console>:89), which has no missing parents
2016-06-13 14:05:16,091  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_500 stored as values in memory (estimated size 11.3 KB, free 98.3 MB)
2016-06-13 14:05:16,092  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_500_piece0 stored as bytes in memory (estimated size 5.2 KB, free 98.3 MB)
2016-06-13 14:05:16,092  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_500_piece0 in memory on localhost:44356 (size: 5.2 KB, free: 9.7 GB)
2016-06-13 14:05:16,092  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 500 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:16,093  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 1 missing tasks from ResultStage 261 (MapPartitionsRDD[330] at show at <console>:89)
2016-06-13 14:05:16,093  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 261.0 with 1 tasks
2016-06-13 14:05:16,093  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 261.0 (TID 504, localhost, partition 0,PROCESS_LOCAL, 2328 bytes)
2016-06-13 14:05:16,093  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 261.0 (TID 504)
2016-06-13 14:05:16,096  INFO [Executor task launch worker-1] (org.apache.spark.CacheManager) - Partition rdd_324_0 not found, computing it
2016-06-13 14:05:16,096  INFO [Executor task launch worker-1] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/user_history_only.json:0+23464789
2016-06-13 14:05:16,187  INFO [Executor task launch worker-1] (org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection) - Code generated in 83.657234 ms
2016-06-13 14:05:17,151  INFO [Executor task launch worker-1] (org.apache.spark.storage.MemoryStore) - Block rdd_324_0 stored as values in memory (estimated size 18.4 MB, free 116.6 MB)
2016-06-13 14:05:17,151  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added rdd_324_0 in memory on localhost:44356 (size: 18.4 MB, free: 9.7 GB)
2016-06-13 14:05:17,189  INFO [Executor task launch worker-1] (org.apache.spark.sql.execution.columnar.GenerateColumnAccessor) - Code generated in 37.109805 ms
2016-06-13 14:05:17,225  INFO [Executor task launch worker-1] (org.apache.spark.sql.catalyst.expressions.codegen.GenerateSafeProjection) - Code generated in 31.00167 ms
2016-06-13 14:05:17,236  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 261.0 (TID 504). 11176 bytes result sent to driver
2016-06-13 14:05:17,237  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 261.0 (TID 504) in 1144 ms on localhost (1/1)
2016-06-13 14:05:17,237  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 261 (show at <console>:89) finished in 1.144 s
2016-06-13 14:05:17,237  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 261.0, whose tasks have all completed, from pool 
2016-06-13 14:05:17,238  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 251 finished: show at <console>:89, took 1.148857 s
2016-06-13 14:05:17,257  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: take at <console>:92
2016-06-13 14:05:17,257  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 252 (take at <console>:92) with 1 output partitions
2016-06-13 14:05:17,257  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 262 (take at <console>:92)
2016-06-13 14:05:17,257  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:17,258  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:17,258  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 262 (MapPartitionsRDD[331] at rdd at <console>:91), which has no missing parents
2016-06-13 14:05:17,259  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_501 stored as values in memory (estimated size 11.3 KB, free 116.7 MB)
2016-06-13 14:05:17,260  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_501_piece0 stored as bytes in memory (estimated size 5.3 KB, free 116.7 MB)
2016-06-13 14:05:17,260  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_501_piece0 in memory on localhost:44356 (size: 5.3 KB, free: 9.7 GB)
2016-06-13 14:05:17,260  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 501 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:17,261  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 1 missing tasks from ResultStage 262 (MapPartitionsRDD[331] at rdd at <console>:91)
2016-06-13 14:05:17,261  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 262.0 with 1 tasks
2016-06-13 14:05:17,261  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 262.0 (TID 505, localhost, partition 0,PROCESS_LOCAL, 2328 bytes)
2016-06-13 14:05:17,261  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 262.0 (TID 505)
2016-06-13 14:05:17,263  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_324_0 locally
2016-06-13 14:05:17,265  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 262.0 (TID 505). 4436 bytes result sent to driver
2016-06-13 14:05:17,266  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 262.0 (TID 505) in 5 ms on localhost (1/1)
2016-06-13 14:05:17,266  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 262 (take at <console>:92) finished in 0.005 s
2016-06-13 14:05:17,266  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 262.0, whose tasks have all completed, from pool 
2016-06-13 14:05:17,267  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 252 finished: take at <console>:92, took 0.009672 s
2016-06-13 14:05:18,098  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.SparkContext) - Starting job: take at <console>:111
2016-06-13 14:05:18,098  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 253 (take at <console>:111) with 1 output partitions
2016-06-13 14:05:18,098  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 263 (take at <console>:111)
2016-06-13 14:05:18,098  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:18,099  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:18,099  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 263 (MapPartitionsRDD[332] at map at <console>:109), which has no missing parents
2016-06-13 14:05:18,100  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_502 stored as values in memory (estimated size 11.6 KB, free 116.7 MB)
2016-06-13 14:05:18,101  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_502_piece0 stored as bytes in memory (estimated size 5.4 KB, free 116.7 MB)
2016-06-13 14:05:18,101  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_502_piece0 in memory on localhost:44356 (size: 5.4 KB, free: 9.7 GB)
2016-06-13 14:05:18,103  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 502 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:18,103  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 1 missing tasks from ResultStage 263 (MapPartitionsRDD[332] at map at <console>:109)
2016-06-13 14:05:18,103  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 263.0 with 1 tasks
2016-06-13 14:05:18,105  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 263.0 (TID 506, localhost, partition 0,PROCESS_LOCAL, 2328 bytes)
2016-06-13 14:05:18,105  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 263.0 (TID 506)
2016-06-13 14:05:18,109  INFO [Executor task launch worker-1] (org.apache.spark.storage.BlockManager) - Found block rdd_324_0 locally
2016-06-13 14:05:18,112  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 263.0 (TID 506). 3897 bytes result sent to driver
2016-06-13 14:05:18,113  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 263.0 (TID 506) in 8 ms on localhost (1/1)
2016-06-13 14:05:18,113  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 263.0, whose tasks have all completed, from pool 
2016-06-13 14:05:18,113  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 263 (take at <console>:111) finished in 0.003 s
2016-06-13 14:05:18,113  INFO [Remote-akka.actor.default-dispatcher-18] (org.apache.spark.scheduler.DAGScheduler) - Job 253 finished: take at <console>:111, took 0.015260 s
2016-06-13 14:05:18,568  INFO [Remote-akka.actor.default-dispatcher-21] (org.apache.spark.sql.execution.datasources.json.JSONRelation) - Listing file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/user_profile_history.json on driver
2016-06-13 14:05:18,571  INFO [Remote-akka.actor.default-dispatcher-21] (org.apache.spark.storage.MemoryStore) - Block broadcast_503 stored as values in memory (estimated size 128.3 KB, free 116.8 MB)
2016-06-13 14:05:18,580  INFO [Remote-akka.actor.default-dispatcher-21] (org.apache.spark.storage.MemoryStore) - Block broadcast_503_piece0 stored as bytes in memory (estimated size 14.2 KB, free 116.8 MB)
2016-06-13 14:05:18,580  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_503_piece0 in memory on localhost:44356 (size: 14.2 KB, free: 9.7 GB)
2016-06-13 14:05:18,581  INFO [Remote-akka.actor.default-dispatcher-21] (org.apache.spark.SparkContext) - Created broadcast 503 from json at <console>:88
2016-06-13 14:05:18,589  INFO [Remote-akka.actor.default-dispatcher-21] (org.apache.hadoop.mapred.FileInputFormat) - Total input paths to process : 1
2016-06-13 14:05:18,596  INFO [Remote-akka.actor.default-dispatcher-21] (org.apache.spark.SparkContext) - Starting job: json at <console>:88
2016-06-13 14:05:18,597  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 254 (json at <console>:88) with 2 output partitions
2016-06-13 14:05:18,597  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 264 (json at <console>:88)
2016-06-13 14:05:18,597  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:18,597  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:18,597  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 264 (MapPartitionsRDD[336] at json at <console>:88), which has no missing parents
2016-06-13 14:05:18,598  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_504 stored as values in memory (estimated size 4.2 KB, free 116.8 MB)
2016-06-13 14:05:18,598  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_504_piece0 stored as bytes in memory (estimated size 2.4 KB, free 116.8 MB)
2016-06-13 14:05:18,599  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_504_piece0 in memory on localhost:44356 (size: 2.4 KB, free: 9.7 GB)
2016-06-13 14:05:18,599  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 504 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:18,599  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 264 (MapPartitionsRDD[336] at json at <console>:88)
2016-06-13 14:05:18,599  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 264.0 with 2 tasks
2016-06-13 14:05:18,600  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 264.0 (TID 507, localhost, partition 0,PROCESS_LOCAL, 2331 bytes)
2016-06-13 14:05:18,600  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 264.0 (TID 508, localhost, partition 1,PROCESS_LOCAL, 2331 bytes)
2016-06-13 14:05:18,600  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 264.0 (TID 508)
2016-06-13 14:05:18,601  INFO [Executor task launch worker-0] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/user_profile_history.json:2710893+2710894
2016-06-13 14:05:18,602  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 264.0 (TID 507)
2016-06-13 14:05:18,603  INFO [Executor task launch worker-1] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/user_profile_history.json:0+2710893
2016-06-13 14:05:18,847  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 264.0 (TID 507). 4533 bytes result sent to driver
2016-06-13 14:05:18,848  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 264.0 (TID 507) in 249 ms on localhost (1/2)
2016-06-13 14:05:18,877  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 264.0 (TID 508). 4533 bytes result sent to driver
2016-06-13 14:05:18,878  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 264.0 (TID 508) in 278 ms on localhost (2/2)
2016-06-13 14:05:18,878  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 264 (json at <console>:88) finished in 0.279 s
2016-06-13 14:05:18,878  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 264.0, whose tasks have all completed, from pool 
2016-06-13 14:05:18,878  INFO [Remote-akka.actor.default-dispatcher-21] (org.apache.spark.scheduler.DAGScheduler) - Job 254 finished: json at <console>:88, took 0.281447 s
2016-06-13 14:05:19,175 ERROR [Remote-akka.actor.default-dispatcher-21] (notebook.kernel.Repl) - Ooops, exception in the cell
java.lang.ExceptionInInitializerError
	at sun.misc.Unsafe.ensureClassInitialized(Native Method)
	at sun.reflect.UnsafeFieldAccessorFactory.newFieldAccessor(UnsafeFieldAccessorFactory.java:43)
	at sun.reflect.ReflectionFactory.newFieldAccessor(ReflectionFactory.java:142)
	at java.lang.reflect.Field.acquireFieldAccessor(Field.java:1088)
	at java.lang.reflect.Field.getFieldAccessor(Field.java:1069)
	at java.lang.reflect.Field.get(Field.java:393)
	at notebook.kernel.Repl.getModule$1(Repl.scala:203)
	at notebook.kernel.Repl.iws$1(Repl.scala:212)
	at notebook.kernel.Repl.liftedTree1$1(Repl.scala:219)
	at notebook.kernel.Repl.evaluate(Repl.scala:199)
	at notebook.client.ReplCalculator$$anonfun$15$$anon$1$$anonfun$29.apply(ReplCalculator.scala:378)
	at notebook.client.ReplCalculator$$anonfun$15$$anon$1$$anonfun$29.apply(ReplCalculator.scala:375)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: java.lang.NoSuchMethodException: org.apache.spark.io.SnappyCompressionCodec.<init>(org.apache.spark.SparkConf)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.spark.io.CompressionCodec$.createCodec(CompressionCodec.scala:71)
	at org.apache.spark.io.CompressionCodec$.createCodec(CompressionCodec.scala:65)
	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$setConf(TorrentBroadcast.scala:73)
	at org.apache.spark.broadcast.TorrentBroadcast.<init>(TorrentBroadcast.scala:80)
	at org.apache.spark.broadcast.TorrentBroadcastFactory.newBroadcast(TorrentBroadcastFactory.scala:34)
	at org.apache.spark.broadcast.BroadcastManager.newBroadcast(BroadcastManager.scala:63)
	at org.apache.spark.SparkContext.broadcast(SparkContext.scala:1326)
	at org.apache.spark.sql.execution.datasources.DataSourceStrategy$.apply(DataSourceStrategy.scala:108)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:396)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner.plan(QueryPlanner.scala:59)
	at org.apache.spark.sql.execution.QueryExecution.sparkPlan$lzycompute(QueryExecution.scala:47)
	at org.apache.spark.sql.execution.QueryExecution.sparkPlan(QueryExecution.scala:45)
	at org.apache.spark.sql.execution.QueryExecution.executedPlan$lzycompute(QueryExecution.scala:52)
	at org.apache.spark.sql.execution.QueryExecution.executedPlan(QueryExecution.scala:52)
	at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:55)
	at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:55)
	at org.apache.spark.sql.DataFrame.toJSON(DataFrame.scala:1724)
	at notebook.front.widgets.DataFrameView$class.notebook$front$widgets$DataFrameView$$json(DataFrame.scala:40)
	at notebook.front.widgets.DataFrameWidget.notebook$front$widgets$DataFrameView$$json$lzycompute(DataFrame.scala:64)
	at notebook.front.widgets.DataFrameWidget.notebook$front$widgets$DataFrameView$$json(DataFrame.scala:64)
	at notebook.front.widgets.DataFrameView$class.$init$(DataFrame.scala:41)
	at notebook.front.widgets.DataFrameWidget.<init>(DataFrame.scala:69)
	at notebook.front.ExtraLowPriorityRenderers$dataFrameAsTable$.render(renderer.scala:13)
	at notebook.front.ExtraLowPriorityRenderers$dataFrameAsTable$.render(renderer.scala:12)
	at notebook.front.Widget$.fromRenderer(Widget.scala:32)
	at $line117.$rendered$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$.<init>(<console>:85)
	at $line117.$rendered$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$.<clinit>(<console>)
	... 20 more
2016-06-13 14:05:32,830  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.storage.MemoryStore) - Block broadcast_506 stored as values in memory (estimated size 127.1 KB, free 117.0 MB)
2016-06-13 14:05:32,839  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.storage.MemoryStore) - Block broadcast_506_piece0 stored as bytes in memory (estimated size 13.8 KB, free 117.0 MB)
2016-06-13 14:05:32,839  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_506_piece0 in memory on localhost:44356 (size: 13.8 KB, free: 9.7 GB)
2016-06-13 14:05:32,840  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.SparkContext) - Created broadcast 506 from show at <console>:89
2016-06-13 14:05:32,845  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.storage.MemoryStore) - Block broadcast_507 stored as values in memory (estimated size 128.3 KB, free 117.1 MB)
2016-06-13 14:05:32,854  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.storage.MemoryStore) - Block broadcast_507_piece0 stored as bytes in memory (estimated size 14.2 KB, free 117.1 MB)
2016-06-13 14:05:32,855  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_507_piece0 in memory on localhost:44356 (size: 14.2 KB, free: 9.7 GB)
2016-06-13 14:05:32,856  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.SparkContext) - Created broadcast 507 from show at <console>:89
2016-06-13 14:05:32,884  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.hadoop.mapred.FileInputFormat) - Total input paths to process : 1
2016-06-13 14:05:32,891  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.SparkContext) - Starting job: show at <console>:89
2016-06-13 14:05:32,892  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 255 (show at <console>:89) with 1 output partitions
2016-06-13 14:05:32,892  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 265 (show at <console>:89)
2016-06-13 14:05:32,892  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:05:32,892  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:05:32,892  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 265 (MapPartitionsRDD[342] at show at <console>:89), which has no missing parents
2016-06-13 14:05:32,895  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_508 stored as values in memory (estimated size 7.5 KB, free 117.1 MB)
2016-06-13 14:05:32,896  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_508_piece0 stored as bytes in memory (estimated size 3.9 KB, free 117.1 MB)
2016-06-13 14:05:32,896  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_508_piece0 in memory on localhost:44356 (size: 3.9 KB, free: 9.7 GB)
2016-06-13 14:05:32,897  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 508 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:32,897  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 1 missing tasks from ResultStage 265 (MapPartitionsRDD[342] at show at <console>:89)
2016-06-13 14:05:32,897  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 265.0 with 1 tasks
2016-06-13 14:05:32,898  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 265.0 (TID 509, localhost, partition 0,PROCESS_LOCAL, 2331 bytes)
2016-06-13 14:05:32,898  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 265.0 (TID 509)
2016-06-13 14:05:32,908  INFO [Executor task launch worker-0] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/user_profile_history.json:0+2710893
2016-06-13 14:05:33,014  INFO [Executor task launch worker-0] (org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection) - Code generated in 101.542353 ms
2016-06-13 14:05:33,096  INFO [Executor task launch worker-0] (org.apache.spark.sql.catalyst.expressions.codegen.GenerateSafeProjection) - Code generated in 72.48288 ms
2016-06-13 14:05:33,129  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 265.0 (TID 509). 77882 bytes result sent to driver
2016-06-13 14:05:33,134  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 265 (show at <console>:89) finished in 0.236 s
2016-06-13 14:05:33,134  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.scheduler.DAGScheduler) - Job 255 finished: show at <console>:89, took 0.242257 s
2016-06-13 14:05:33,135  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 265.0 (TID 509) in 236 ms on localhost (1/1)
2016-06-13 14:05:33,136  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 265.0, whose tasks have all completed, from pool 
2016-06-13 14:05:33,212  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.storage.MemoryStore) - Block broadcast_509 stored as values in memory (estimated size 127.1 KB, free 117.2 MB)
2016-06-13 14:05:33,224  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.storage.MemoryStore) - Block broadcast_509_piece0 stored as bytes in memory (estimated size 13.8 KB, free 117.3 MB)
2016-06-13 14:05:33,227  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_509_piece0 in memory on localhost:44356 (size: 13.8 KB, free: 9.7 GB)
2016-06-13 14:05:33,227  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.SparkContext) - Created broadcast 509 from count at <console>:95
2016-06-13 14:05:33,230  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.storage.MemoryStore) - Block broadcast_510 stored as values in memory (estimated size 128.3 KB, free 117.4 MB)
2016-06-13 14:05:33,241  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.storage.MemoryStore) - Block broadcast_510_piece0 stored as bytes in memory (estimated size 14.2 KB, free 117.4 MB)
2016-06-13 14:05:33,242  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_510_piece0 in memory on localhost:44356 (size: 14.2 KB, free: 9.7 GB)
2016-06-13 14:05:33,243  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.SparkContext) - Created broadcast 510 from count at <console>:95
2016-06-13 14:05:33,303  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.hadoop.mapred.FileInputFormat) - Total input paths to process : 1
2016-06-13 14:05:33,329  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.SparkContext) - Starting job: count at <console>:95
2016-06-13 14:05:33,330  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Registering RDD 348 (count at <console>:95)
2016-06-13 14:05:33,330  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 256 (count at <console>:95) with 1 output partitions
2016-06-13 14:05:33,330  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 267 (count at <console>:95)
2016-06-13 14:05:33,330  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List(ShuffleMapStage 266)
2016-06-13 14:05:33,330  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List(ShuffleMapStage 266)
2016-06-13 14:05:33,330  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ShuffleMapStage 266 (MapPartitionsRDD[348] at count at <console>:95), which has no missing parents
2016-06-13 14:05:33,332  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_511 stored as values in memory (estimated size 10.4 KB, free 117.4 MB)
2016-06-13 14:05:33,333  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_511_piece0 stored as bytes in memory (estimated size 5.3 KB, free 117.4 MB)
2016-06-13 14:05:33,333  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_511_piece0 in memory on localhost:44356 (size: 5.3 KB, free: 9.7 GB)
2016-06-13 14:05:33,333  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 511 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:33,334  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ShuffleMapStage 266 (MapPartitionsRDD[348] at count at <console>:95)
2016-06-13 14:05:33,335  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 266.0 with 2 tasks
2016-06-13 14:05:33,335  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 266.0 (TID 510, localhost, partition 0,PROCESS_LOCAL, 2320 bytes)
2016-06-13 14:05:33,336  INFO [dispatcher-event-loop-0] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 266.0 (TID 511, localhost, partition 1,PROCESS_LOCAL, 2320 bytes)
2016-06-13 14:05:33,336  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 266.0 (TID 510)
2016-06-13 14:05:33,336  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 266.0 (TID 511)
2016-06-13 14:05:33,338  INFO [Executor task launch worker-0] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/user_profile_history.json:0+2710893
2016-06-13 14:05:33,339  INFO [Executor task launch worker-1] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/user_profile_history.json:2710893+2710894
2016-06-13 14:05:33,353  INFO [Executor task launch worker-0] (org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection) - Code generated in 13.622394 ms
2016-06-13 14:05:33,390  INFO [Executor task launch worker-0] (org.apache.spark.sql.catalyst.expressions.codegen.GenerateMutableProjection) - Code generated in 11.86751 ms
2016-06-13 14:05:33,425  INFO [Executor task launch worker-1] (org.apache.spark.sql.catalyst.expressions.codegen.GenerateMutableProjection) - Code generated in 11.525256 ms
2016-06-13 14:05:33,447  INFO [Executor task launch worker-1] (org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeRowJoiner) - Code generated in 10.935354 ms
2016-06-13 14:05:33,460  INFO [Executor task launch worker-1] (org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection) - Code generated in 7.463926 ms
2016-06-13 14:05:33,628  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 266.0 (TID 511). 2500 bytes result sent to driver
2016-06-13 14:05:33,628  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 266.0 (TID 510). 2500 bytes result sent to driver
2016-06-13 14:05:33,629  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 266.0 (TID 511) in 294 ms on localhost (1/2)
2016-06-13 14:05:33,630  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 266.0 (TID 510) in 295 ms on localhost (2/2)
2016-06-13 14:05:33,631  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 266.0, whose tasks have all completed, from pool 
2016-06-13 14:05:33,634  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ShuffleMapStage 266 (count at <console>:95) finished in 0.299 s
2016-06-13 14:05:33,634  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - looking for newly runnable stages
2016-06-13 14:05:33,634  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - running: Set()
2016-06-13 14:05:33,634  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - waiting: Set(ResultStage 267)
2016-06-13 14:05:33,634  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - failed: Set()
2016-06-13 14:05:33,634  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 267 (MapPartitionsRDD[351] at count at <console>:95), which has no missing parents
2016-06-13 14:05:33,636  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_512 stored as values in memory (estimated size 11.5 KB, free 117.4 MB)
2016-06-13 14:05:33,637  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_512_piece0 stored as bytes in memory (estimated size 5.8 KB, free 117.4 MB)
2016-06-13 14:05:33,639  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_512_piece0 in memory on localhost:44356 (size: 5.8 KB, free: 9.7 GB)
2016-06-13 14:05:33,640  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 512 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:05:33,640  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 1 missing tasks from ResultStage 267 (MapPartitionsRDD[351] at count at <console>:95)
2016-06-13 14:05:33,640  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 267.0 with 1 tasks
2016-06-13 14:05:33,642  INFO [dispatcher-event-loop-2] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 267.0 (TID 512, localhost, partition 0,NODE_LOCAL, 2093 bytes)
2016-06-13 14:05:33,642  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 267.0 (TID 512)
2016-06-13 14:05:33,644  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 2 non-empty blocks out of 2 blocks
2016-06-13 14:05:33,644  INFO [Executor task launch worker-0] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2016-06-13 14:05:33,659  INFO [Executor task launch worker-0] (org.apache.spark.sql.catalyst.expressions.codegen.GenerateMutableProjection) - Code generated in 8.830243 ms
2016-06-13 14:05:33,714  INFO [Executor task launch worker-0] (org.apache.spark.sql.catalyst.expressions.codegen.GenerateMutableProjection) - Code generated in 7.477935 ms
2016-06-13 14:05:33,726  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 267.0 (TID 512). 1830 bytes result sent to driver
2016-06-13 14:05:33,727  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 267.0 (TID 512) in 87 ms on localhost (1/1)
2016-06-13 14:05:33,727  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 267.0, whose tasks have all completed, from pool 
2016-06-13 14:05:33,727  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 267 (count at <console>:95) finished in 0.085 s
2016-06-13 14:05:33,727  INFO [Remote-akka.actor.default-dispatcher-3] (org.apache.spark.scheduler.DAGScheduler) - Job 256 finished: count at <console>:95, took 0.397527 s
2016-06-13 14:05:33,958  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_512_piece0 on localhost:44356 in memory (size: 5.8 KB, free: 9.7 GB)
2016-06-13 14:05:33,962  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 273
2016-06-13 14:05:33,964  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_511_piece0 on localhost:44356 in memory (size: 5.3 KB, free: 9.7 GB)
2016-06-13 14:05:33,965  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 272
2016-06-13 14:05:33,966  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned shuffle 4
2016-06-13 14:05:33,966  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 271
2016-06-13 14:05:33,966  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 270
2016-06-13 14:05:33,966  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 269
2016-06-13 14:05:33,966  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 268
2016-06-13 14:05:33,966  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 267
2016-06-13 14:05:33,966  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 266
2016-06-13 14:05:33,967  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 265
2016-06-13 14:05:33,967  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 264
2016-06-13 14:05:33,967  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_510_piece0 on localhost:44356 in memory (size: 14.2 KB, free: 9.7 GB)
2016-06-13 14:05:33,971  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_509_piece0 on localhost:44356 in memory (size: 13.8 KB, free: 9.7 GB)
2016-06-13 14:05:33,971  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_508_piece0 on localhost:44356 in memory (size: 3.9 KB, free: 9.7 GB)
2016-06-13 14:05:33,971  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 262
2016-06-13 14:05:33,971  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_507_piece0 on localhost:44356 in memory (size: 14.2 KB, free: 9.7 GB)
2016-06-13 14:05:33,972  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_506_piece0 on localhost:44356 in memory (size: 13.8 KB, free: 9.7 GB)
2016-06-13 14:05:33,972  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_504_piece0 on localhost:44356 in memory (size: 2.4 KB, free: 9.7 GB)
2016-06-13 14:05:33,976  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 261
2016-06-13 14:05:33,977  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_503_piece0 on localhost:44356 in memory (size: 14.2 KB, free: 9.7 GB)
2016-06-13 14:05:33,977  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_502_piece0 on localhost:44356 in memory (size: 5.4 KB, free: 9.7 GB)
2016-06-13 14:05:33,977  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 260
2016-06-13 14:05:33,978  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_501_piece0 on localhost:44356 in memory (size: 5.3 KB, free: 9.7 GB)
2016-06-13 14:05:33,978  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 259
2016-06-13 14:05:33,978  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_500_piece0 on localhost:44356 in memory (size: 5.2 KB, free: 9.7 GB)
2016-06-13 14:05:33,978  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 258
2016-06-13 14:05:33,979  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_498_piece0 on localhost:44356 in memory (size: 13.8 KB, free: 9.7 GB)
2016-06-13 14:05:33,979  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_497_piece0 on localhost:44356 in memory (size: 2.4 KB, free: 9.7 GB)
2016-06-13 14:05:33,979  INFO [Spark Context Cleaner] (org.apache.spark.ContextCleaner) - Cleaned accumulator 256
2016-06-13 14:05:33,980  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Removed broadcast_496_piece0 on localhost:44356 in memory (size: 14.2 KB, free: 9.7 GB)
2016-06-13 14:06:02,446  INFO [Remote-akka.actor.default-dispatcher-21] (org.apache.spark.sql.execution.datasources.json.JSONRelation) - Listing file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/user_profiles_only.json on driver
2016-06-13 14:06:02,450  INFO [Remote-akka.actor.default-dispatcher-21] (org.apache.spark.storage.MemoryStore) - Block broadcast_513 stored as values in memory (estimated size 128.2 KB, free 116.5 MB)
2016-06-13 14:06:02,458  INFO [Remote-akka.actor.default-dispatcher-21] (org.apache.spark.storage.MemoryStore) - Block broadcast_513_piece0 stored as bytes in memory (estimated size 14.2 KB, free 116.5 MB)
2016-06-13 14:06:02,459  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_513_piece0 in memory on localhost:44356 (size: 14.2 KB, free: 9.7 GB)
2016-06-13 14:06:02,461  INFO [Remote-akka.actor.default-dispatcher-21] (org.apache.spark.SparkContext) - Created broadcast 513 from json at <console>:89
2016-06-13 14:06:02,468  INFO [Remote-akka.actor.default-dispatcher-21] (org.apache.hadoop.mapred.FileInputFormat) - Total input paths to process : 1
2016-06-13 14:06:02,475  INFO [Remote-akka.actor.default-dispatcher-21] (org.apache.spark.SparkContext) - Starting job: json at <console>:89
2016-06-13 14:06:02,476  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 257 (json at <console>:89) with 2 output partitions
2016-06-13 14:06:02,476  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 268 (json at <console>:89)
2016-06-13 14:06:02,476  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:06:02,476  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:06:02,476  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 268 (MapPartitionsRDD[355] at json at <console>:89), which has no missing parents
2016-06-13 14:06:02,477  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_514 stored as values in memory (estimated size 4.2 KB, free 116.5 MB)
2016-06-13 14:06:02,478  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_514_piece0 stored as bytes in memory (estimated size 2.4 KB, free 116.5 MB)
2016-06-13 14:06:02,479  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_514_piece0 in memory on localhost:44356 (size: 2.4 KB, free: 9.7 GB)
2016-06-13 14:06:02,481  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 514 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:06:02,481  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ResultStage 268 (MapPartitionsRDD[355] at json at <console>:89)
2016-06-13 14:06:02,481  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 268.0 with 2 tasks
2016-06-13 14:06:02,481  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 268.0 (TID 513, localhost, partition 0,PROCESS_LOCAL, 2329 bytes)
2016-06-13 14:06:02,482  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 268.0 (TID 514, localhost, partition 1,PROCESS_LOCAL, 2329 bytes)
2016-06-13 14:06:02,482  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 268.0 (TID 513)
2016-06-13 14:06:02,482  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 268.0 (TID 514)
2016-06-13 14:06:02,483  INFO [Executor task launch worker-1] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/user_profiles_only.json:2205344+2205345
2016-06-13 14:06:02,483  INFO [Executor task launch worker-0] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/user_profiles_only.json:0+2205344
2016-06-13 14:06:02,574  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 268.0 (TID 514). 3899 bytes result sent to driver
2016-06-13 14:06:02,576  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 268.0 (TID 514) in 94 ms on localhost (1/2)
2016-06-13 14:06:02,610  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 268.0 (TID 513). 3899 bytes result sent to driver
2016-06-13 14:06:02,612  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 268.0 (TID 513) in 131 ms on localhost (2/2)
2016-06-13 14:06:02,612  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 268.0, whose tasks have all completed, from pool 
2016-06-13 14:06:02,612  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 268 (json at <console>:89) finished in 0.131 s
2016-06-13 14:06:02,612  INFO [Remote-akka.actor.default-dispatcher-21] (org.apache.spark.scheduler.DAGScheduler) - Job 257 finished: json at <console>:89, took 0.136292 s
2016-06-13 14:06:02,806 ERROR [Remote-akka.actor.default-dispatcher-21] (notebook.kernel.Repl) - Ooops, exception in the cell
java.lang.ExceptionInInitializerError
	at sun.misc.Unsafe.ensureClassInitialized(Native Method)
	at sun.reflect.UnsafeFieldAccessorFactory.newFieldAccessor(UnsafeFieldAccessorFactory.java:43)
	at sun.reflect.ReflectionFactory.newFieldAccessor(ReflectionFactory.java:142)
	at java.lang.reflect.Field.acquireFieldAccessor(Field.java:1088)
	at java.lang.reflect.Field.getFieldAccessor(Field.java:1069)
	at java.lang.reflect.Field.get(Field.java:393)
	at notebook.kernel.Repl.getModule$1(Repl.scala:203)
	at notebook.kernel.Repl.iws$1(Repl.scala:212)
	at notebook.kernel.Repl.liftedTree1$1(Repl.scala:219)
	at notebook.kernel.Repl.evaluate(Repl.scala:199)
	at notebook.client.ReplCalculator$$anonfun$15$$anon$1$$anonfun$29.apply(ReplCalculator.scala:378)
	at notebook.client.ReplCalculator$$anonfun$15$$anon$1$$anonfun$29.apply(ReplCalculator.scala:375)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24)
	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24)
	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)
	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397)
	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)
	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)
	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)
	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)
Caused by: java.lang.NoSuchMethodException: org.apache.spark.io.SnappyCompressionCodec.<init>(org.apache.spark.SparkConf)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.spark.io.CompressionCodec$.createCodec(CompressionCodec.scala:71)
	at org.apache.spark.io.CompressionCodec$.createCodec(CompressionCodec.scala:65)
	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$setConf(TorrentBroadcast.scala:73)
	at org.apache.spark.broadcast.TorrentBroadcast.<init>(TorrentBroadcast.scala:80)
	at org.apache.spark.broadcast.TorrentBroadcastFactory.newBroadcast(TorrentBroadcastFactory.scala:34)
	at org.apache.spark.broadcast.BroadcastManager.newBroadcast(BroadcastManager.scala:63)
	at org.apache.spark.SparkContext.broadcast(SparkContext.scala:1326)
	at org.apache.spark.sql.execution.datasources.DataSourceStrategy$.apply(DataSourceStrategy.scala:108)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner$$anonfun$1.apply(QueryPlanner.scala:58)
	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:396)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner.plan(QueryPlanner.scala:59)
	at org.apache.spark.sql.execution.QueryExecution.sparkPlan$lzycompute(QueryExecution.scala:47)
	at org.apache.spark.sql.execution.QueryExecution.sparkPlan(QueryExecution.scala:45)
	at org.apache.spark.sql.execution.QueryExecution.executedPlan$lzycompute(QueryExecution.scala:52)
	at org.apache.spark.sql.execution.QueryExecution.executedPlan(QueryExecution.scala:52)
	at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:55)
	at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:55)
	at org.apache.spark.sql.DataFrame.toJSON(DataFrame.scala:1724)
	at notebook.front.widgets.DataFrameView$class.notebook$front$widgets$DataFrameView$$json(DataFrame.scala:40)
	at notebook.front.widgets.DataFrameWidget.notebook$front$widgets$DataFrameView$$json$lzycompute(DataFrame.scala:64)
	at notebook.front.widgets.DataFrameWidget.notebook$front$widgets$DataFrameView$$json(DataFrame.scala:64)
	at notebook.front.widgets.DataFrameView$class.$init$(DataFrame.scala:41)
	at notebook.front.widgets.DataFrameWidget.<init>(DataFrame.scala:69)
	at notebook.front.ExtraLowPriorityRenderers$dataFrameAsTable$.render(renderer.scala:13)
	at notebook.front.ExtraLowPriorityRenderers$dataFrameAsTable$.render(renderer.scala:12)
	at notebook.front.Widget$.fromRenderer(Widget.scala:32)
	at $line119.$rendered$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$.<init>(<console>:85)
	at $line119.$rendered$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$$iw$.<clinit>(<console>)
	... 20 more
2016-06-13 14:06:07,573  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.MemoryStore) - Block broadcast_516 stored as values in memory (estimated size 127.1 KB, free 116.6 MB)
2016-06-13 14:06:07,581  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.MemoryStore) - Block broadcast_516_piece0 stored as bytes in memory (estimated size 13.8 KB, free 116.6 MB)
2016-06-13 14:06:07,582  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_516_piece0 in memory on localhost:44356 (size: 13.8 KB, free: 9.7 GB)
2016-06-13 14:06:07,583  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkContext) - Created broadcast 516 from show at <console>:90
2016-06-13 14:06:07,585  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.MemoryStore) - Block broadcast_517 stored as values in memory (estimated size 128.2 KB, free 116.8 MB)
2016-06-13 14:06:07,594  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.MemoryStore) - Block broadcast_517_piece0 stored as bytes in memory (estimated size 14.2 KB, free 116.8 MB)
2016-06-13 14:06:07,594  INFO [dispatcher-event-loop-3] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_517_piece0 in memory on localhost:44356 (size: 14.2 KB, free: 9.7 GB)
2016-06-13 14:06:07,595  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkContext) - Created broadcast 517 from show at <console>:90
2016-06-13 14:06:07,609  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.hadoop.mapred.FileInputFormat) - Total input paths to process : 1
2016-06-13 14:06:07,611  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkContext) - Starting job: show at <console>:90
2016-06-13 14:06:07,612  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 258 (show at <console>:90) with 1 output partitions
2016-06-13 14:06:07,612  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 269 (show at <console>:90)
2016-06-13 14:06:07,612  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List()
2016-06-13 14:06:07,612  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List()
2016-06-13 14:06:07,612  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 269 (MapPartitionsRDD[361] at show at <console>:90), which has no missing parents
2016-06-13 14:06:07,615  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_518 stored as values in memory (estimated size 6.7 KB, free 116.8 MB)
2016-06-13 14:06:07,616  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_518_piece0 stored as bytes in memory (estimated size 3.7 KB, free 116.8 MB)
2016-06-13 14:06:07,617  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_518_piece0 in memory on localhost:44356 (size: 3.7 KB, free: 9.7 GB)
2016-06-13 14:06:07,618  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 518 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:06:07,618  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 1 missing tasks from ResultStage 269 (MapPartitionsRDD[361] at show at <console>:90)
2016-06-13 14:06:07,618  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 269.0 with 1 tasks
2016-06-13 14:06:07,620  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 269.0 (TID 515, localhost, partition 0,PROCESS_LOCAL, 2329 bytes)
2016-06-13 14:06:07,620  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 269.0 (TID 515)
2016-06-13 14:06:07,623  INFO [Executor task launch worker-0] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/user_profiles_only.json:0+2205344
2016-06-13 14:06:07,671  INFO [Executor task launch worker-0] (org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection) - Code generated in 44.252039 ms
2016-06-13 14:06:07,723  INFO [Executor task launch worker-0] (org.apache.spark.sql.catalyst.expressions.codegen.GenerateSafeProjection) - Code generated in 38.965952 ms
2016-06-13 14:06:07,743  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 269.0 (TID 515). 68576 bytes result sent to driver
2016-06-13 14:06:07,748  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 269.0 (TID 515) in 128 ms on localhost (1/1)
2016-06-13 14:06:07,748  INFO [task-result-getter-0] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 269.0, whose tasks have all completed, from pool 
2016-06-13 14:06:07,748  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 269 (show at <console>:90) finished in 0.127 s
2016-06-13 14:06:07,748  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.scheduler.DAGScheduler) - Job 258 finished: show at <console>:90, took 0.137070 s
2016-06-13 14:06:07,759  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.MemoryStore) - Block broadcast_519 stored as values in memory (estimated size 127.1 KB, free 116.9 MB)
2016-06-13 14:06:07,767  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.MemoryStore) - Block broadcast_519_piece0 stored as bytes in memory (estimated size 13.8 KB, free 116.9 MB)
2016-06-13 14:06:07,768  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_519_piece0 in memory on localhost:44356 (size: 13.8 KB, free: 9.7 GB)
2016-06-13 14:06:07,768  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkContext) - Created broadcast 519 from count at <console>:96
2016-06-13 14:06:07,771  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.MemoryStore) - Block broadcast_520 stored as values in memory (estimated size 128.2 KB, free 117.0 MB)
2016-06-13 14:06:07,779  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.storage.MemoryStore) - Block broadcast_520_piece0 stored as bytes in memory (estimated size 14.2 KB, free 117.1 MB)
2016-06-13 14:06:07,780  INFO [dispatcher-event-loop-1] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_520_piece0 in memory on localhost:44356 (size: 14.2 KB, free: 9.7 GB)
2016-06-13 14:06:07,781  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkContext) - Created broadcast 520 from count at <console>:96
2016-06-13 14:06:07,804  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.hadoop.mapred.FileInputFormat) - Total input paths to process : 1
2016-06-13 14:06:07,815  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.SparkContext) - Starting job: count at <console>:96
2016-06-13 14:06:07,815  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Registering RDD 367 (count at <console>:96)
2016-06-13 14:06:07,816  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Got job 259 (count at <console>:96) with 1 output partitions
2016-06-13 14:06:07,816  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Final stage: ResultStage 271 (count at <console>:96)
2016-06-13 14:06:07,816  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Parents of final stage: List(ShuffleMapStage 270)
2016-06-13 14:06:07,816  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Missing parents: List(ShuffleMapStage 270)
2016-06-13 14:06:07,816  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ShuffleMapStage 270 (MapPartitionsRDD[367] at count at <console>:96), which has no missing parents
2016-06-13 14:06:07,817  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_521 stored as values in memory (estimated size 10.4 KB, free 117.1 MB)
2016-06-13 14:06:07,818  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_521_piece0 stored as bytes in memory (estimated size 5.3 KB, free 117.1 MB)
2016-06-13 14:06:07,818  INFO [dispatcher-event-loop-2] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_521_piece0 in memory on localhost:44356 (size: 5.3 KB, free: 9.7 GB)
2016-06-13 14:06:07,819  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 521 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:06:07,819  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 2 missing tasks from ShuffleMapStage 270 (MapPartitionsRDD[367] at count at <console>:96)
2016-06-13 14:06:07,819  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 270.0 with 2 tasks
2016-06-13 14:06:07,819  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 270.0 (TID 516, localhost, partition 0,PROCESS_LOCAL, 2318 bytes)
2016-06-13 14:06:07,819  INFO [dispatcher-event-loop-3] (org.apache.spark.scheduler.TaskSetManager) - Starting task 1.0 in stage 270.0 (TID 517, localhost, partition 1,PROCESS_LOCAL, 2318 bytes)
2016-06-13 14:06:07,819  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 270.0 (TID 516)
2016-06-13 14:06:07,819  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 1.0 in stage 270.0 (TID 517)
2016-06-13 14:06:07,821  INFO [Executor task launch worker-1] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/user_profiles_only.json:2205344+2205345
2016-06-13 14:06:07,821  INFO [Executor task launch worker-0] (org.apache.spark.rdd.HadoopRDD) - Input split: file:/home/jatin/Downloads/spark-notebook-0.6.2-scala-2.11.7-spark-1.6.0-hadoop-2.2.0-with-hive-with-parquet/user_profiles_only.json:0+2205344
2016-06-13 14:06:07,898  INFO [Executor task launch worker-0] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 270.0 (TID 516). 2500 bytes result sent to driver
2016-06-13 14:06:07,898  INFO [task-result-getter-3] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 270.0 (TID 516) in 79 ms on localhost (1/2)
2016-06-13 14:06:07,902  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 1.0 in stage 270.0 (TID 517). 2500 bytes result sent to driver
2016-06-13 14:06:07,903  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSetManager) - Finished task 1.0 in stage 270.0 (TID 517) in 84 ms on localhost (2/2)
2016-06-13 14:06:07,903  INFO [task-result-getter-2] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 270.0, whose tasks have all completed, from pool 
2016-06-13 14:06:07,903  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ShuffleMapStage 270 (count at <console>:96) finished in 0.084 s
2016-06-13 14:06:07,903  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - looking for newly runnable stages
2016-06-13 14:06:07,903  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - running: Set()
2016-06-13 14:06:07,903  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - waiting: Set(ResultStage 271)
2016-06-13 14:06:07,903  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - failed: Set()
2016-06-13 14:06:07,903  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting ResultStage 271 (MapPartitionsRDD[370] at count at <console>:96), which has no missing parents
2016-06-13 14:06:07,904  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_522 stored as values in memory (estimated size 11.5 KB, free 117.1 MB)
2016-06-13 14:06:07,905  INFO [dag-scheduler-event-loop] (org.apache.spark.storage.MemoryStore) - Block broadcast_522_piece0 stored as bytes in memory (estimated size 5.8 KB, free 117.1 MB)
2016-06-13 14:06:07,905  INFO [dispatcher-event-loop-0] (org.apache.spark.storage.BlockManagerInfo) - Added broadcast_522_piece0 in memory on localhost:44356 (size: 5.8 KB, free: 9.7 GB)
2016-06-13 14:06:07,905  INFO [dag-scheduler-event-loop] (org.apache.spark.SparkContext) - Created broadcast 522 from broadcast at DAGScheduler.scala:1006
2016-06-13 14:06:07,905  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - Submitting 1 missing tasks from ResultStage 271 (MapPartitionsRDD[370] at count at <console>:96)
2016-06-13 14:06:07,906  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.TaskSchedulerImpl) - Adding task set 271.0 with 1 tasks
2016-06-13 14:06:07,906  INFO [dispatcher-event-loop-1] (org.apache.spark.scheduler.TaskSetManager) - Starting task 0.0 in stage 271.0 (TID 518, localhost, partition 0,NODE_LOCAL, 2093 bytes)
2016-06-13 14:06:07,906  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Running task 0.0 in stage 271.0 (TID 518)
2016-06-13 14:06:07,908  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Getting 2 non-empty blocks out of 2 blocks
2016-06-13 14:06:07,908  INFO [Executor task launch worker-1] (org.apache.spark.storage.ShuffleBlockFetcherIterator) - Started 0 remote fetches in 0 ms
2016-06-13 14:06:07,910  INFO [Executor task launch worker-1] (org.apache.spark.executor.Executor) - Finished task 0.0 in stage 271.0 (TID 518). 1830 bytes result sent to driver
2016-06-13 14:06:07,911  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSetManager) - Finished task 0.0 in stage 271.0 (TID 518) in 5 ms on localhost (1/1)
2016-06-13 14:06:07,911  INFO [task-result-getter-1] (org.apache.spark.scheduler.TaskSchedulerImpl) - Removed TaskSet 271.0, whose tasks have all completed, from pool 
2016-06-13 14:06:07,911  INFO [dag-scheduler-event-loop] (org.apache.spark.scheduler.DAGScheduler) - ResultStage 271 (count at <console>:96) finished in 0.005 s
2016-06-13 14:06:07,911  INFO [Remote-akka.actor.default-dispatcher-15] (org.apache.spark.scheduler.DAGScheduler) - Job 259 finished: count at <console>:96, took 0.095765 s
